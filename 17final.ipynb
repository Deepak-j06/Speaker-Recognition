{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3104725d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: speechbrain in c:\\users\\deepak\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\deepak\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torch in c:\\users\\deepak\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: librosa in c:\\users\\deepak\\anaconda3\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: hyperpyyaml in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from speechbrain) (1.2.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from speechbrain) (1.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from speechbrain) (1.24.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from speechbrain) (24.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from speechbrain) (1.11.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from speechbrain) (0.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from speechbrain) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from speechbrain) (0.29.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from librosa) (0.57.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from librosa) (0.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.40.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from huggingface-hub->speechbrain) (6.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from tqdm->speechbrain) (0.4.6)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from hyperpyyaml->speechbrain) (0.18.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install speechbrain torchaudio torch librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10bb7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "import speechbrain as sb\n",
    "from speechbrain.inference import SpeakerRecognition\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d04eee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained ECAPA-TDNN model from SpeechBrain\n",
    "model = SpeakerRecognition.from_hparams(\n",
    "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "    savedir=\"pretrained_models/spkrec-ecapa\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "443c6f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected speakers: ['.ipynb_checkpoints', 'deepak', 'harika', 'likith', 'likta', 'macha', 'maimuna', 'manasa', 'nihar', 'nikith', 'pavan', 'rajesh', 'rno1', 'ruk', 'satwik', 'sup', 'vara', 'vijetha']\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"17paras\"  # Folder where your speaker subfolders exist\n",
    "\n",
    "# List all speaker directories\n",
    "speakers = os.listdir(data_folder)\n",
    "print(\"Detected speakers:\", speakers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b7d889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 603 audio files from 18 speakers.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"17paras\"\n",
    "\n",
    "# Get list of speakers (folder names)\n",
    "speakers = sorted(os.listdir(dataset_path))\n",
    "speaker_to_id = {spk: i for i, spk in enumerate(speakers)}\n",
    "\n",
    "# Load all data\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for speaker in speakers:\n",
    "    speaker_folder = os.path.join(dataset_path, speaker)\n",
    "    for filename in os.listdir(speaker_folder):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            filepath = os.path.join(speaker_folder, filename)\n",
    "            data.append(filepath)\n",
    "            labels.append(speaker_to_id[speaker])\n",
    "\n",
    "# Convert labels to tensor\n",
    "labels = torch.tensor(labels)\n",
    "print(f\"Loaded {len(data)} audio files from {len(speakers)} speakers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea5c32ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from speechbrain.inference import EncoderClassifier\n",
    "import torchaudio\n",
    "\n",
    "# Load the pre-trained ECAPA-TDNN model\n",
    "classifier = EncoderClassifier.from_hparams(\n",
    "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "    savedir=\"speechbrain_pretrained\"\n",
    ")\n",
    "\n",
    "def extract_embeddings(file):\n",
    "    \"\"\"Extract ECAPA-TDNN embeddings and ensure consistent shape.\"\"\"\n",
    "    signal = classifier.load_audio(file)  # Load the audio\n",
    "    embeddings = classifier.encode_batch(signal).detach()  # Get embeddings\n",
    "\n",
    "    # Ensure shape is always [1, 192]\n",
    "    embeddings = embeddings.squeeze(0)  # Remove batch dim\n",
    "    if embeddings.dim() == 1:\n",
    "        embeddings = embeddings.unsqueeze(0)  # Ensure (1, 192)\n",
    "\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3535e0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: torch.Size([603, 192])\n",
      "y Shape: torch.Size([603])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEEPAK\\AppData\\Local\\Temp\\ipykernel_19360\\721886779.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "# Extract features with consistent shape\n",
    "X = [extract_embeddings(file) for file in data]\n",
    "X = torch.cat(X, dim=0)  # Concatenate correctly\n",
    "y = torch.tensor(labels)\n",
    "\n",
    "print(\"X Shape:\", X.shape)  # Should be (num_samples, 192)\n",
    "print(\"y Shape:\", y.shape)  # Should be (num_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8de57785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 29.4529\n",
      "Epoch 2, Loss: 0.2332\n",
      "Epoch 3, Loss: 0.0587\n",
      "Epoch 4, Loss: 0.0382\n",
      "Epoch 5, Loss: 0.0300\n",
      "Epoch 6, Loss: 0.0245\n",
      "Epoch 7, Loss: 0.0202\n",
      "Epoch 8, Loss: 0.0173\n",
      "Epoch 9, Loss: 0.0148\n",
      "Epoch 10, Loss: 0.0128\n",
      "Epoch 11, Loss: 0.0112\n",
      "Epoch 12, Loss: 0.0100\n",
      "Epoch 13, Loss: 0.0089\n",
      "Epoch 14, Loss: 0.0079\n",
      "Epoch 15, Loss: 0.0071\n",
      "Epoch 16, Loss: 0.0064\n",
      "Epoch 17, Loss: 0.0059\n",
      "Epoch 18, Loss: 0.0054\n",
      "Epoch 19, Loss: 0.0049\n",
      "Epoch 20, Loss: 0.0046\n",
      "Epoch 21, Loss: 0.0043\n",
      "Epoch 22, Loss: 0.0039\n",
      "Epoch 23, Loss: 0.0036\n",
      "Epoch 24, Loss: 0.0034\n",
      "Epoch 25, Loss: 0.0032\n",
      "Epoch 26, Loss: 0.0030\n",
      "Epoch 27, Loss: 0.0028\n",
      "Epoch 28, Loss: 0.0026\n",
      "Epoch 29, Loss: 0.0025\n",
      "Epoch 30, Loss: 0.0023\n",
      "Epoch 31, Loss: 0.0022\n",
      "Epoch 32, Loss: 0.0021\n",
      "Epoch 33, Loss: 0.0020\n",
      "Epoch 34, Loss: 0.0019\n",
      "Epoch 35, Loss: 0.0018\n",
      "Epoch 36, Loss: 0.0017\n",
      "Epoch 37, Loss: 0.0016\n",
      "Epoch 38, Loss: 0.0015\n",
      "Epoch 39, Loss: 0.0014\n",
      "Epoch 40, Loss: 0.0014\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create dataset & dataloader\n",
    "dataset = TensorDataset(X, y)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Define classifier\n",
    "class SpeakerClassifier(nn.Module):\n",
    "    def __init__(self, input_size=192, num_classes=len(speakers)):\n",
    "        super(SpeakerClassifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = SpeakerClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the classifier\n",
    "for epoch in range(40):  # 20 epochs\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e92de93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 29.8161\n",
      "Epoch 2, Loss: 0.1491\n",
      "Epoch 3, Loss: 0.0546\n",
      "Epoch 4, Loss: 0.0358\n",
      "Epoch 5, Loss: 0.0274\n",
      "Epoch 6, Loss: 0.0217\n",
      "Epoch 7, Loss: 0.0180\n",
      "Epoch 8, Loss: 0.0151\n",
      "Epoch 9, Loss: 0.0130\n",
      "Epoch 10, Loss: 0.0111\n",
      "Epoch 11, Loss: 0.0097\n",
      "Epoch 12, Loss: 0.0087\n",
      "Epoch 13, Loss: 0.0076\n",
      "Epoch 14, Loss: 0.0068\n",
      "Epoch 15, Loss: 0.0061\n",
      "Epoch 16, Loss: 0.0055\n",
      "Epoch 17, Loss: 0.0050\n",
      "Epoch 18, Loss: 0.0046\n",
      "Epoch 19, Loss: 0.0042\n",
      "Epoch 20, Loss: 0.0039\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create dataset & dataloader\n",
    "dataset = TensorDataset(X, y)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Define classifier\n",
    "class SpeakerClassifier(nn.Module):\n",
    "    def __init__(self, input_size=192, num_classes=len(speakers)):\n",
    "        super(SpeakerClassifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = SpeakerClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the classifier\n",
    "for epoch in range(20):  # 20 epochs\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c260a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speakers List: ['.ipynb_checkpoints', 'deepak', 'harika', 'likith', 'likta', 'macha', 'maimuna', 'manasa', 'nihar', 'nikith', 'pavan', 'rajesh', 'rno1', 'ruk', 'satwik', 'sup', 'vara', 'vijetha']\n"
     ]
    }
   ],
   "source": [
    "print(\"Speakers List:\", speakers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fbdf4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_speaker(model, classifier, audio_path):\n",
    "    # Extract embedding\n",
    "    embedding = extract_embeddings(audio_path) # Pass only the audio_path\n",
    "    print(\"Embedding Shape:\", embedding.shape)  # Expected (192,) or (256,)\n",
    "\n",
    "    # Ensure embedding is in the correct format\n",
    "    embedding = embedding.unsqueeze(0)  # Shape should be (1, 192) or (1, 256)\n",
    "    print(\"Reshaped Embedding Shape:\", embedding.shape)\n",
    "\n",
    "    # Get model output\n",
    "    with torch.no_grad():\n",
    "        output = model(embedding)\n",
    "        print(\"Model Output Shape:\", output.shape)  # Expected (1, num_speakers)\n",
    "\n",
    "    # Debug: Print full output tensor\n",
    "    print(\"Model Raw Output:\", output)\n",
    "\n",
    "    # Get the predicted label\n",
    "    pred_label = torch.argmax(output, dim=-1).item()\n",
    "    print(\"Predicted Label Index:\", pred_label)\n",
    "\n",
    "    # Check if pred_label is valid\n",
    "    if pred_label >= len(speakers):\n",
    "        print(\"Error: Predicted label out of range!\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "    return speakers[pred_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e599ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.2735,  -4.5327,  -6.3374,  12.7525,  -0.7987,   1.0738,  -9.4011,\n",
      "           -3.4586,   1.0701,  -2.3468,   4.7494,   1.0715,  -3.1335,  -2.7711,\n",
      "            1.9931,  -1.3675,  -6.2056,  -1.6441]]])\n",
      "Predicted Label Index: 3\n",
      "Predicted Speaker: likith\n"
     ]
    }
   ],
   "source": [
    "test_audio = \"17paras/likith/lik_1.wav\"\n",
    "predicted_speaker = predict_speaker(model, classifier, test_audio)\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5dcb213f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.2722,  2.4743, -2.7410,  1.4582, -3.6348, -3.0698, -6.7030,\n",
      "          -6.4339,  2.6832,  1.9525,  2.8084,  8.3893, -1.8746, -5.3146,\n",
      "           1.9231, -6.2032, -9.7421, -9.4702]]])\n",
      "Predicted Label Index: 11\n",
      "Predicted Speaker: rajesh\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Call the existing function\n",
    "test_audio = \"test/newraj.wav\"\n",
    "predicted_speaker = predict_speaker(model, classifier, test_audio)\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")\n",
    "\n",
    "# Get model output again for confidence scores\n",
    "with torch.no_grad():\n",
    "    embedding = extract_embeddings(test_audio).unsqueeze(0)  # Ensure correct shape\n",
    "    output = model(embedding)\n",
    "\n",
    "# Apply softmax to convert logits into probabilities\n",
    "softmax_probs = F.softmax(output, dim=-1).squeeze()  # Remove extra dimensions if needed\n",
    "softmax_probs = softmax_probs.cpu().numpy()  # Convert only after calling .cpu()\n",
    "\n",
    "# Plot confidence scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(np.arange(len(speakers)), softmax_probs, color='skyblue')\n",
    "plt.xticks(np.arange(len(speakers)), speakers, rotation=45)\n",
    "plt.ylabel(\"Confidence Score\")\n",
    "plt.xlabel(\"Speakers\")\n",
    "plt.title(f\"Speaker Prediction Confidence - {predicted_speaker}\")\n",
    "plt.ylim(0, 1)  # Confidence scores range from 0 to 1\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Highlight the predicted speaker\n",
    "pred_label = np.argmax(softmax_probs)\n",
    "plt.bar(pred_label, softmax_probs[pred_label], color='green', label=\"Predicted Speaker\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "77241c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Predicted Speaker: likith (Confidence: 0.3847)\n",
      "\n",
      " Confidence Scores for Each Speaker:\n",
      ".ipynb_checkpoints: 0.0003\n",
      "deepak: 0.0008\n",
      "harika: 0.0003\n",
      "likith: 0.3847\n",
      "likta: 0.0078\n",
      "macha: 0.0184\n",
      "maimuna: 0.0000\n",
      "manasa: 0.0021\n",
      "nihar: 0.0238\n",
      "nikith: 0.1435\n",
      "pavan: 0.3020\n",
      "rajesh: 0.1122\n",
      "rno1: 0.0010\n",
      "ruk: 0.0002\n",
      "satwik: 0.0024\n",
      "sup: 0.0005\n",
      "vara: 0.0001\n",
      "vijetha: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a threshold for unknown speakers\n",
    "UNKNOWN_THRESHOLD = 0.3  # Adjust based on performance\n",
    "\n",
    "def predict_speaker_with_confidence(model, classifier, audio_path):\n",
    "    \"\"\"Predict speaker with confidence score comparison.\"\"\"\n",
    "    embedding = extract_embeddings(audio_path).unsqueeze(0)  # Ensure correct shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(embedding)\n",
    "\n",
    "    # Apply softmax for confidence scores\n",
    "    softmax_probs = F.softmax(output, dim=-1).squeeze().cpu().numpy()\n",
    "\n",
    "    # Get the most confident prediction\n",
    "    pred_label = np.argmax(softmax_probs)\n",
    "    confidence = softmax_probs[pred_label]\n",
    "\n",
    "    # Handle unknown speakers\n",
    "    if confidence < UNKNOWN_THRESHOLD:\n",
    "        predicted_speaker = \"Unknown\"\n",
    "    else:\n",
    "        predicted_speaker = speakers[pred_label]\n",
    "\n",
    "    print(f\"\\n Predicted Speaker: {predicted_speaker} (Confidence: {confidence:.4f})\")\n",
    "\n",
    "    # Print all confidence scores\n",
    "    print(\"\\n Confidence Scores for Each Speaker:\")\n",
    "    for i, speaker in enumerate(speakers):\n",
    "        print(f\"{speaker}: {softmax_probs[i]:.4f}\")\n",
    "\n",
    "    # Plot confidence scores\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(np.arange(len(speakers)), softmax_probs, color='skyblue')\n",
    "    plt.xticks(np.arange(len(speakers)), speakers, rotation=45)\n",
    "    plt.ylabel(\"Confidence Score\")\n",
    "    plt.xlabel(\"Speakers\")\n",
    "    plt.title(f\"Speaker Prediction Confidence - {predicted_speaker}\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Highlight the predicted speaker\n",
    "    if predicted_speaker != \"Unknown\":\n",
    "        bars[pred_label].set_color('green')  # Change color to green\n",
    "        plt.text(pred_label, softmax_probs[pred_label] + 0.02, f\"{confidence:.2f}\",\n",
    "                 ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "    plt.legend([\"Other Speakers\", \"Predicted Speaker\"], loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "    return predicted_speaker, confidence\n",
    "\n",
    "# Test with an audio file\n",
    "test_audio = \"test17.wav\"\n",
    "predicted_speaker, confidence = predict_speaker_with_confidence(model, classifier, test_audio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b6509f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Recording... Speak Now!\n",
      " Recording saved as realtime.wav\n",
      "\n",
      " Model Output Shape: torch.Size([1, 1, 18])\n",
      "\n",
      " Softmax Probabilities Shape: torch.Size([1, 1, 18])\n",
      " Softmax Probabilities: [[[4.3343312e-05 9.1625243e-01 3.0412972e-03 1.2651942e-02 2.4847861e-04\n",
      "   2.8256897e-02 3.0778408e-06 5.9526943e-04 2.0720916e-02 6.2825568e-03\n",
      "   1.1674721e-03 7.3735132e-03 2.5450918e-04 2.3021084e-05 2.6134080e-03\n",
      "   4.3085284e-04 3.9209437e-05 1.7333737e-06]]]\n",
      " ERROR: Model did not output multiple class scores. Check training setup!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "import time\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio(filename=\"realtime.wav\", duration=5, sr=16000):\n",
    "    print(\" Recording... Speak Now!\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\" Recording saved as\", filename)\n",
    "    \n",
    "    \n",
    "def predict_speaker_realtime(model, classifier, audio_path):\n",
    "    embedding = extract_embeddings(audio_path).unsqueeze(0).to(device)  # Shape: (1, 192)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(embedding)  # Forward pass\n",
    "\n",
    "        # Debugging: Print output shape\n",
    "        print(\"\\n Model Output Shape:\", outputs.shape)\n",
    "\n",
    "        # Ensure softmax is applied to a correct dimension\n",
    "        softmax_probs = torch.nn.functional.softmax(outputs, dim=-1)  # Convert to probabilities\n",
    "        \n",
    "        # Debugging: Check softmax probabilities\n",
    "        print(\"\\n Softmax Probabilities Shape:\", softmax_probs.shape)\n",
    "        print(\" Softmax Probabilities:\", softmax_probs.cpu().numpy())\n",
    "\n",
    "        # Check if we have multiple speaker classes\n",
    "        if softmax_probs.shape[1] < 2:\n",
    "            print(\" ERROR: Model did not output multiple class scores. Check training setup!\")\n",
    "            return \"Unknown\", 0.0  # Return default values if something is wrong\n",
    "\n",
    "        pred_label = torch.argmax(softmax_probs, dim=-1).cpu().item()\n",
    "        confidence = softmax_probs.squeeze(0)[pred_label].cpu().item() * 100\n",
    "\n",
    "    print(f\"\\n Predicted Speaker: **{speakers[pred_label]}** (Confidence: {confidence:.2f}%)\")\n",
    "    return speakers[pred_label], confidence\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Realtime Testing\n",
    "record_audio(\"realtime.wav\", duration=5)  # Record a 5-second audio sample\n",
    "predicted_speaker, confidence = predict_speaker_realtime(model, classifier, \"realtime.wav\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "65f770ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.6289, 10.3493, -1.3503, -3.3429, -2.4368,  3.7588, -3.1506,\n",
      "          -4.0891,  1.2252, -2.7715, -2.2155, -0.9209, -1.7529, -4.5233,\n",
      "           1.8699, -5.4171, -7.1299, -9.8016]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.1258,  12.1999,   0.9666,  -5.2497,  -2.6514,   1.9149,  -3.0376,\n",
      "           -3.2686,   0.6048,  -0.5622,  -3.0170,  -1.5685,  -2.2509,  -4.9379,\n",
      "           -1.6342,  -2.8045,  -4.6630, -11.7208]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.5978,  10.7670,  -1.3824,  -5.6347,  -3.5759,   1.7283,  -3.4667,\n",
      "           -3.5425,  -0.6829,  -1.2344,  -1.0163,  -1.4025,  -1.6508,  -4.8028,\n",
      "           -1.1749,  -2.3372,  -5.2023, -11.0199]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.6036, 10.1484, -0.0540, -4.2667, -4.6962,  1.0581, -4.3301,\n",
      "          -3.6495,  1.5824, -4.5452, -4.5333, -2.6626, -1.9356, -3.8253,\n",
      "           0.2270, -4.2923, -5.8542, -9.9199]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.4324, 11.1330,  0.9212, -3.5512, -3.7715, -0.8422, -3.0537,\n",
      "          -4.7510,  1.1338, -2.6110, -2.8088, -0.1105, -2.1889, -4.6248,\n",
      "           1.7072, -3.1349, -6.7746, -8.1971]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -1.6235,  11.2849,  -1.4478,  -5.1797,  -2.3436,   0.0688,  -1.5321,\n",
      "           -2.5301,   1.2404,  -4.4313,  -4.4103,  -3.6865,  -1.1650,  -3.8630,\n",
      "            0.1985,  -1.8939,  -4.0637, -10.3968]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.1406, 11.7039,  0.9235, -2.9117, -3.5372, -0.9712, -4.5112,\n",
      "          -4.0832,  0.9779, -3.1310, -3.6873,  0.6720, -2.2517, -4.9692,\n",
      "           0.7270, -3.3438, -6.3479, -9.5911]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.8004,  11.6137,   0.9378,  -3.2158,  -3.9919,   0.0439,  -3.9499,\n",
      "           -3.4865,   0.2491,  -3.1517,  -2.5729,  -1.6264,  -1.8388,  -4.1640,\n",
      "           -0.8900,  -2.6083,  -4.2418, -10.1162]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.2468, 11.9367,  0.5683, -4.3857, -3.2777, -0.4513, -2.7648,\n",
      "          -3.2018,  0.9079, -3.3669, -3.7188, -1.1513, -1.5122, -4.4849,\n",
      "          -0.9279, -1.5735, -3.5379, -9.9498]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.5802,  13.2179,   1.3545,  -2.7932,  -3.2287,  -0.9661,  -5.0775,\n",
      "           -4.3016,  -0.5903,  -3.0653,  -1.6652,   0.2882,  -1.9471,  -4.0487,\n",
      "           -1.4845,  -1.1147,  -3.9122, -10.6988]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.4316,  12.9496,   0.9545,  -2.9737,  -4.2833,  -2.8720,  -4.2208,\n",
      "           -4.9763,   0.2028,  -3.8426,  -2.2718,   0.2816,  -2.2990,  -4.3126,\n",
      "           -0.2195,  -0.4250,  -3.8948, -10.0502]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.2067,  10.5612,  -0.0893,  -3.9026,  -3.2732,   0.8887,  -3.2989,\n",
      "           -3.2170,   1.3186,  -1.4813,  -2.9672,  -0.5740,  -2.4384,  -4.5770,\n",
      "           -0.2447,  -3.7155,  -5.7488, -10.3465]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.2366, 11.1542, -0.3956, -3.1876, -2.8319,  1.1918, -1.3711,\n",
      "          -1.4440,  0.4770, -2.6466, -2.7820, -3.1085, -2.4418, -4.0616,\n",
      "          -1.2040, -1.5216, -2.4742, -9.5554]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.9271, 11.2238,  1.0745, -3.7243, -1.2789, -0.2631, -2.7570,\n",
      "          -2.2315,  1.2502, -2.3666, -2.8520, -0.9419, -2.9576, -3.9401,\n",
      "          -0.4196, -1.8411, -3.6584, -8.6852]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.9994,  10.8064,   0.1606,  -4.6654,  -3.7797,   0.4265,  -2.9307,\n",
      "           -2.8426,   1.4729,  -1.0114,  -3.3609,  -0.9486,  -2.3203,  -4.7256,\n",
      "           -0.7761,  -2.5773,  -4.8783, -11.3423]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.9671,  12.3665,   1.5603,  -4.4647,  -4.7595,  -0.9223,  -4.7701,\n",
      "           -4.1134,   1.6773,  -3.5077,  -3.3516,  -0.2799,  -3.4545,  -4.4099,\n",
      "            0.1516,  -3.2565,  -5.9281, -11.1675]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.2712, 12.7959,  1.2112, -4.1941, -3.1174, -1.7808, -3.1061,\n",
      "          -3.7620,  1.5918, -3.6681, -1.8548, -2.3506, -3.8486, -4.1365,\n",
      "          -0.3843, -3.3499, -5.6376, -9.3933]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.4752,  12.9484,   0.9113,  -3.9135,  -4.6980,  -0.1662,  -2.9940,\n",
      "           -4.0214,   1.8959,  -1.7408,  -2.1755,  -1.8186,  -3.7416,  -4.2916,\n",
      "           -1.2469,  -3.5244,  -5.5986, -11.8076]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.9969,  12.9028,   0.5606,  -4.6296,  -4.9521,  -1.3877,  -2.9703,\n",
      "           -3.8591,   0.9386,  -2.1402,  -2.5013,   0.9785,  -2.5389,  -3.4573,\n",
      "           -0.7706,  -2.3133,  -5.0828, -12.1961]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.3178,  13.8827,   0.0197,  -4.7148,  -3.7280,   0.2831,  -3.0803,\n",
      "           -2.8189,   1.2940,  -5.0132,  -2.6206,  -2.5917,  -2.4823,  -3.1419,\n",
      "           -1.2357,  -3.5550,  -4.6393, -11.3107]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.1776,  11.6797,   0.5654,  -3.2481,  -3.8816,   0.2921,  -4.5814,\n",
      "           -2.7633,   0.8284,  -3.6965,  -4.4282,  -0.4318,  -1.7874,  -4.0072,\n",
      "           -1.9711,  -2.8084,  -3.9587, -10.2052]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.3719,  12.5882,   0.6557,  -4.5785,  -4.5084,   0.2235,  -5.5377,\n",
      "           -4.3016,  -0.0970,  -3.4162,  -5.3199,   1.0348,  -1.8501,  -3.7340,\n",
      "           -0.0972,  -1.6079,  -4.3816, -11.0219]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.0963,  12.7235,   0.3192,  -6.7954,  -3.4304,  -2.1390,  -2.3846,\n",
      "           -4.5679,   2.8399,  -0.9166,  -2.9830,   0.6951,  -3.2357,  -5.0578,\n",
      "           -0.2611,  -3.0872,  -7.1454, -12.5816]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.5851,  13.3909,   0.4812,  -4.2350,  -3.8421,  -0.5062,  -3.8473,\n",
      "           -3.6042,   0.1289,  -3.0413,  -2.6161,  -0.4204,  -2.5150,  -3.5237,\n",
      "           -1.1381,  -1.5934,  -4.1399, -11.0326]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.3292,  11.2688,   2.2184,  -3.4563,  -4.9014,  -1.6786,  -5.5543,\n",
      "           -3.7436,   1.0273,  -1.8269,  -3.2717,   1.0610,  -2.7265,  -4.7321,\n",
      "           -1.8379,  -2.5933,  -4.0849, -10.7599]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.7797,  14.0416,   0.5063,  -5.4480,  -3.9690,  -0.5349,  -3.7904,\n",
      "           -4.1957,   0.8430,  -2.9848,  -3.7392,  -0.5073,  -2.9021,  -3.7504,\n",
      "           -0.9355,  -2.0863,  -4.7882, -12.2423]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.9729, 10.8970,  1.2728, -5.9907, -3.4746, -1.7556, -2.1225,\n",
      "          -4.5660,  1.4773, -1.8394, -0.4059, -0.9680, -2.3866, -3.2915,\n",
      "           0.5315, -2.2832, -4.7931, -8.4627]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.2649,  12.9978,   1.2749,  -4.2059,  -3.4940,  -2.4616,  -3.3497,\n",
      "           -3.8867,   1.0846,  -2.8677,  -1.6748,  -0.2163,  -4.1871,  -2.8614,\n",
      "            0.1592,  -1.8502,  -5.9923, -12.0942]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.9146,  14.3031,   1.2799,  -6.4439,  -3.6052,  -1.4524,  -2.6190,\n",
      "           -3.5133,   2.3483,  -3.9086,  -4.9127,  -1.3849,  -4.1455,  -4.9495,\n",
      "           -0.1230,  -3.2681,  -5.8459, -10.9982]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.4875,  12.6823,  -0.2371,  -5.1731,  -2.3263,   2.7013,  -2.9171,\n",
      "           -3.8804,  -0.4431,  -0.4277,  -2.6128,  -0.5787,  -1.7447,  -4.7266,\n",
      "           -0.4961,  -2.0830,  -4.4617, -11.7675]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.4421,  12.7675,   0.3272,  -4.9803,  -3.4553,   3.2451,  -3.3980,\n",
      "           -3.2536,   0.8987,  -2.3852,  -2.1238,  -2.2583,  -3.5861,  -3.9361,\n",
      "           -0.6380,  -4.7124,  -7.6663, -12.1483]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.1637,  12.2122,  -0.8520,  -5.9373,  -2.6317,   1.1177,  -1.9890,\n",
      "           -2.0130,   0.4940,  -3.5344,  -2.9382,  -2.1049,  -2.2722,  -4.5940,\n",
      "            0.8353,  -1.8268,  -5.8874, -10.6081]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.0155,  13.6515,   0.6119,  -6.3658,  -2.5490,   2.9063,  -4.9170,\n",
      "           -5.1714,  -0.4978,  -1.3628,  -4.7344,   0.4903,  -2.0449,  -4.9974,\n",
      "            0.2831,  -2.5478,  -5.8210, -12.8049]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.4319,  12.5067,   0.4925,  -5.6932,  -3.7451,   2.4348,  -4.7306,\n",
      "           -6.5225,  -0.6672,  -1.9563,  -2.3382,  -0.3865,  -1.8762,  -5.3381,\n",
      "            1.0860,  -2.5327,  -6.6131, -11.0882]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.2004,  13.0246,   0.6304,  -5.5585,  -3.2165,   2.7729,  -5.1043,\n",
      "           -4.6372,  -0.4008,  -1.4968,  -4.3056,  -0.7485,  -2.3760,  -6.3873,\n",
      "            0.4016,  -1.5755,  -6.1721, -12.3766]]])\n",
      "Predicted Label Index: 1\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.6355, -1.1027,  8.4498, -4.1329,  0.1410, -3.8600, -7.2504,\n",
      "          -2.7789, -2.5970, -1.1915,  0.0827, -0.3441, -1.7452, -0.4026,\n",
      "          -3.5469,  0.8964, -0.4391, -0.4641]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.6046, -0.8760, 10.5198, -4.1552, -0.7886, -0.2788, -3.4837,\n",
      "           0.6508, -2.2818,  0.1063, -1.6779, -3.8919, -1.9007, -0.9578,\n",
      "          -4.0076, -1.7388,  0.1304, -1.3853]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.0943, -0.4990, 11.9709, -6.8928, -2.7312, -0.2839, -4.7180,\n",
      "          -2.6202, -1.9272,  0.4534,  0.1449, -3.1224, -3.6962, -0.8100,\n",
      "          -1.3222, -2.3081, -0.9583, -2.1242]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.6208, -0.0689,  9.7411, -3.3939, -1.7493, -0.6633, -5.6796,\n",
      "           0.6161, -0.9321, -1.0021, -1.1060, -1.6531, -2.3794,  1.5885,\n",
      "          -6.1450, -2.7825,  0.3080, -3.5272]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.6236, -0.1934, 12.5386, -4.3687, -4.1893, -2.4402, -7.2811,\n",
      "          -2.3914, -2.2348,  1.2678, -1.1425, -2.3803, -3.8705, -1.6034,\n",
      "          -2.6379,  0.7248,  0.2281, -3.4571]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.2628, -2.0217, 11.7873, -4.8005, -3.5565, -4.1041, -2.5896,\n",
      "          -2.8932, -1.1644,  1.0986, -1.5676, -3.1639, -4.1829, -3.0974,\n",
      "           0.3911, -0.3668,  0.2502,  0.0331]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.9768, -1.0637, 10.4261, -5.4999, -3.0742, -3.1888, -3.4498,\n",
      "          -2.4758, -1.2255,  0.0984, -0.9838, -3.4413, -1.7509, -0.8701,\n",
      "          -2.7986, -1.8481,  0.6810, -1.8875]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.5490,  0.1487, 13.3699, -5.3937, -0.3450, -2.0641, -5.7196,\n",
      "          -3.2543, -1.2124,  1.9617, -1.0532, -5.4501, -5.2184, -3.4990,\n",
      "          -2.0022, -2.5729,  1.9351, -4.3871]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.1564,  -1.4692,  14.2665,  -7.5160,  -5.0217,  -1.7856,  -3.7887,\n",
      "           -2.9104,  -1.8939,  -0.1864,  -2.2441,  -4.1679,  -2.3551,  -2.5418,\n",
      "           -2.1882,  -1.9674,   1.0590,  -0.9763]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.8704, -1.4291, 16.2178, -8.0360, -4.3886, -2.4552, -5.4835,\n",
      "          -3.3148, -2.3512, -1.6927, -2.5806, -5.6035, -2.8415, -1.9513,\n",
      "          -2.6446, -3.4492, -0.8032,  0.4807]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.6083, -2.9832, 12.0841, -6.1122, -3.8608, -4.5407, -3.3802,\n",
      "          -0.3670, -2.0785,  0.1579,  0.6963, -5.0706, -3.9500, -2.0970,\n",
      "          -1.2871,  2.0737,  2.0298, -1.7941]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.4082, -1.0362, 10.6264, -3.4065, -3.6336, -3.5718, -7.9376,\n",
      "          -2.6900, -3.7440, -1.5779, -3.6458, -3.2930, -0.8606, -1.3844,\n",
      "          -3.5915, -0.0454,  1.0115, -2.1481]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.0027, -1.8829, 13.0213, -5.9129, -5.2023, -5.5234, -6.0475,\n",
      "          -3.6582, -2.8310, -1.4731, -2.4905, -6.5361, -3.8879, -3.5586,\n",
      "          -2.2898,  2.5192,  1.7957,  0.2264]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.1150, -1.2753, 11.0261, -5.8158, -1.8057, -2.4153, -3.2096,\n",
      "          -1.2517, -2.2559,  0.1635, -0.4817, -3.3414, -0.9063, -0.2919,\n",
      "          -3.6682, -2.6601,  0.7788, -2.3121]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.7857, -1.1700, 12.4518, -4.5276, -2.3455, -2.4646, -2.4820,\n",
      "          -1.1027, -0.6245,  1.3147, -1.4252, -3.7910, -2.7644, -0.6052,\n",
      "          -3.3916, -3.4780,  2.0692, -1.5468]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.7402, -2.2537, 12.1501, -7.7299, -3.0940, -4.5078, -1.7933,\n",
      "          -1.6651, -1.7287, -0.0384, -0.7881, -4.5012, -2.5396, -3.2823,\n",
      "          -2.4236, -1.2283, -0.1383, -2.3005]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.3912, -1.3711, 10.4866, -3.0889, -4.6426, -2.1680, -8.7684,\n",
      "          -3.3447, -4.5058, -3.5922, -3.2679, -4.4025, -0.4951,  2.6124,\n",
      "          -6.5392, -1.7459,  1.5773, -0.1645]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.5025,  0.0210, 11.0853, -5.4674, -2.6481, -3.0667, -2.2607,\n",
      "          -0.8400, -0.7779,  1.3686, -3.4550, -2.4401, -1.7644, -3.7227,\n",
      "          -1.5990, -1.3437,  1.5149, -2.9801]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.8051,  0.0650, 11.9064, -5.9335, -3.7686, -2.9719, -6.0770,\n",
      "          -3.9389, -2.8810, -0.5754, -3.7844, -4.1610, -1.4112, -3.2699,\n",
      "          -3.1394, -1.6828,  1.8631, -2.3423]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.8454, -1.4179, 13.2924, -6.0638, -3.4940, -1.3259, -7.7596,\n",
      "          -3.7346, -3.6688, -1.8542, -2.3015, -5.1107, -1.8936, -0.1788,\n",
      "          -4.1756, -1.9512,  3.1649, -0.3721]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.4903,  0.4000, 13.3334, -6.0283, -4.4036, -3.0687, -4.2280,\n",
      "          -2.3744, -1.7231,  0.2270, -3.3357, -4.2434, -3.5603, -3.4635,\n",
      "          -3.6016,  0.1252,  2.7342, -5.4318]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.0318, -0.5454, 12.0967, -5.8627, -2.1499, -2.7960, -1.9635,\n",
      "          -3.3464, -0.2256,  2.4451, -2.2667, -3.5634, -4.3553, -3.8461,\n",
      "          -0.8336, -1.9388,  0.7783, -3.5417]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.5461, -1.7058, 11.6309, -5.7182, -5.2434, -2.7994, -5.9813,\n",
      "          -1.9394, -2.9375, -2.9843, -4.1462, -4.6536, -0.6186, -0.5240,\n",
      "          -6.0870, -1.9805,  1.1333, -1.3052]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.1689, -0.7576, 14.3811, -6.2244, -2.9917, -3.6184, -6.3120,\n",
      "          -5.3671, -2.8535,  0.9832, -2.3827, -2.5314, -3.0957, -3.4914,\n",
      "          -1.3777,  0.1606,  2.0445, -1.7748]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.6065, -1.0284, 12.0461, -5.5930, -3.1278, -3.7691, -2.2968,\n",
      "          -3.0208, -1.1372,  0.8710, -1.5629, -3.3928, -4.5575, -1.8015,\n",
      "           1.1437, -1.2595, -0.9798, -0.4310]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.6930,  0.4117, 14.6062, -7.3424, -3.7160, -2.0690, -3.8710,\n",
      "          -2.9554, -1.7660,  0.4963, -1.9280, -2.8580, -4.3722, -1.8521,\n",
      "          -2.3847, -2.1606, -1.1231, -1.0086]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.8247, -1.2660, 13.7530, -8.6727, -3.1890, -1.7363, -1.8393,\n",
      "          -1.5297, -1.0549, -1.0313, -0.6644, -5.6340, -4.6091, -0.7045,\n",
      "          -2.4955, -3.9914, -2.5716, -0.5205]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.5765, -1.2062, 13.9158, -9.0667, -4.4985, -3.8584, -0.0850,\n",
      "          -4.2095, -1.6147,  1.4595, -2.2063, -4.4857, -1.2981, -4.0670,\n",
      "          -4.9062, -3.6454,  1.8535, -1.7611]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.5690,  1.2872, 13.9814, -7.3267, -4.7009, -3.3207, -3.6179,\n",
      "          -3.5043, -2.1913,  0.8783, -3.4057, -1.7174, -2.8451, -3.2771,\n",
      "          -5.7342, -1.8437,  1.1414, -3.1431]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.6816,  0.6268, 12.2132, -7.9641, -3.2498, -3.1176, -2.8011,\n",
      "          -2.8522, -1.1325, -0.3455, -1.0171, -1.8415, -2.6638, -1.4423,\n",
      "          -2.0446, -3.1259, -4.4894, -1.8146]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.5989,  -1.6361,  13.8445,  -8.7678,  -6.0950,  -2.1546,  -3.3807,\n",
      "           -5.7080,  -0.7225,   1.2427,  -1.1063,  -2.2720,  -5.1037,  -0.6579,\n",
      "           -0.9192,  -5.7731,  -3.7108,  -1.6139]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.5394,  1.1807, 12.8044, -3.4784, -3.6843, -1.0458, -7.6741,\n",
      "          -2.8534, -2.7668, -0.9638, -3.3087, -1.1762, -2.4808,  0.7166,\n",
      "          -3.4710, -1.7763,  0.9398, -4.2995]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.0930, -2.4819, 13.1722, -5.8901, -4.5601, -3.9523, -4.7398,\n",
      "          -3.3216, -3.0281, -1.6472, -2.4147, -4.6757, -0.4282, -1.4826,\n",
      "          -5.3627, -2.0136,  2.1365,  0.6230]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.0860, -1.3943, 11.4862, -3.2992, -5.6666, -3.1595, -8.2245,\n",
      "          -4.9835, -2.8948, -0.9242, -4.6760, -3.1092, -3.3191, -1.1943,\n",
      "          -2.1003,  2.6470,  0.7217, -0.8118]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.4172, -1.8370, 14.5176, -7.2889, -5.0054, -2.9674, -3.8708,\n",
      "          -4.1677, -2.0105, -0.2123, -1.8224, -3.5467, -3.2967, -3.1973,\n",
      "          -1.9704, -0.8966,  2.1941, -0.4044]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.7559, -1.5240, 14.0486, -6.8103, -1.5026, -1.6192, -5.6462,\n",
      "          -3.8182, -2.9579, -0.9208, -2.0616, -5.0441, -1.7021, -0.8352,\n",
      "          -4.7568, -4.7184,  2.7008, -0.5962]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.6127, -1.3415, 13.9506, -7.4416, -2.3855, -1.0619, -4.4131,\n",
      "          -3.6376, -3.0196,  1.0299, -0.6699, -3.8339, -1.7816, -1.9554,\n",
      "          -3.0493, -3.8173,  0.7441, -0.9413]]])\n",
      "Predicted Label Index: 2\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.2735,  -4.5327,  -6.3374,  12.7525,  -0.7987,   1.0738,  -9.4011,\n",
      "           -3.4586,   1.0701,  -2.3468,   4.7494,   1.0715,  -3.1335,  -2.7711,\n",
      "            1.9931,  -1.3675,  -6.2056,  -1.6441]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.3121,  -3.2757,  -5.9858,  13.2599,  -4.0620,   1.8741,  -6.5795,\n",
      "           -1.8045,   0.8360,  -2.2183,   2.2476,   2.6287,  -1.4653,  -2.7284,\n",
      "           -0.6816,  -2.5096,  -4.4919,  -3.2052]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.1908e+01, -3.7271e+00, -6.0543e+00,  1.2553e+01, -3.4260e+00,\n",
      "           1.7074e-01, -5.9074e+00, -1.0351e+00, -6.7687e-05, -3.8648e+00,\n",
      "           1.5015e+00,  1.8542e+00, -1.2729e+00, -2.1227e+00,  1.0932e+00,\n",
      "          -1.1172e+00, -3.6651e+00, -2.7522e+00]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-14.5447,  -6.9271,  -8.3833,  15.6757,  -2.5115,   1.7503,  -7.7117,\n",
      "           -1.5344,   0.8000,  -2.2862,   4.3920,   0.5535,  -1.3475,  -5.4158,\n",
      "           -0.2020,  -1.1645,  -4.6919,  -1.4019]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.9377,  -2.5631,  -6.0919,  12.7036,  -5.2753,   0.1305,  -7.6952,\n",
      "           -0.6596,   0.4975,  -4.0241,   2.2462,   2.0353,  -1.9242,  -1.8800,\n",
      "            0.2374,  -3.4331,  -6.3054,  -5.3413]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-14.2749,  -3.3501,  -5.4798,  13.1130,  -3.7372,   3.2731,  -7.5808,\n",
      "           -1.3666,   1.5623,  -0.1765,   1.0694,   2.5013,  -2.0403,  -3.7981,\n",
      "           -2.5886,  -2.7740,  -4.6484,  -4.8512]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.4710, -4.3770, -6.5182, 12.3095, -4.2201,  0.4311, -6.0323,\n",
      "          -1.1377,  2.0875, -2.0446,  1.1306, -1.3181, -2.0283, -3.7887,\n",
      "          -1.9057, -1.4996, -3.6340, -2.1468]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.5693,  -2.6787,  -6.2734,  13.5836,  -2.8569,   2.9104,  -6.7289,\n",
      "           -1.1767,   1.5403,  -1.4049,   2.1165,   1.3303,  -0.9883,  -3.8196,\n",
      "           -0.3474,  -2.7938,  -5.1745,  -3.7065]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.2224,  -3.3101,  -8.3183,  13.5002,  -5.7072,   0.9161,  -6.5077,\n",
      "           -2.6082,   1.1908,  -2.4987,  -0.6490,   3.3931,  -2.7513,  -4.6401,\n",
      "            0.0950,  -3.9239,  -6.9920,  -5.8889]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.0432,  -3.2281,  -7.1536,  11.9413,  -3.6148,   0.9897,  -5.5042,\n",
      "           -1.2285,   1.4017,  -5.6659,   0.9201,  -0.5667,  -1.4463,  -0.9026,\n",
      "           -0.6498,  -2.1294,  -3.9585,  -2.5479]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.8784,  -3.6630,  -6.4216,  14.9471,  -3.9605,   1.1654,  -7.7194,\n",
      "           -1.0713,   0.0988,  -2.7203,   2.9730,   2.8823,  -1.3435,  -2.7730,\n",
      "            0.2616,  -1.9782,  -5.3277,  -3.9900]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.6647,  -4.1556,  -5.5944,  13.3600,  -3.5216,   1.5226,  -7.7598,\n",
      "           -0.9172,   1.1365,  -1.8188,   0.8996,   0.5551,  -2.4318,  -2.7475,\n",
      "            0.0395,  -1.3096,  -3.8463,  -3.7464]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.9380,  -4.1227,  -6.6593,  14.1587,  -3.3208,   1.0291,  -6.9605,\n",
      "           -0.0537,   0.8046,  -3.3166,   3.7083,   0.9692,  -2.0424,  -2.6331,\n",
      "            0.3013,  -2.0149,  -5.6692,  -3.7097]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-14.2229,  -3.2149,  -6.0888,  14.3309,  -2.8545,  -0.1118,  -6.6097,\n",
      "           -3.0783,  -0.8020,  -2.8890,   3.3979,   2.6508,  -0.8443,  -3.2990,\n",
      "            0.9851,  -1.2789,  -3.5774,  -2.2842]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.6980,  -4.3465,  -7.5162,  14.6723,  -4.0806,   1.2797,  -7.9191,\n",
      "           -2.0338,   0.9625,  -4.2526,   2.7424,   2.3051,  -1.6956,  -1.5144,\n",
      "           -0.9780,  -3.0496,  -5.3480,  -3.0058]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-14.2727,  -4.0046,  -6.3048,  13.5785,  -3.6661,   1.5594,  -6.8719,\n",
      "           -2.7607,   0.8152,  -1.9260,   2.4394,   2.5765,  -1.2499,  -2.7936,\n",
      "           -0.3383,  -3.1546,  -4.4298,  -3.5736]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.7698,  -1.4464,  -4.6393,  13.0798,  -1.8738,   1.0046,  -5.7833,\n",
      "           -1.0126,   0.1625,  -2.0995,   1.7371,   2.3753,  -1.8049,  -4.2302,\n",
      "            3.0982,  -2.0919,  -5.3790,  -3.5870]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-14.1406,  -7.2098,  -6.7830,  14.9056,  -4.2516,   0.4798,  -8.9660,\n",
      "           -1.6912,   0.1363,  -2.7480,   2.5781,   1.1233,  -1.2744,  -3.0433,\n",
      "           -0.4627,  -1.4699,  -3.8392,  -1.4884]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.3309e+01, -3.3274e+00, -6.7867e+00,  1.4509e+01, -4.3352e+00,\n",
      "          -5.8739e-01, -6.4454e+00, -1.1123e+00,  4.2332e-01, -3.4874e+00,\n",
      "           1.9315e+00,  2.9199e+00, -1.7527e+00, -2.9452e+00, -2.0410e-03,\n",
      "          -2.8039e+00, -6.1205e+00, -3.0132e+00]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.6767,  -3.6828,  -5.1633,  13.4829,  -3.7887,   1.2589,  -7.6835,\n",
      "           -1.3277,   0.7021,  -2.1498,   1.6660,   1.5224,  -1.9069,  -3.8967,\n",
      "            0.8496,  -3.0099,  -5.4563,  -2.7647]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.2847,  -3.0687,  -7.1356,  13.7285,  -4.0990,   0.9153,  -7.1715,\n",
      "            0.0211,   0.9690,  -4.9478,  -0.5035,   2.6098,  -0.8827,  -1.3937,\n",
      "           -0.9690,  -2.9074,  -4.8054,  -4.2377]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.2116,  -7.2295,  -7.2164,  12.3302,  -4.0444,   1.6641,  -7.0829,\n",
      "           -2.5071,   0.8130,  -1.0312,   1.8090,   1.0929,  -2.3873,  -3.3847,\n",
      "           -0.2351,  -2.4792,  -4.1757,  -3.0857]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-14.5845,  -3.0821,  -5.3318,  14.3976,  -3.0555,   1.8537,  -8.6169,\n",
      "           -1.0651,  -0.2871,  -1.0131,   3.7736,   1.9671,  -1.6083,  -4.2281,\n",
      "           -0.0877,  -1.9516,  -3.1458,  -4.4617]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.1532,  -6.6378,  -5.0578,  12.4966,  -1.9507,  -1.6710,  -6.0303,\n",
      "           -0.8871,   1.4795,  -1.0312,   1.6660,   0.0304,  -2.3960,  -5.1556,\n",
      "            0.5585,  -0.3384,  -1.6794,   0.1185]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.8662,  -5.8895,  -7.2816,  14.3414,  -4.6606,  -0.4029,  -8.6445,\n",
      "           -1.9328,   1.8854,  -3.2350,   1.1215,   2.1026,  -2.6177,  -2.5791,\n",
      "           -0.5195,  -2.2096,  -5.3409,  -2.2588]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-14.6070,  -3.2845,  -6.9555,  14.3860,  -3.8508,   3.3200,  -7.5919,\n",
      "           -1.2524,   0.5389,  -2.9236,   1.9343,   0.8841,  -1.2740,  -3.9452,\n",
      "           -1.2120,  -1.8352,  -3.7739,  -3.4289]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.2859,  -3.6642,  -7.1462,  12.3948,  -5.2387,   0.9471,  -6.1616,\n",
      "           -2.1965,   2.3140,  -3.4786,  -0.2244,   3.1126,  -2.3565,  -2.0760,\n",
      "           -0.7928,  -4.5643,  -6.7905,  -4.2971]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.8045,  -1.1320,  -5.3019,  10.0622,  -4.0397,   1.3764,  -3.5218,\n",
      "           -0.6889,  -0.4338,   0.7949,   2.8940,   1.0169,  -1.8414,  -3.9328,\n",
      "           -0.7226,  -0.5660,  -3.4588,  -6.3706]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.9248,  -3.3283,  -6.0547,  11.8391,  -4.5697,  -0.5523,  -5.5876,\n",
      "           -1.3865,   1.4871,  -3.0535,   1.4859,   2.0078,  -1.9961,  -1.3329,\n",
      "           -0.3091,  -1.7612,  -4.6866,  -3.8648]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.4994,  -3.4048,  -6.4458,  12.7643,  -4.6017,  -0.9624,  -6.9706,\n",
      "           -0.1302,   2.1745,  -3.5675,  -0.0917,   2.9634,  -3.0246,  -2.8237,\n",
      "            0.2810,  -3.2731,  -7.1095,  -5.0774]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.5482,  -4.0175,  -9.0431,  13.5017,  -5.9381,  -1.3149,  -7.2413,\n",
      "           -1.8334,   1.1772,  -2.1374,  -0.3626,   4.7377,  -2.0835,  -4.4600,\n",
      "           -1.7892,  -2.8407,  -5.5011,  -6.7074]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.8776,  -3.8819,  -7.1401,  12.0141,  -3.5713,  -1.0510,  -6.8752,\n",
      "           -1.2625,   0.6927,  -4.1921,   0.9404,   3.4077,  -2.1428,  -2.7120,\n",
      "           -0.1309,  -2.1204,  -5.7735,  -3.1423]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.8085,  -3.1693,  -6.4590,  11.1142,  -4.0621,  -0.6329,  -6.3949,\n",
      "           -3.1298,   1.7811,  -0.7012,   2.0123,   3.5291,  -2.7369,  -3.5287,\n",
      "           -1.4113,  -2.4307,  -6.9024,  -4.5571]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.4262,  -3.0164,  -4.8770,  12.5616,  -3.4973,   0.4859,  -6.4201,\n",
      "           -0.1310,   1.6240,  -2.9660,   0.0767,   1.5338,  -2.1925,  -1.4956,\n",
      "            0.2565,  -1.3002,  -3.8386,  -3.7690]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.7726,  -4.3318,  -6.1603,  13.2230,  -3.7747,   1.2239,  -9.0374,\n",
      "           -1.9045,   0.1119,  -2.0175,   2.2248,   2.7505,  -1.8379,  -2.3850,\n",
      "           -0.6191,  -1.8671,  -4.3265,  -4.0247]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.9835,  -3.8038,  -5.1089,  11.8446,  -4.4184,   0.0962,  -4.9012,\n",
      "           -2.0708,   1.0008,  -0.6973,   1.7118,  -0.8790,  -1.5687,  -4.8289,\n",
      "           -0.3094,  -0.6363,  -2.6981,  -3.1639]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.2042e+01, -3.9864e+00, -6.0389e+00,  1.1456e+01, -4.8733e+00,\n",
      "           2.1311e+00, -6.5562e+00, -3.8571e+00,  2.1438e+00,  5.4171e-03,\n",
      "           2.2570e+00,  2.9764e+00, -1.9530e+00, -3.2636e+00, -1.7676e+00,\n",
      "          -5.0089e+00, -6.1862e+00, -4.9664e+00]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-14.0638,  -3.1039,  -6.0751,  15.1702,  -2.6154,   0.7757,  -5.8855,\n",
      "           -2.5203,   0.4115,  -2.0772,   3.6267,   1.6086,  -2.1482,  -4.0952,\n",
      "            1.5982,  -0.7267,  -3.8841,  -2.0113]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.5467,  -3.1517,  -6.4983,  13.2497,  -3.5396,  -0.5322,  -6.5595,\n",
      "           -3.9272,   1.5153,  -0.8942,   3.0176,   3.1548,  -1.5792,  -4.4404,\n",
      "           -0.2426,  -4.2302,  -5.7449,  -4.5812]]])\n",
      "Predicted Label Index: 3\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.7440,  -0.7105,  -1.0652,  -0.8807,  16.6996,  -1.5189, -10.2034,\n",
      "           -2.0332,  -3.1768,  -1.0646,   0.7779,  -1.2487,  -1.7131,  -5.5110,\n",
      "           -1.0522,  -0.5571,  -2.4065,   3.6475]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.5005,  0.5910,  0.0547, -6.4121, 11.0568, -3.1784, -7.2789,\n",
      "          -1.5986, -0.0114, -4.4945, -0.6409, -6.0587, -2.4572, -4.1856,\n",
      "          -3.5522, -0.7319, -1.0384,  1.2098]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.5929,  1.8119,  1.2563, -2.6498, 17.1964,  1.2931, -9.9618,\n",
      "          -2.1605, -4.4097, -1.0407,  0.9440, -0.8564, -1.2722, -3.5319,\n",
      "          -1.4050, -0.1795, -0.0914,  0.7712]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.6008,   2.6067,  -0.2077,  -2.5717,  19.5180,   2.0745, -11.4082,\n",
      "           -3.2065,  -5.0672,  -0.2201,   4.5002,  -1.4383,  -0.5070,  -5.4896,\n",
      "           -0.6181,   0.2525,  -2.0814,   1.2771]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.5688,  0.0536, -0.1816, -3.1781, 15.1613, -2.1219, -5.6226,\n",
      "           0.2648, -0.1048,  0.7600,  0.8945, -4.3458, -2.9534, -3.3440,\n",
      "          -6.6219, -3.3666, -0.4687, -2.2912]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.4592, -2.8689, -1.9897, -0.2385, 11.3762,  0.2205, -4.2240,\n",
      "           0.1617, -2.7608, -0.0152, -0.5235, -2.5426, -0.1717, -2.1296,\n",
      "          -1.5057,  0.1579, -0.6131, -0.9332]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.1102e+00, -2.7746e-01, -8.9985e-01, -3.9946e-02,  1.2832e+01,\n",
      "          -1.6505e+00, -7.7324e+00,  1.3309e+00, -1.6906e+00, -1.8064e+00,\n",
      "           1.0173e+00, -1.8851e+00, -1.7873e+00, -3.9580e+00,  5.6894e-02,\n",
      "          -3.9910e-03, -1.8755e+00, -1.6932e+00]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.8694, -1.8004,  0.1623, -2.1438, 11.7835,  0.2017, -8.1179,\n",
      "          -3.2366, -0.5540, -1.4605,  2.7429, -1.7658, -1.1772, -3.6409,\n",
      "           0.1939, -3.3155, -3.8689,  1.7422]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.6049, -1.6136, -1.7840, -1.6295,  9.7183, -0.2117, -4.1800,\n",
      "           2.1329, -1.2497, -1.8166,  0.2043, -3.0726, -1.5234, -1.0138,\n",
      "          -0.3294, -0.8325, -2.2887, -2.3894]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.6815,  1.3329, -2.1259, -2.8655, 14.6359, -2.2579, -5.8141,\n",
      "          -0.3509, -2.7622, -4.0454, -0.9616, -3.2689, -1.1812, -2.2294,\n",
      "           0.7612, -1.3840, -2.9645, -2.2723]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.2470, -0.5661, -1.8538, -1.5266, 13.2965,  0.5992, -8.9354,\n",
      "          -1.1647, -1.5997, -2.0144,  1.2603, -0.0194, -0.7092, -4.4404,\n",
      "           0.2217, -3.2107, -4.2946,  0.2073]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.7380,  3.0954, -4.7771, -7.1511, 14.1514, -2.7207, -4.1202,\n",
      "           2.8135, -3.4929, -7.5956,  0.7563, -8.7786,  1.3807, -3.0169,\n",
      "          -2.1526, -0.8317,  0.9065,  0.3676]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.7843,  1.1320,  0.0603, -2.2144, 14.3217, -1.6083, -8.3167,\n",
      "          -0.2936, -2.5829, -1.9511,  2.3301, -2.1774, -2.8869, -3.2819,\n",
      "           0.3015, -0.4838, -2.6741, -0.2039]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.7316, -1.2840, -2.7506, -0.3962, 15.3392, -3.5080, -8.9496,\n",
      "          -1.2890, -5.3792, -4.4027, -2.6420, -1.5656, -0.0988, -4.6762,\n",
      "           0.1769,  3.0339, -0.3276,  0.3691]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.6837,   2.1574,  -1.5263,  -1.0564,  17.4494,   2.0759, -10.0916,\n",
      "           -0.2523,  -4.1972,  -0.9793,   3.9443,  -0.6584,  -1.8227,  -2.5562,\n",
      "            2.2045,  -0.7877,  -5.4732,   0.1644]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.8058,   0.5337,  -1.4877,  -2.0500,  12.4428,  -1.8069, -10.5342,\n",
      "            0.3799,  -4.8927,  -5.8006,  -1.1263,  -4.4315,  -0.7423,   0.7185,\n",
      "           -3.1037,  -1.0327,  -0.1325,  -1.9439]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.9802, -0.8129,  0.4812, -0.8003,  9.9775, -0.9175, -6.4552,\n",
      "           0.9882, -1.2830, -1.3395, -2.1336, -2.9044, -0.0999, -2.3751,\n",
      "          -3.9467, -1.0848, -0.2338, -2.7130]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.3730,   0.7751,   1.1353,  -1.3006,  13.7481,  -0.7835, -10.9915,\n",
      "           -2.2068,  -3.3720,  -2.0043,  -1.1935,  -3.1233,  -2.4981,  -3.8021,\n",
      "           -2.5101,  -0.2997,  -2.1125,  -0.5591]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.4702e+00, -5.9962e-02, -1.4670e+00, -1.0312e-03,  1.2445e+01,\n",
      "          -2.1319e+00, -7.6991e+00,  9.3048e-01, -3.0488e+00, -2.4977e+00,\n",
      "           1.4178e+00, -1.6035e+00, -1.0299e+00, -4.3258e+00, -2.2680e-01,\n",
      "           1.5869e+00, -7.0945e-01, -2.5377e+00]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.7258,  4.1920,  0.1439, -1.7987, 13.3676,  3.4661, -9.3892,\n",
      "           0.2536, -3.6525, -1.8776,  1.9314,  1.1362, -1.9019, -1.3448,\n",
      "           1.3968, -2.4747, -2.3922, -1.9179]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.4341,  -4.2926,  -1.6437,   1.4663,  13.5692,  -5.0347, -11.3381,\n",
      "            3.9520,  -0.2664,  -4.8803,   0.8938,  -6.9382,  -7.5920,  -2.5534,\n",
      "           -2.4418,  -2.2168,  -2.1338,  -0.7195]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.5984,   2.3263,   0.3172,  -1.1928,  13.5013,  -4.7348, -11.0497,\n",
      "            3.0032,  -1.8186,  -5.7431,  -1.4431,  -3.2706,  -5.4149,  -3.3428,\n",
      "            2.2832,   0.0934,  -0.4142,  -0.2141]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.7289,  0.1674, -2.6350,  0.4512, 14.6223, -1.7150, -9.6883,\n",
      "          -0.6033, -1.9191, -3.4855,  0.8312, -0.5081, -2.6611, -3.2026,\n",
      "          -0.7186, -0.7630, -1.2904,  0.8173]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.4068, -0.6108, -1.6712, -3.7570,  8.7262, -3.3647, -5.4241,\n",
      "          -5.1488, -2.0845, -3.7702, -2.1699, -1.2794, -0.2835, -1.2743,\n",
      "          -0.5615, -2.2755, -2.0929, -2.6794]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.6951,  2.4873, -0.4910, -1.3027, 14.2535,  0.0329, -8.3743,\n",
      "           0.6782, -0.8667, -2.8639,  2.3275, -0.0843, -2.0390, -3.0657,\n",
      "          -1.3838, -2.6685, -5.1843, -1.4394]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-0.3254, -4.6448, -4.5687, -2.9040, 13.0284, -2.9249, -3.5146,\n",
      "           1.6064, -1.7170, -2.8272, -1.0671, -6.8278,  0.5148, -1.4045,\n",
      "          -5.0462, -3.2081, -1.7998, -2.1859]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.4902,   5.0038,  -1.7405,  -5.4460,  15.1582,  -3.9771, -10.3026,\n",
      "           -2.1910,  -3.1100,  -5.1266,  -0.4511,  -4.2752,  -2.3619,  -4.6910,\n",
      "           -5.5690,  -1.1184,   3.1184,   2.0686]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.1919,   2.4944,   1.5141,  -1.1307,  19.5866,   1.5758, -12.6346,\n",
      "           -1.8922,  -4.6112,  -0.5533,   3.8249,  -0.2098,  -1.5875,  -5.8617,\n",
      "            1.4841,   0.1968,  -2.2839,   1.5851]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.5405, -0.0126, -2.2672, -0.0707, 11.3095,  3.3023, -7.7530,\n",
      "          -1.0050, -0.7901, -0.9378,  2.4499, -0.0548, -0.9518, -1.2190,\n",
      "           0.7318, -3.2068, -4.8227,  0.5249]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ 0.1145, -2.2301, -1.5172, -3.8013, 12.5990, -2.2949, -5.1799,\n",
      "          -3.0553, -0.8670,  0.1477,  1.1125, -0.8812, -0.7507, -5.2020,\n",
      "          -0.9423, -0.9996, -2.5242, -0.1990]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.7104,  0.2648, -1.2363, -1.4346, 16.1029, -0.1286, -6.9794,\n",
      "           1.1854, -0.1199, -0.1534,  1.2268, -3.5737, -4.0084, -3.2284,\n",
      "          -2.3504, -1.9823, -2.5630, -1.1208]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.0637, -1.3985, -2.5680, -2.1917, 11.1369, -3.9867, -5.6077,\n",
      "          -1.6582, -2.3581, -3.9920, -0.4921, -5.2203, -0.6666, -3.3563,\n",
      "          -1.0063, -1.1057, -1.5442,  0.9644]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.8043, -4.6258, -3.9260,  1.6383, 13.4414, -2.9343, -9.3367,\n",
      "           0.4161, -1.8020, -3.0506,  0.3194, -2.6181, -2.1534, -5.4322,\n",
      "          -1.2189,  2.0994, -3.2089,  1.0535]]])\n",
      "Predicted Label Index: 4\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.5711,   1.1459,  -3.1609,   3.0333,   0.3187,  17.0695, -10.3090,\n",
      "           -1.2967,  -1.7775,   6.4999,  -1.4018,   4.4097,  -1.8146,  -4.8611,\n",
      "           -3.8501,  -5.2694,  -7.1594,  -8.5672]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.4480,  4.0682, -3.2143,  0.1551,  2.3536, 18.5203, -6.7718,\n",
      "          -1.1986, -1.6429,  6.0725, -1.4406, -1.6687, -2.4283, -6.2012,\n",
      "          -2.8952, -5.0128, -6.2264, -9.4935]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.3212,  2.2353, -2.8197,  0.1858,  1.0055, 14.1748, -7.4140,\n",
      "          -4.1620, -2.7008,  5.4841, -1.3039,  1.8415, -1.8335, -6.5050,\n",
      "          -1.1043, -3.7938, -4.9828, -6.9271]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.0605,   4.2805,  -2.6331,   2.7120,  -1.0799,  15.7314,  -8.9327,\n",
      "           -1.3145,  -1.1480,   3.3023,  -4.3326,  -0.1476,  -1.4902,  -4.9083,\n",
      "           -2.2199,  -3.9308,  -5.2330,  -9.2305]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.4376,   2.3158,  -2.9680,   0.6218,   0.1236,  17.0316,  -7.7437,\n",
      "           -1.3653,  -3.3060,   5.5811,  -5.6959,  -1.1748,  -0.3301,  -5.7435,\n",
      "           -3.8574,  -3.8335,  -3.1584, -11.9572]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.0794,  5.3512, -0.5768,  1.1418,  1.2846, 15.0869, -6.2071,\n",
      "          -2.0194, -2.3793,  4.8801, -1.2581,  1.1911, -1.0558, -4.1917,\n",
      "          -0.3654, -3.3081, -4.7430, -8.8665]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.8735,   4.6269,  -1.8730,  -0.8579,   0.9177,  15.7505,  -6.1523,\n",
      "           -2.0860,  -1.0926,   5.6798,  -2.3317,   0.6745,  -1.6519,  -4.6581,\n",
      "           -0.5649,  -4.3169,  -5.4724, -11.5262]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.6127e+00,  4.3936e+00, -1.5132e+00,  5.2095e-01,  9.4684e-01,\n",
      "           1.5983e+01, -8.9228e+00, -1.4752e+00, -1.2339e+00,  3.6059e+00,\n",
      "          -1.5545e+00, -8.4739e-03, -2.1486e+00, -3.8869e+00, -1.5090e+00,\n",
      "          -5.3594e+00, -6.7642e+00, -9.3284e+00]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.0250,   6.5322,  -1.0609,  -1.5731,   0.7994,  14.7659,  -6.4229,\n",
      "           -3.2583,  -0.5521,   5.2351,  -2.2812,   0.6023,  -2.3905,  -5.0074,\n",
      "            1.2279,  -5.2821,  -7.9359, -12.2954]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.6654,   5.8861,  -1.2123,  -1.4289,   1.6632,  15.6940,  -7.9401,\n",
      "           -4.1888,  -2.7224,   6.5421,  -1.4088,   1.1230,  -0.3503,  -7.4833,\n",
      "            0.3223,  -4.3943,  -5.4685, -11.3439]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.4750,   6.3727,  -1.6025,  -1.2521,   1.7517,  16.3577,  -6.6024,\n",
      "           -1.2712,  -1.1356,   3.7881,  -1.9671,  -0.9559,  -1.8851,  -3.6189,\n",
      "           -1.6491,  -5.5611,  -6.0548, -11.0254]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.4750,   6.3727,  -1.6025,  -1.2521,   1.7517,  16.3577,  -6.6024,\n",
      "           -1.2712,  -1.1356,   3.7881,  -1.9671,  -0.9559,  -1.8851,  -3.6189,\n",
      "           -1.6491,  -5.5611,  -6.0548, -11.0254]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.9495,  5.7592, -1.1095, -0.4498,  0.4793, 16.8616, -7.3212,\n",
      "          -1.7290, -2.9815,  2.8456, -3.0215,  0.0623, -0.7372, -4.4069,\n",
      "          -1.5836, -5.0223, -4.2780, -9.0135]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.0681,  3.5066, -1.4155, -3.9297,  4.1191, 13.4369, -8.7928,\n",
      "          -0.5762, -1.7333,  1.3068, -2.7350,  0.9270,  0.1754, -2.1831,\n",
      "          -2.0390, -4.9985, -4.7906, -6.2947]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.1643,  3.0122, -2.1052,  0.6607,  1.1611, 15.9488, -7.3110,\n",
      "          -3.0442, -2.1723,  6.2271,  0.5091, -0.0505, -1.8961, -6.5948,\n",
      "          -0.3270, -4.5776, -5.4595, -9.4105]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.2938,   4.8487,  -2.9506,   0.3802,   0.1322,  17.4369,  -7.1317,\n",
      "           -1.1819,  -2.3931,   4.2908,  -3.2500,   0.0676,  -0.2621,  -4.9559,\n",
      "           -2.9788,  -4.0505,  -3.9318, -11.2471]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.6201,  4.7727, -2.7701,  1.1888,  1.5175, 15.9558, -5.4153,\n",
      "          -2.4079, -1.2723,  5.1493,  0.1677, -1.1935, -1.4530, -6.1491,\n",
      "          -0.7541, -4.4688, -5.5204, -9.3966]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.6201,  4.7727, -2.7701,  1.1888,  1.5175, 15.9558, -5.4153,\n",
      "          -2.4079, -1.2723,  5.1493,  0.1677, -1.1935, -1.4530, -6.1491,\n",
      "          -0.7541, -4.4688, -5.5204, -9.3966]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.6201,  4.7727, -2.7701,  1.1888,  1.5175, 15.9558, -5.4153,\n",
      "          -2.4079, -1.2723,  5.1493,  0.1677, -1.1935, -1.4530, -6.1491,\n",
      "          -0.7541, -4.4688, -5.5204, -9.3966]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.5843,   1.6235,  -2.8664,   3.8374,   0.3888,  14.4897,  -7.6209,\n",
      "           -3.3528,  -2.2164,   4.5808,   0.3105,   3.8421,  -0.3650,  -4.1357,\n",
      "           -1.2139,  -3.5859,  -4.0601,  -6.5257]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.3718,  2.1999, -2.7244,  2.5921,  1.2693, 14.5818, -6.5674,\n",
      "          -4.5749, -2.1057,  5.8048,  2.1399,  3.0190,  0.6307, -5.3591,\n",
      "          -1.9693, -5.4520, -4.7528, -6.6374]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.6215,   7.7578,  -0.2235,  -1.1719,   0.6971,  15.0785,  -5.8405,\n",
      "           -1.8602,  -1.1401,   3.0914,  -1.8669,  -3.3148,  -2.2174,  -4.7417,\n",
      "           -0.3115,  -4.9243,  -6.0201, -11.6028]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.9312,  4.3818, -1.4085, -0.8149,  2.0809, 13.2304, -6.0411,\n",
      "           1.4017, -0.8477,  1.4589, -2.6823,  0.2352, -0.4321, -1.7677,\n",
      "          -0.9130, -4.7512, -5.0528, -8.5251]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.5341e+00,  2.7698e+00, -2.4825e+00,  3.4408e-02,  3.6130e-01,\n",
      "           1.4656e+01, -6.1083e+00,  1.5260e+00,  1.5432e-03,  5.6995e+00,\n",
      "          -1.9972e+00, -1.4786e-01, -3.5347e+00, -2.5861e+00, -2.6344e+00,\n",
      "          -5.2588e+00, -6.6666e+00, -1.1771e+01]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.9997,  3.0065, -2.3037,  0.5816,  0.2107, 15.8675, -6.1861,\n",
      "          -1.2617,  1.2742,  2.1149, -1.4567, -0.6286, -0.3549, -4.6581,\n",
      "          -1.1786, -7.3323, -7.9594, -6.9527]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.0871,   3.3932,  -2.1104,   2.1568,   0.9014,  18.3323,  -8.8070,\n",
      "           -0.7031,  -2.6833,   3.5549,  -2.4852,   0.6008,  -1.4444,  -3.5169,\n",
      "           -1.7570,  -4.2344,  -5.5112,  -9.0821]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.0467,   3.3312,  -2.1179,   1.0150,   0.2818,  16.7809,  -5.9597,\n",
      "           -1.2267,  -1.5193,   5.5468,  -0.7377,   0.3906,  -1.5683,  -4.0895,\n",
      "           -1.5299,  -4.7528,  -5.8560, -10.3793]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.5938e+00,  3.2267e+00, -2.7045e+00,  9.2368e-01, -6.7994e-03,\n",
      "           1.7684e+01, -8.7421e+00, -8.9133e-01, -2.2168e+00,  2.8356e+00,\n",
      "          -2.0930e+00,  1.5891e+00, -2.0778e+00, -2.6530e+00, -2.1794e+00,\n",
      "          -5.7751e+00, -6.9598e+00, -9.3362e+00]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.6231,  1.1377, -3.7510,  1.8156,  0.5167, 16.1266, -7.3916,\n",
      "          -1.1647, -2.0920,  4.1594, -1.9287, -0.8627, -0.0707, -4.0484,\n",
      "          -1.4025, -4.0770, -4.8205, -9.5328]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.7251,  4.8122, -2.1417, -0.0879,  1.1638, 17.9290, -6.2824,\n",
      "          -1.1034, -3.0392,  3.9423, -2.4357, -0.6321, -0.8083, -2.7352,\n",
      "          -4.3913, -4.4532, -4.6440, -8.8323]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.7632,   2.7444,  -3.1394,  -0.6092,   1.2464,  17.2500,  -6.3251,\n",
      "            0.1802,  -1.5964,   5.5773,  -3.6814,  -0.5443,  -1.4313,  -4.1741,\n",
      "           -3.8079,  -4.1761,  -5.2242, -10.1333]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.0506,  2.6815, -4.3321, -3.3651,  6.1119, 15.3004, -3.5950,\n",
      "           0.3996, -3.0341,  4.2369, -2.1554, -3.4896, -0.5792, -5.6546,\n",
      "          -1.1878, -2.2123, -1.7526, -8.5394]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.5337,   4.0917,  -3.2471,  -1.3079,   1.5689,  16.7427,  -5.8344,\n",
      "            0.9579,  -1.2699,   3.6540,  -2.5917,  -0.9924,  -1.1641,  -2.9247,\n",
      "           -3.2135,  -4.7653,  -6.1637, -10.2378]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.6155,   2.5542,  -2.2455,   1.6733,   2.2230,  16.9560,  -8.5586,\n",
      "           -1.0464,  -3.2407,   3.9507,   0.9409,   1.7469,  -0.1034,  -5.2702,\n",
      "           -2.6699,  -4.2525,  -5.3797,  -6.9681]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.6287,   6.1723,  -3.0196,   0.0540,  -1.0140,  15.7577,  -5.6363,\n",
      "           -0.2557,  -0.5518,   3.1570,  -4.5914,  -0.6519,  -1.9915,  -2.8468,\n",
      "           -1.7553,  -5.1355,  -5.3613, -12.4398]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.4834,  4.7806, -1.7935, -1.4795,  0.9843, 16.1271, -9.6519,\n",
      "          -2.4751, -1.0639,  3.7281, -3.6187,  0.7983, -0.6660, -5.1322,\n",
      "          -1.8596, -6.3074, -6.5931, -9.8179]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.8009,  3.5888, -1.7615, -0.7586,  2.1051, 15.8274, -5.4956,\n",
      "          -2.9752, -1.3676,  3.4546, -3.6446,  1.1421, -0.1951, -2.7304,\n",
      "           0.8622, -4.1378, -4.9445, -7.9902]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.9697,   1.6081,  -3.5312,   3.8312,   1.2598,  17.7720,  -7.6037,\n",
      "            0.6462,  -1.5372,   5.9975,  -1.1139,   0.8274,  -1.6732,  -4.5907,\n",
      "           -2.6126,  -4.1424,  -7.0387,  -8.8905]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.0559,  3.4896, -3.7899,  0.3625,  1.5382, 16.7279, -6.3691,\n",
      "           0.8531, -1.8012,  2.7580,  0.0498, -0.7105, -1.8196, -3.8203,\n",
      "          -1.9927, -5.0021, -8.1834, -7.6476]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.1192,  3.4661, -3.7295, -0.7608,  1.7032, 17.1838, -5.4242,\n",
      "          -0.8821, -0.9164,  5.6593, -1.3912, -0.5199, -2.2469, -4.1935,\n",
      "          -2.3340, -5.1213, -6.8805, -8.9775]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.1192,  3.4661, -3.7295, -0.7608,  1.7032, 17.1838, -5.4242,\n",
      "          -0.8821, -0.9164,  5.6593, -1.3912, -0.5199, -2.2469, -4.1935,\n",
      "          -2.3340, -5.1213, -6.8805, -8.9775]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.0770,  2.4709, -1.8222, -0.5362,  0.7110, 15.7187, -7.3010,\n",
      "          -0.5157, -1.2381,  5.4035, -0.6723,  0.4972, -2.3625, -4.3634,\n",
      "          -2.6572, -5.1625, -7.6238, -9.1959]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.4829,   3.8629,  -1.8364,   0.2695,   1.0742,  16.0441,  -9.2616,\n",
      "           -2.0282,  -2.5309,   5.8959,  -0.7216,   1.9724,  -2.4923,  -6.1563,\n",
      "            0.3157,  -4.7815,  -6.9562, -10.3104]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.7748,   4.0763,  -1.1090,   1.7510,   0.3244,  14.9623,  -7.7103,\n",
      "           -2.1174,  -3.1166,   4.1825,  -0.6225,   4.0644,  -0.4421,  -4.2950,\n",
      "           -0.4818,  -4.2535,  -4.6142,  -8.0483]]])\n",
      "Predicted Label Index: 5\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.0358,  -3.5905,  -0.2497, -10.0521,  -6.1182,  -7.1992,  13.8349,\n",
      "            1.3334,   4.1053,   1.2299,   1.1088,  -5.3186,  -0.4683,  -4.3861,\n",
      "           -0.4260,  -3.2745,  -5.7460,  -0.1924]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.0578, -1.0668,  1.5408, -8.7210, -5.0315, -7.1940, 13.3358,\n",
      "           4.0224,  3.6227, -0.7056, -3.1131, -3.4079,  0.6555, -5.9099,\n",
      "          -0.5700, -2.9251, -4.0819, -1.6303]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.2446,  -2.1521,  -0.1250, -10.6673,  -6.5684,  -7.6639,  14.6897,\n",
      "            2.3650,   4.2049,  -0.4541,  -0.8503,  -6.4387,  -0.5147,  -7.2047,\n",
      "           -0.3462,  -0.9744,  -5.7657,  -0.1180]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.6847, -0.2714, -1.3153, -9.8304, -5.2154, -7.4282, 13.6006,\n",
      "           1.6618,  3.1900, -0.1349,  0.5375, -5.1401, -0.9572, -7.0526,\n",
      "           3.0663,  0.1562, -4.9693, -0.3744]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.3782,  -1.2684,  -1.5880, -11.4225,  -5.7500,  -6.1474,  16.6385,\n",
      "            0.2276,   4.4487,   0.9034,   0.5867,  -5.1683,  -0.3442,  -3.8385,\n",
      "           -1.2193,  -4.3959,  -5.4389,  -1.3697]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.0807, -1.5725,  0.7966, -9.4479, -5.5035, -6.7239, 14.5465,\n",
      "           2.9154,  3.0582,  1.2822, -0.2134, -6.2801,  0.1760, -6.9809,\n",
      "          -1.6496, -2.3907, -3.0144, -0.6581]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.5030,  -0.7885,  -1.6328, -10.1645,  -7.0728,  -9.9297,  16.6009,\n",
      "            1.3775,   4.7980,   0.2317,   0.9513,  -6.6437,  -0.4403,  -8.6597,\n",
      "            2.9951,  -1.7136,  -5.7712,  -2.5436]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.5391,  -0.1037,   1.7193, -13.0026,  -4.6878,  -7.9204,  17.0281,\n",
      "            1.0041,   3.5043,   0.6019,  -0.2150,  -5.6035,   0.2636,  -6.0278,\n",
      "           -1.1032,  -4.4813,  -3.4637,  -1.0471]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.4315,  -4.1887,   2.0982, -12.3406,  -6.9252,  -8.1170,  12.1509,\n",
      "           -0.1469,   2.9285,   0.4377,   0.2015,  -7.4722,   0.5764,  -7.5355,\n",
      "            0.6597,  -1.3525,  -4.2527,  -0.1829]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.2891,  -3.9021,  -2.6254, -11.8583,  -6.8765,  -7.4802,  15.6997,\n",
      "            1.2520,   3.2384,  -0.2963,  -0.4626,  -9.1056,   2.2606,  -6.7277,\n",
      "           -4.0415,  -3.5523,  -4.7580,  -0.6315]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.2504,  -4.0145,   0.4165, -13.5505,  -6.9540,  -7.0260,  18.7407,\n",
      "            3.4773,   4.6295,   1.2645,   0.8754,  -8.1743,  -1.1406,  -5.0611,\n",
      "           -3.0564,  -4.8414,  -5.9170,  -1.1646]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.7112, -2.4977,  0.1868, -8.4186, -6.7163, -7.9778, 13.1284,\n",
      "           0.9755,  4.0428,  0.6010, -0.4588, -4.8056, -1.6784, -4.8737,\n",
      "           0.6168, -2.8558, -5.7036,  0.7774]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.3133,  -3.2515,   0.4671, -10.6968,  -6.3257,  -7.9807,  14.9755,\n",
      "           -1.6257,   4.3549,   1.6821,  -0.1003,  -7.4163,   0.6584,  -7.5692,\n",
      "           -0.1766,  -3.8038,  -3.2141,  -0.6187]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.0911,  -1.6874,   0.1695, -12.8135,  -7.8285,  -9.0974,  15.6916,\n",
      "            1.7310,   5.5773,   0.5046,   0.0313,  -6.0459,  -1.6922,  -7.8340,\n",
      "            2.1334,  -2.3544,  -7.8974,  -1.4738]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.0908,  -2.1730,  -0.2864, -13.2503,  -4.0198,  -7.9265,  14.4185,\n",
      "            1.4522,   3.8997,  -1.2890,  -0.4168,  -7.8338,   1.1548,  -6.2260,\n",
      "           -2.6544,  -3.6659,  -5.3179,  -0.8925]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.4891,  -0.6706,  -1.5919, -12.2653,  -4.6506,  -6.2620,  16.4982,\n",
      "            1.0175,   3.8583,  -0.9952,   1.3066,  -6.9858,  -0.0637,  -4.3720,\n",
      "           -1.4611,  -4.1348,  -3.9830,  -1.5541]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.5229, -3.3865, -2.9405, -7.0629, -4.8918, -6.8985, 13.1062,\n",
      "           5.2965,  2.9017,  0.5997, -1.0878, -7.6224, -1.8717, -4.5280,\n",
      "          -0.8978, -2.7914, -4.2829,  0.1608]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.7736e+00, -1.9483e+00, -1.7612e+00, -1.2494e+01, -8.1674e+00,\n",
      "          -9.3244e+00,  1.7202e+01,  1.3850e+00,  4.9090e+00,  1.3383e-02,\n",
      "          -3.8732e-01, -8.3549e+00, -3.3732e-01, -5.4396e+00, -2.0817e+00,\n",
      "          -2.6603e+00, -5.4250e+00, -6.6569e-01]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.7657,   0.1069,  -2.0221, -12.0806,  -6.6517,  -8.9372,  18.7041,\n",
      "            0.2776,   5.7737,   0.9041,   0.5662,  -5.8582,  -2.2839,  -6.6470,\n",
      "            1.0567,  -2.4806,  -5.4977,  -3.8115]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.0383,  -2.4132,  -0.3647, -10.8017,  -8.0580,  -9.3188,  17.4461,\n",
      "            2.9722,   5.7315,   1.1747,  -1.4365,  -7.1245,  -1.5636,  -7.0946,\n",
      "           -1.4476,  -4.5263,  -5.8867,  -3.2043]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.2420,  -1.5292,   0.1906, -10.7193,  -5.7159,  -9.5363,  14.5484,\n",
      "            0.7757,   5.2461,   1.2378,   0.1137,  -5.9165,  -2.8463,  -6.1567,\n",
      "            1.8503,  -1.4080,  -5.4967,  -2.8038]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.6484,  -2.2728,   2.0802, -10.3651,  -6.5546,  -7.4969,  15.8866,\n",
      "            2.4824,   3.8516,   1.7797,   0.1622,  -5.3413,  -1.4128,  -5.3890,\n",
      "           -1.3254,  -4.0352,  -4.6017,   0.4169]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.5798,  -4.9952,  -0.1399, -14.1097,  -7.2496,  -7.6540,  17.9816,\n",
      "            1.4634,   5.7126,   0.5001,   0.3902,  -7.5974,   1.0682,  -5.5881,\n",
      "           -3.1706,  -5.8480,  -5.8479,  -2.0614]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.6987,  -1.2381,  -0.1144, -10.3399,  -7.7949,  -8.0184,  15.3598,\n",
      "            1.8296,   4.3300,  -0.0774,  -0.5273,  -6.9621,  -1.0101,  -6.0028,\n",
      "           -2.4872,  -3.2292,  -5.2081,  -2.1104]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.7254e+00, -1.7985e+00,  1.1474e-02, -1.2727e+01, -7.4075e+00,\n",
      "          -8.5155e+00,  1.7601e+01,  6.6081e-01,  6.0956e+00,  1.3834e+00,\n",
      "          -3.3472e-01, -7.0556e+00, -1.7720e+00, -5.9091e+00, -6.0622e-01,\n",
      "          -4.2175e+00, -4.6860e+00, -3.3175e+00]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.1141,  -2.1010,  -0.6398, -13.0646,  -7.1386,  -8.9186,  18.1282,\n",
      "            2.5550,   5.3803,  -1.3881,   0.2701,  -8.1474,   0.3081,  -6.7353,\n",
      "           -2.0740,  -4.3323,  -4.7445,  -1.8596]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.1690,  -0.7483,   1.3641, -10.9217,  -5.8936,  -6.6302,  15.3829,\n",
      "            2.7182,   4.5601,   0.1572,  -2.4982,  -7.3113,  -2.6988,  -4.1451,\n",
      "           -0.6506,  -3.5322,  -3.4072,  -2.6243]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.6102, -2.3283, -0.8394, -9.7980, -7.4215, -7.6847, 15.8341,\n",
      "           3.3920,  5.6498, -0.2670,  0.0657, -7.4553, -3.2745, -5.9835,\n",
      "           1.4458, -2.3090, -6.9807, -2.5726]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.2212,  -3.5616,   0.1660, -11.7983,  -7.7749,  -8.3619,  17.6496,\n",
      "            2.6827,   5.9587,   1.1330,  -1.2362,  -6.0691,  -0.5858,  -5.6922,\n",
      "           -2.2227,  -6.8896,  -7.7090,  -0.8826]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.5293e+00, -3.3169e+00,  4.8445e-04, -1.1471e+01, -7.6421e+00,\n",
      "          -8.1126e+00,  1.6240e+01,  3.2936e-01,  5.7011e+00, -5.2474e-01,\n",
      "          -2.3878e+00, -7.3964e+00, -4.1611e-01, -6.6596e+00, -1.5291e+00,\n",
      "          -3.7869e+00, -5.4759e+00, -4.5221e-01]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.2021,  -2.1691,  -1.1461, -10.6432,  -7.8774,  -8.2804,  13.7925,\n",
      "            1.3289,   2.9523,  -1.3435,  -0.7446,  -7.4939,   0.9391,  -7.2775,\n",
      "           -0.3556,  -1.3138,  -5.5584,   0.3444]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.1993,  -2.9846,   1.2687, -12.6646,  -9.3359,  -9.7656,  19.6419,\n",
      "            1.7927,   6.8137,   1.3035,  -0.5814,  -5.7578,  -0.8274,  -7.8077,\n",
      "           -1.2213,  -6.3568,  -6.6476,  -1.7200]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.8391,  -1.0629,   1.7371, -10.9144,  -6.1912,  -8.2262,  14.8144,\n",
      "           -0.1172,   4.3249,   1.8206,  -0.0605,  -4.5558,  -0.7367,  -7.8469,\n",
      "            1.7453,  -1.3970,  -4.3233,  -0.3420]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -1.1154,  -3.0818,  -0.1283, -10.1753,  -6.5731,  -9.0758,  15.8427,\n",
      "           -0.0725,   4.9299,   2.2093,   0.6089,  -5.2846,  -1.0245,  -7.3464,\n",
      "           -0.2844,  -3.8188,  -6.1163,  -0.3586]]])\n",
      "Predicted Label Index: 6\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.1369, -4.0829, -3.4218, -5.8303,  1.0026, -2.8447,  1.4360,\n",
      "          11.8402, -3.2711, -7.4103,  0.9945, -9.4828,  3.3314, -3.5741,\n",
      "          -3.5570, -1.6093, -2.2833, -1.6326]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.9493, -4.6529, -2.5544, -1.6621, -0.4232, -1.5201,  0.0454,\n",
      "          13.5869, -0.6373, -5.1666, -0.5243, -6.7501, -1.1097, -2.7077,\n",
      "          -0.8964, -0.2769, -5.0174, -4.6021]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.4734,  -1.9858,  -0.5054,  -5.1085,  -1.5984,  -0.6214,  -1.1201,\n",
      "           12.6105,  -1.9984,  -6.1633,  -1.0826, -10.2005,   0.0128,  -4.8459,\n",
      "           -2.2275,  -1.2008,  -6.4478,  -6.6231]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.2222,  -4.6346,  -4.5036,  -2.2349,  -0.4897,  -0.8276,  -1.8009,\n",
      "           14.4217,  -1.1732,  -6.9250,   0.9273, -11.7136,   0.1657,  -5.0333,\n",
      "           -0.6738,   0.7074,  -5.6776,  -6.7025]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.5548,  -6.5561,  -5.4941,  -4.4409,  -1.3507,  -2.9153,   2.5302,\n",
      "           16.0576,  -0.3783,  -7.0632,   0.9276, -12.0890,   0.4418,  -4.3397,\n",
      "           -1.3265,  -0.8659,  -6.6913,  -4.8074]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.7406, -2.3823, -7.0047, -1.8044,  0.1161, -0.2117, -0.8951,\n",
      "          16.0293, -0.4437, -9.2778,  0.1337, -9.3322, -1.0277, -4.4808,\n",
      "           3.3317, -0.2839, -7.6137, -4.9844]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.1524,  -5.4478,  -5.0399,  -0.7994,  -2.3599,  -0.9341,  -1.5737,\n",
      "           16.6541,  -0.4381,  -7.9232,  -1.1451, -11.1852,  -1.7552,  -4.8161,\n",
      "            1.1977,   1.6436,  -7.0361,  -6.5483]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.1126, -3.9389, -2.4583, -3.5641, -0.3283, -2.2947,  0.0144,\n",
      "          13.0126, -1.5004, -7.1665, -0.6224, -9.2788,  0.6397, -2.8417,\n",
      "          -1.6472, -2.3318, -3.6034, -6.0075]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.2071,  -4.0029,  -5.0888,  -1.9651,  -0.3809,  -0.8886,  -1.0432,\n",
      "           14.7809,  -0.5925,  -7.6706,  -2.2190, -11.3443,  -0.6917,  -5.6077,\n",
      "           -0.0694,  -1.0811,  -5.5013,  -6.0233]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.8667, -4.9475, -3.1155, -2.7085, -1.9536, -3.5255,  3.2127,\n",
      "          12.3143,  0.9451, -4.1766, -1.0281, -8.3560, -2.2477, -3.5809,\n",
      "          -0.4888, -0.1388, -5.0137, -3.8323]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.6803, -5.5618, -3.5649, -0.7660, -1.1533, -1.9654, -1.8692,\n",
      "          11.6454, -0.1662, -5.9725, -2.1797, -8.3828, -0.7884, -4.3754,\n",
      "          -0.2608, -0.0888, -5.3059, -3.3509]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.9530, -5.6030, -2.7974, -1.0472, -1.2428,  1.1236, -2.3204,\n",
      "          13.9303,  0.5427, -7.0522, -4.4101, -9.7226, -2.7540, -0.7221,\n",
      "          -2.5884, -2.0863, -2.7746, -4.3357]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.0101, -4.8058, -1.7633,  0.9620,  1.1700, -2.6302, -3.1441,\n",
      "          10.5369,  0.4450, -4.2402, -0.6249, -6.2460, -3.9928, -5.1150,\n",
      "           1.6267,  1.0923, -5.6476, -2.3204]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.4693, -3.1416, -1.9724, -3.7243,  0.1222, -2.3219,  2.2151,\n",
      "          13.7335, -1.5862, -5.2498,  1.7859, -9.7878, -1.4348, -3.8299,\n",
      "           3.0573,  0.3664, -4.9707, -4.4375]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.3912,  -4.0429,  -0.6027,  -5.0704,  -0.9352,  -1.7383,   0.5360,\n",
      "           11.6256,  -2.5582,  -5.1493,  -1.0188, -10.3708,   1.6575,  -6.2051,\n",
      "            0.5300,   1.4362,  -4.5678,  -4.2998]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.2883,  -1.6551,  -2.8539,  -4.8852,   0.5273,  -0.7974,   0.8856,\n",
      "           13.4869,  -0.9429,  -6.0363,  -0.2406, -10.9104,   0.6435,  -5.2043,\n",
      "           -0.6887,  -1.6061,  -4.4423,  -7.5329]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.6429,  -4.2980,  -1.8170,  -4.9477,  -2.1696,  -1.3625,   0.3274,\n",
      "           14.5057,  -1.1844,  -6.8907,   0.1709, -10.9295,  -0.8554,  -5.0062,\n",
      "           -1.9054,   1.0306,  -7.1225,  -5.0933]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.6563, -3.6118, -1.6405, -3.8535, -0.5189, -1.2404,  0.8824,\n",
      "          11.8225, -1.0956, -5.6962, -3.3559, -8.6871,  0.3746, -3.9956,\n",
      "          -0.2198, -0.6204, -4.7179, -4.7255]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.0931e+00, -4.8315e+00, -1.1823e+00, -3.9074e+00, -1.6535e+00,\n",
      "          -4.4613e+00,  5.6898e-01,  1.0628e+01, -1.2950e+00, -6.0341e+00,\n",
      "          -2.4363e+00, -9.9102e+00,  5.0048e-01, -4.5840e+00, -1.2303e+00,\n",
      "           7.8346e-03, -4.9675e+00, -3.9350e+00]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.3408, -3.0710, -0.8984, -4.1744, -0.6923, -1.3617, -0.7891,\n",
      "          11.7385, -2.8271, -7.0273, -0.0998, -9.2006,  2.8781, -4.7937,\n",
      "          -2.8307, -0.3990, -2.9289, -4.4510]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.4831,  -5.3447,  -0.9808,  -6.1417,  -4.0946,  -4.8760,   3.5010,\n",
      "           12.0783,  -0.7055,  -8.0354,  -1.1584, -10.2081,   3.9865,  -7.6305,\n",
      "           -0.8464,  -2.4461,  -6.1588,  -3.1946]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.3065, -2.8974, -3.6072, -2.8902, -2.4526, -0.8588, -0.9896,\n",
      "          13.4817, -0.8321, -6.3394, -1.6053, -8.5790, -0.4578, -5.3396,\n",
      "          -0.2024,  1.9769, -6.8950, -6.0098]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.0709, -4.2185, -2.4371, -2.4792, -3.4532, -1.0358, -2.1105,\n",
      "          11.2513, -0.2169, -7.4952, -3.8151, -7.1374, -1.1404, -2.5138,\n",
      "           0.4540, -0.9373, -6.5952, -3.3099]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.0333,  -3.3542,  -2.8776,  -5.0637,  -1.0886,  -0.5596,   0.2564,\n",
      "           14.7315,  -2.6110,  -6.4147,  -0.4699, -12.5878,   1.0562,  -6.4816,\n",
      "           -4.0430,  -0.3141,  -6.2074,  -6.9543]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.8403, -3.0939, -4.4906, -3.4442, -1.3177, -1.0853,  0.4701,\n",
      "          12.7792, -1.0493, -5.9848,  0.0183, -9.0108,  1.7892, -4.8829,\n",
      "          -1.8861,  0.2501, -4.3081, -6.2181]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.8073, -3.3928, -2.9193, -3.3434, -2.2496, -0.9759, -2.4306,\n",
      "          13.1517, -1.7241, -7.5042, -2.4131, -9.5094,  1.4674, -6.0633,\n",
      "          -0.6744, -0.9420, -6.1107, -8.0003]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.1257, -1.2418, -0.8217, -3.7343, -1.7417, -0.8402, -3.3015,\n",
      "          11.0181, -0.4961, -6.7594, -0.1388, -5.7153,  0.1290, -5.0318,\n",
      "           0.1905,  0.5390, -6.7761, -5.3042]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.5940,  -4.6514,  -5.0000,  -2.0756,  -2.4466,  -2.6794,  -0.3476,\n",
      "           15.1546,  -0.2093,  -7.6748,  -0.6498, -10.2591,  -1.0947,  -5.5360,\n",
      "           -1.2192,   0.1948,  -4.3875,  -5.9970]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.0377,  -4.5378,  -3.9797,  -4.8441,  -1.1423,  -3.0873,   1.7852,\n",
      "           13.0687,  -0.8431,  -7.1700,  -0.7066, -11.5323,   0.7995,  -5.0605,\n",
      "            1.3747,  -0.3439,  -5.4270,  -4.6074]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.7238,  -4.9263,  -5.3396,  -3.7498,  -2.8509,  -1.6494,   0.1460,\n",
      "           12.1119,  -1.6980,  -7.4163,  -1.0423, -11.4376,   2.9175,  -5.7889,\n",
      "           -1.7911,   1.4704,  -3.4662,  -6.6274]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.5946, -3.7968, -6.7137, -1.3205, -2.2482, -1.7835,  0.6607,\n",
      "          17.5352,  0.5972, -7.9920, -1.3044, -9.9086, -2.4423, -6.7474,\n",
      "           0.4657,  0.8946, -8.0012, -7.4360]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.0650, -3.8607, -4.6802, -4.3491, -3.1121, -2.0646,  2.5909,\n",
      "          12.4624,  1.3177, -5.3198, -2.5776, -7.8792,  0.3793, -6.6404,\n",
      "          -1.1026, -0.9164, -6.6607, -5.8223]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.3569, -4.9593, -1.3313, -4.9020,  0.5445, -2.7134,  0.4097,\n",
      "           9.5595, -1.6579, -6.7256, -1.6815, -8.5821,  1.4807, -1.4143,\n",
      "          -3.5094, -3.5588, -2.8226, -1.3664]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.2468e+00, -4.5424e+00, -2.2697e+00, -3.1095e+00, -2.7829e+00,\n",
      "          -1.8186e+00, -3.8570e-01,  1.4783e+01, -1.5937e+00, -8.3593e+00,\n",
      "           1.2388e-01, -1.1139e+01, -1.2501e-02, -3.6505e+00, -6.6870e-02,\n",
      "          -8.7276e-01, -5.5049e+00, -3.9429e+00]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.2657, -5.2438, -7.1763,  0.1174, -2.4976, -0.7961, -1.4888,\n",
      "          15.8843,  1.0739, -7.6242, -2.0625, -9.0993, -2.0889, -4.7187,\n",
      "           0.3653, -0.9524, -7.9442, -5.5212]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.2180, -3.0644, -1.7424, -5.7120, -0.7701, -1.2399,  0.6313,\n",
      "          11.4817, -1.0261, -6.4935,  0.2164, -9.5931,  1.8262, -4.8119,\n",
      "          -1.8897, -1.8541, -6.5527, -3.0460]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.2786,  -4.9937,  -3.1115,  -2.2416,  -2.3069,  -3.4901,   0.0418,\n",
      "           15.1719,  -0.6181,  -7.7592,  -1.5682, -10.1567,  -1.4902,  -5.6336,\n",
      "           -1.5485,   2.6657,  -4.8534,  -4.4281]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.5004, -5.0515, -2.7881, -2.8521, -2.8687,  0.8393, -1.1441,\n",
      "          12.6580,  0.9364, -7.6484, -2.7588, -9.3448, -0.2032, -0.0857,\n",
      "          -5.2096, -5.8114, -6.2961, -5.8362]]])\n",
      "Predicted Label Index: 7\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -1.2167,   2.9315,  -5.3132,  -4.4498,  -1.2447,  -8.3592,   0.3995,\n",
      "           -1.0875,  10.7898,  -4.8632,  -2.1176,  -6.2473,  -7.7600,  -6.4311,\n",
      "            1.2077,  -4.4241, -11.3961,  -8.0382]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -1.3322,  -0.8654,  -3.8240,  -2.2319,  -1.8800,  -2.6590,  -3.7639,\n",
      "           -2.9640,  10.6305,  -2.1576,  -1.2896,  -2.7854,  -3.7025,  -7.3145,\n",
      "           -1.0559,  -8.4583, -11.1470,  -4.8029]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.3215,   2.3794,  -1.1499,  -5.4461,  -4.9383,  -6.6083,  -3.4119,\n",
      "           -3.2418,  11.6265,  -2.3348,  -3.5984,  -1.8986,  -6.2979,  -5.4324,\n",
      "           -0.1254,  -5.7388, -12.2359,  -9.4593]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ 1.3443, -0.5911, -3.7476, -4.6888, -2.8936, -5.1415, -0.4254,\n",
      "           0.1198, 10.9597, -3.0169, -2.6547, -3.5189, -4.6515, -6.0870,\n",
      "          -3.6770, -7.7977, -9.9697, -5.3976]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -1.5217,   1.5285,  -3.5600,  -5.8110,  -5.2864,  -4.7893,   0.8959,\n",
      "           -1.0621,  12.9113,  -3.1600,  -3.2938,  -2.7931,  -6.0378,  -5.4206,\n",
      "           -1.6963,  -8.2514, -13.0551,  -7.0427]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.2723,   1.6132,  -3.1241,  -5.3537,  -4.0785,  -1.8566,  -0.3199,\n",
      "           -3.2352,   9.7662,  -0.7241,  -0.7594,  -3.8772,  -4.9474,  -5.7890,\n",
      "            0.3519,  -6.6078, -10.8529,  -5.6724]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.7095e+00, -9.2201e-01, -3.8209e+00, -3.4276e+00, -5.3302e+00,\n",
      "          -3.1000e+00,  1.0395e-01, -3.3695e+00,  9.8430e+00,  5.9850e-01,\n",
      "          -1.0026e-03, -1.6300e+00, -3.6303e+00, -5.5948e+00, -1.2202e+00,\n",
      "          -7.0252e+00, -9.8578e+00, -6.7738e+00]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -1.8126,   1.2937,  -2.6247,  -4.2065,  -4.9904,  -4.3453,  -0.1592,\n",
      "           -3.7578,  11.8510,  -0.7580,  -1.9265,  -2.9901,  -5.7114,  -7.0375,\n",
      "           -0.8450,  -8.5983, -12.9641,  -6.4262]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.1806,  -1.5955,  -2.9389,  -2.5802,  -2.2763,  -4.9392,  -3.3618,\n",
      "           -1.8723,  10.8638,   0.8528,  -1.5065,  -0.9607,  -6.7705,  -6.7652,\n",
      "            0.3367,  -9.2483, -12.5587,  -6.4508]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.8142,  -0.5340,  -3.3533,  -4.7977,  -2.9996,  -6.5513,  -2.2599,\n",
      "           -5.1152,  12.0522,  -1.2896,   1.1106,  -1.6917,  -6.9677,  -7.5178,\n",
      "            1.7626,  -8.8389, -12.9165,  -6.7306]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.8085, -1.6821, -3.8921, -1.5387, -3.2631, -2.0908, -0.1879,\n",
      "          -3.2002,  9.3583,  0.8520, -0.7452, -1.4010, -4.8046, -4.6464,\n",
      "           0.4137, -7.8520, -9.8271, -4.6748]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.8313,  -4.9152,  -5.5943,  -0.9292,  -2.2637,  -2.2543,  -6.5309,\n",
      "           -5.3100,   9.7538,  -1.0503,  -4.2560,   0.8976,  -5.0626,  -3.9337,\n",
      "            1.3572,  -9.1729, -11.7845,  -3.8169]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.0240,  -2.5855,  -3.1045,  -1.8198,  -3.0990,  -3.0090,  -3.4324,\n",
      "           -2.9646,   8.8889,  -0.1485,  -2.5093,  -0.1811,  -4.7858,  -4.3271,\n",
      "           -0.5847,  -8.4217, -10.1076,  -4.8748]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.9457,  -3.4898,  -3.6535,  -2.3140,  -4.0267,  -2.8823,  -1.5822,\n",
      "           -3.6310,   9.9004,   0.6147,  -0.7384,  -0.1963,  -5.3955,  -4.8561,\n",
      "            0.1013,  -8.7966, -10.5457,  -5.0555]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.2386,  -4.1832,  -5.3110,  -2.5859,  -4.0939,  -6.1244,  -2.2082,\n",
      "           -3.6888,  12.3248,  -0.4384,  -3.9635,  -0.8382,  -7.2385,  -6.9730,\n",
      "            0.3229, -10.7307, -12.9456,  -7.9327]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.2807, -1.4000, -3.3856, -1.5439, -2.6807, -2.4175, -1.4591,\n",
      "          -3.0549,  8.9534,  0.4381, -1.2954, -1.2441, -4.2488, -5.0398,\n",
      "           0.5678, -7.6240, -9.2024, -5.1223]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -0.2897,  -2.9074,  -6.4696,  -2.4214,  -2.6380,  -3.6790,  -6.7779,\n",
      "           -3.7686,  11.3551,   1.7000,   1.1570,  -3.0263,  -5.4760, -10.5341,\n",
      "           -2.8071, -10.7735, -14.3722,  -6.8582]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[  1.2723,  -3.2869,  -4.1734,  -2.8318,  -4.8495,  -5.5844,  -7.3396,\n",
      "           -3.8086,  12.9815,   0.5277,  -2.8989,  -0.3197,  -7.1903,  -7.6289,\n",
      "           -2.0837,  -7.7554, -13.0189,  -4.6641]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.6129, -2.7939, -0.7959, -0.8721, -4.3623, -6.7354,  0.3926,\n",
      "          -0.6557, 10.0478, -0.2988, -2.4634, -4.5091, -6.7061, -1.9575,\n",
      "           1.5783, -4.4772, -7.0606, -5.1558]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.8815, -4.8943, -3.0079,  0.3623, -2.9023, -3.7365, -2.8262,\n",
      "          -1.8149, 10.0079,  1.3558, -0.9103, -4.0415, -6.6251, -7.4271,\n",
      "          -2.2345, -8.5830, -9.3637, -5.8920]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.2790, -2.2464, -5.1584, -2.3317, -4.6464, -7.7011, -2.2340,\n",
      "          -1.6566, 11.5701, -5.6635, -1.6856, -7.0760, -5.4827, -3.6591,\n",
      "          -1.4728, -4.4117, -8.5420, -6.7972]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.5281,  -2.1344,  -5.9015,  -2.9291,  -3.2601,  -7.4914,  -4.9220,\n",
      "           -2.1361,  14.6644,  -6.9398,  -2.8768,  -7.3767,  -8.2631,  -5.3878,\n",
      "           -1.5609,  -8.1699, -12.6197,  -7.1314]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -1.2908,  -3.0544,  -5.8912,  -2.8539,  -4.0077,  -8.5576,  -2.0883,\n",
      "           -2.3726,  13.7777,  -6.0979,  -7.5139,  -4.9404,  -5.3259,  -6.4819,\n",
      "            0.1339,  -7.8197, -11.1465,  -5.5908]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.1874,  -0.9868,  -2.9889,  -5.4427,  -5.6806,  -7.5438,  -2.2808,\n",
      "           -4.3912,  10.9659,  -3.2800,  -2.4404,  -2.3828,  -4.6410,  -5.1969,\n",
      "           -0.9944,  -6.3602, -10.7169,  -6.4364]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[  0.2969,  -2.1383,  -5.9816,  -7.7415,  -5.6718, -10.4920,   0.0863,\n",
      "           -3.9110,  15.0833,  -4.3762,  -2.2001,  -7.8365,  -7.7312,  -8.3593,\n",
      "            0.7606,  -6.4166, -13.5864,  -6.5634]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -2.5255,  -0.4881,  -3.0854,  -1.9557,  -5.8197,  -3.7331,  -3.3655,\n",
      "           -3.3238,  11.4024,  -0.8125,  -4.2746,  -0.5898,  -4.1776,  -7.8382,\n",
      "           -0.4329,  -7.4663, -10.7729,  -7.4931]]])\n",
      "Predicted Label Index: 8\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.2341,  -4.5744,  -3.5615,   1.7721,  -3.3789,   2.7791,  -4.0819,\n",
      "           -6.4922,   3.3115,  16.0135,   3.8639,   1.9872,  -4.7364, -13.1447,\n",
      "           -2.8709,  -5.5003,  -7.8016, -12.0746]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.4170,  -5.2371,  -3.4724,   4.0089,  -3.1228,   4.2829,  -8.7999,\n",
      "           -4.7275,   2.1872,  13.3449,   2.1729,   1.7517,  -4.2146, -13.1350,\n",
      "           -5.5574,  -4.8618,  -7.3726, -10.1977]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.0743,  -5.7301,  -3.6266,   2.3998,  -5.2038,   2.5462,  -5.3425,\n",
      "           -5.6266,   3.0296,  15.5465,   0.0958,   2.2159,  -5.1673, -15.1967,\n",
      "           -2.6650,  -4.1800,  -6.3222, -11.8141]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.5721,  -4.2032,  -3.4297,   3.0822,  -4.8711,   1.2729,  -4.7010,\n",
      "           -5.1841,   1.8196,  12.1095,   1.4548,   2.5990,  -3.4841, -11.2886,\n",
      "           -3.7695,  -3.3253,  -5.2296, -10.0515]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.4289e+00, -3.8963e+00, -3.3386e+00,  3.9984e-04, -3.0544e+00,\n",
      "           6.4292e-01, -3.3150e+00, -4.9186e+00,  2.6176e+00,  1.2430e+01,\n",
      "           1.9060e+00,  1.2692e+00, -3.1706e+00, -1.2857e+01, -8.1887e-01,\n",
      "          -3.2087e+00, -7.0203e+00, -1.0586e+01]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.0488, -4.3180, -2.3455,  2.3826, -4.7216,  2.7007, -3.0408,\n",
      "          -5.2526,  2.7470, 12.7997,  2.1185,  3.2917, -3.2638, -9.9141,\n",
      "          -2.7080, -4.1925, -5.8868, -9.2585]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.9653,  -4.6647,  -2.5942,   2.7318,  -3.0803,  -0.0288,  -4.6790,\n",
      "           -5.5473,   3.2231,  13.1639,   1.9028,   1.8363,  -4.3110, -12.0847,\n",
      "           -3.3028,  -3.1244,  -5.9683,  -9.8576]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.9015,  -5.5296,  -3.6015,   2.8070,  -5.6896,   0.6039,  -4.6550,\n",
      "           -6.4945,   1.9236,  14.9478,   1.5843,   2.2807,  -4.1534, -13.6047,\n",
      "           -2.5514,  -2.2816,  -4.4425, -10.9876]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.2541,  -8.4643,  -3.1719,   6.0627,  -1.6910,   3.1757,  -8.1134,\n",
      "           -5.8407,   2.8857,  15.1711,   2.2272,   0.1571,  -4.1927, -13.6253,\n",
      "           -5.5330,  -3.4809,  -4.7375,  -8.8350]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.3062,  -5.1688,  -3.5450,   2.3588,  -4.1012,   1.3276,  -3.9949,\n",
      "           -5.6697,   3.7539,  13.0389,   2.1193,   2.4876,  -4.9033, -11.3996,\n",
      "           -3.2244,  -6.1446,  -7.7504, -10.8554]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.4087,  -5.2137,  -3.1017,   2.3645,  -2.2560,   2.2370,  -4.7652,\n",
      "           -4.5718,  -0.0473,  11.5940,   1.2377,   1.8145,  -2.3773, -11.5831,\n",
      "           -3.5751,  -2.9961,  -4.9620,  -8.2457]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.0134,  -4.0692,  -3.6939,   0.8607,  -5.4887,   1.5200,  -4.0240,\n",
      "           -6.5660,   3.8655,  12.6999,   2.5074,   2.3306,  -4.0888, -13.3967,\n",
      "           -0.1555,  -5.6782,  -8.2886, -10.7558]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.0479,  -3.7064,  -1.9027,   1.8003,  -4.7306,   2.4328,  -5.4402,\n",
      "           -5.0472,   4.0752,  14.0473,   0.5193,   0.7769,  -5.9811, -12.5140,\n",
      "           -2.0853,  -3.3713,  -7.0356, -10.5599]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.0133,  -3.6931,  -2.7945,   0.6530,  -6.3044,   3.6139,  -4.5503,\n",
      "           -4.4307,   2.1143,  12.3838,  -0.8134,   3.1993,  -2.9519, -11.0743,\n",
      "           -4.8459,  -3.7553,  -6.5936,  -9.7823]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.5321,  -4.1838,  -2.6483,   1.9631,  -3.6618,   1.7682,  -2.1396,\n",
      "           -5.2380,   3.0810,  13.0101,   1.9900,   2.4847,  -3.5114, -10.9935,\n",
      "           -1.7275,  -3.0372,  -5.6794,  -8.7039]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.4821,  -3.6241,  -2.1285,   1.2340,  -6.3974,   0.6801,  -2.7341,\n",
      "           -6.3830,   2.7136,  14.4961,   0.5047,   2.0414,  -4.6035, -10.8367,\n",
      "           -3.3312,  -3.6318,  -6.8610, -10.3563]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.4404,  -4.2526,  -1.9662,   2.8198,  -5.4875,   1.7301,  -2.9282,\n",
      "           -6.8922,   3.2591,  13.4502,   1.2194,   3.1103,  -3.4511, -11.1841,\n",
      "           -1.6565,  -5.1410,  -6.3231,  -9.2827]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.3579,  -4.2196,  -2.7617,   0.5142,  -5.4604,   1.2497,  -3.9623,\n",
      "           -5.0481,   3.8667,  14.0626,   0.0222,   1.3376,  -4.9772, -12.8260,\n",
      "           -3.9760,  -4.7536,  -7.1831, -10.8734]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.8944,  -5.1555,  -3.0769,   4.0626,  -4.5548,   3.3046,  -5.9982,\n",
      "           -6.3546,   2.0287,  14.2225,   0.9179,   1.6058,  -4.2480, -12.3172,\n",
      "           -3.9415,  -4.2449,  -6.5511, -11.1762]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.8052,  -3.8220,  -1.6157,   2.1098,  -2.9916,   2.6289,  -4.0197,\n",
      "           -5.1414,   1.8624,  13.2644,   1.8492,   1.4593,  -3.5759, -10.1030,\n",
      "           -2.5908,  -2.6339,  -4.2631,  -9.3749]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.8485,  -5.4621,  -1.4315,   3.0682,  -5.4052,   1.5055,  -4.8673,\n",
      "           -5.2907,   2.9861,  14.5450,   1.6266,   0.6379,  -4.6987, -10.6071,\n",
      "           -3.5218,  -3.7476,  -6.9808,  -8.6282]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.1386,  -5.4920,  -3.3708,   1.5398,  -5.2959,   1.3566,  -4.8933,\n",
      "           -4.3965,   1.2332,  13.4339,   0.9186,   2.6229,  -4.2253, -11.8619,\n",
      "           -3.2871,  -3.7690,  -7.4880,  -9.3462]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.2972,  -3.7328,  -2.0733,   1.9734,  -4.1168,   4.3773,  -5.4765,\n",
      "           -6.5090,   2.8508,  14.2483,   2.2131,   0.4863,  -4.3463, -11.8291,\n",
      "           -3.1464,  -5.9672,  -7.9286,  -9.6153]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -4.6059,  -1.0208,  -1.6593,  -1.4742,  -3.8272,   2.4901,  -2.9851,\n",
      "           -3.7762,   1.2188,  10.9828,   0.0215,   0.5776,  -2.7798, -11.7756,\n",
      "           -1.2785,  -0.7455,  -4.9190, -10.1469]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.6287,  -3.8733,  -0.3065,   1.7779,  -3.8255,   1.2042,  -3.7025,\n",
      "           -4.3762,   2.8977,  14.2279,   0.4564,   2.1662,  -5.1298, -10.3981,\n",
      "           -3.1276,  -3.5509,  -5.4289, -10.2043]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.7797,  -4.6207,  -2.3740,   1.8104,  -4.1196,   1.5112,  -4.2426,\n",
      "           -5.0410,   2.9743,  14.3550,   0.9808,   1.1671,  -4.7007, -13.2861,\n",
      "           -3.2368,  -3.9149,  -6.2444,  -9.7308]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.4193,  -5.4917,  -3.3733,   2.7004,  -5.6689,   2.3582,  -5.6956,\n",
      "           -6.4310,   3.0662,  15.7976,   2.0861,   0.8579,  -4.8692, -15.0478,\n",
      "           -4.4451,  -5.4289,  -6.8921, -12.0360]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.9558,  -4.4564,  -3.3913,   1.4318,  -4.9639,   0.8414,  -3.1861,\n",
      "           -5.2769,   1.5402,  13.3066,   0.8785,   2.5913,  -3.8522, -12.0273,\n",
      "           -2.4574,  -5.3416,  -7.6223,  -9.9703]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.0117,  -6.3227,  -2.8998,   2.3531,  -5.1408,   2.5700,  -5.2685,\n",
      "           -5.3619,   0.5237,  12.3692,   3.5640,   3.0545,  -2.5020, -11.9951,\n",
      "           -1.5374,  -4.6460,  -7.4614,  -8.8524]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.3832,  -4.5805,  -2.4166,   2.7352,  -3.2637,   3.8814,  -7.9714,\n",
      "           -5.7114,   3.1757,  14.3698,   2.2613,   2.1342,  -4.8300, -12.5712,\n",
      "           -3.8146,  -6.1411,  -8.2658, -10.9036]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.4897,  -0.8507,  -1.7645,   0.3889,  -3.3655,   0.9146,  -4.2927,\n",
      "           -5.5340,   3.3412,  14.1905,   0.7085,   1.9238,  -5.7037, -13.3635,\n",
      "           -2.4259,  -2.4985,  -7.0569, -13.3763]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.1032,  -6.3353,  -4.1089,   2.8152,  -2.8543,   1.6870,  -5.5688,\n",
      "           -6.3431,   2.7419,  14.3275,   3.7482,   2.6292,  -3.7251, -12.5757,\n",
      "           -2.5271,  -3.9836,  -7.2758, -10.1129]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.1541,  -5.3185,  -3.0660,   2.8245,  -3.3702,   2.5169,  -4.8865,\n",
      "           -4.5979,   2.3115,  14.0337,   2.2068,   2.6763,  -4.5548, -12.0572,\n",
      "           -4.4151,  -4.2239,  -5.5128,  -9.1735]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.7802,  -7.4228,  -3.5192,   2.1838,  -4.2804,   2.0476,  -6.5548,\n",
      "           -4.3251,   4.0923,  16.0659,   3.0955,   0.8052,  -6.2824, -15.4546,\n",
      "           -4.6624,  -4.6168,  -7.7271, -10.1469]]])\n",
      "Predicted Label Index: 9\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.1925,  -0.4779,  -6.6971,  -0.8367,  -3.2805,  -3.5359,  -5.0211,\n",
      "           -0.3298,   1.4190,  -4.3955,  11.3808,  -6.4930,  -4.5574,  -8.1862,\n",
      "            1.5960,  -3.9500, -10.8665,  -6.9731]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.9832,  -7.6768,  -8.6917,   2.4178,  -2.3153,   3.0974, -10.1793,\n",
      "           -4.8662,  -1.2065,  -2.4798,  16.6894,  -3.2150,  -1.6489,  -7.3403,\n",
      "            3.0312,  -5.3099, -12.0281,  -2.2661]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.1344,  -2.1488,  -4.2420,  -1.7964,  -3.0173,  -1.9140,  -7.8851,\n",
      "           -6.8662,  -0.0469,  -1.6273,  14.7631,  -0.5005,  -2.5458,  -6.8894,\n",
      "            4.6970,  -7.1465, -14.9590,  -5.8508]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.6983, -3.2750, -5.1103, -1.1573, -4.0756, -1.4942, -6.4510,\n",
      "          -6.4108, -2.5868,  0.2154, 14.0382, -0.0510, -2.1265, -4.8426,\n",
      "           3.6632, -2.7254, -9.7988, -6.0574]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.8184,  -1.9603,  -5.9512,  -3.6864,  -4.1176,  -3.1558, -10.8601,\n",
      "           -8.8579,  -0.5709,  -2.2657,  15.2474,   3.2543,  -2.3089,  -7.4674,\n",
      "            1.9661,  -6.0232, -14.4147,  -7.4987]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.4305,  -3.0103,  -6.2499,   3.0854,  -2.5091,   1.2587,  -7.8045,\n",
      "           -7.1543,   0.6575,  -0.1121,  12.9002,   1.6047,  -1.8780,  -4.4691,\n",
      "            0.9429,  -5.7400, -11.3522,  -2.2810]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.0400,  -9.0847,  -8.0204,  -0.7488,  -6.3651,  -2.6979,  -7.8199,\n",
      "           -6.7309,   0.5889,  -1.9718,  14.9087,  -2.2587,  -1.3475,  -7.8297,\n",
      "            0.8956,  -4.8725, -11.6155,  -3.4235]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.2594,  -3.9215,  -6.5687,   0.9518,  -5.0632,  -2.1766,  -7.9765,\n",
      "           -6.3556,  -1.2174,   0.5177,  13.7816,  -0.9466,  -3.0403,  -6.6505,\n",
      "           -0.7474,  -5.2066, -12.1208,  -7.3062]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.9985,  -2.5074,  -6.6528,  -0.0886,  -4.3836,  -0.2434,  -7.3185,\n",
      "           -6.3003,   0.7254,  -0.2571,  14.3119,   0.9863,  -2.2850,  -4.1958,\n",
      "           -0.8501,  -6.3713, -12.7338,  -6.8529]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.9894,  -3.4812,  -5.3141,   0.3347,  -2.8575,  -0.8566,  -7.6576,\n",
      "           -3.9123,  -0.7531,  -2.0415,  12.7456,  -3.1985,  -2.6322,  -7.6628,\n",
      "            1.5150,  -5.1907, -11.1593,  -4.8932]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.8649,  -2.3388,  -6.6004,   1.5439,  -3.1985,   0.4957,  -6.6826,\n",
      "           -4.9101,  -0.8471,  -0.9194,  13.3078,   1.6151,  -1.4764,  -3.2673,\n",
      "            0.3360,  -5.7000, -11.4160,  -5.6571]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.0813e+01, -4.4692e+00, -6.5799e+00,  2.2538e+00, -1.3481e+00,\n",
      "          -4.5548e-01, -5.2315e+00, -4.5795e+00,  8.1703e-03, -1.8948e+00,\n",
      "           1.1531e+01, -5.6397e-01, -1.1316e+00, -4.7578e+00,  3.2311e+00,\n",
      "          -1.9008e+00, -5.7316e+00, -2.9000e+00]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.4118,  -5.0859,  -7.4715,   4.3341,  -2.3907,  -2.3466,  -9.3912,\n",
      "           -4.5139,   0.8044,  -0.4281,  13.9254,  -0.4758,  -3.5826,  -5.0536,\n",
      "            0.8523,  -3.9134, -12.3376,  -4.9406]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-15.4393,  -6.9911,  -8.7722,   2.9659,  -6.1039,  -2.1942, -10.3397,\n",
      "           -8.3656,  -2.3655,  -4.7052,  16.5810,  -1.4976,  -1.8979,  -5.0257,\n",
      "            4.2111,  -4.3134, -12.6053,  -4.6344]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.1497,  -5.3657,  -5.4233,   3.3532,  -4.6183,  -1.8160,  -9.2334,\n",
      "           -5.2391,  -0.0777,   1.1949,  13.5579,  -1.1487,  -1.8330,  -4.3799,\n",
      "           -0.4555,  -2.5664,  -9.4187,  -5.1670]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.4399,  -0.1989,  -5.0796,   3.1800,  -3.8913,  -0.4559,  -7.0119,\n",
      "           -5.9238,  -0.3673,  -1.5949,  11.4464,  -1.1431,  -3.7717,  -5.2133,\n",
      "            3.2598,  -5.2594, -10.7572,  -8.1650]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.7202, -5.4058, -4.9951, -2.1194,  2.8274,  1.4001, -8.0285,\n",
      "          -0.5287, -2.8074, -0.3040, 12.8355, -0.2286,  1.9793, -8.1768,\n",
      "          -0.1689, -4.1319, -8.3858,  0.6856]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.2818,  -4.4431,  -5.8790,   1.4019,   2.4244,   0.0662,  -3.8048,\n",
      "           -2.1589,   3.7575,   1.7853,  15.8471,  -0.9466,  -3.1288,  -5.7320,\n",
      "            1.1343,  -5.5423, -10.9608,  -1.3601]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.1897,  -4.0241,  -5.0067,  -0.7173,  -2.4367,  -1.5371,  -2.5958,\n",
      "           -6.2087,   0.5246,  -1.2520,  11.8596,   1.9852,  -0.9428,  -3.7051,\n",
      "            2.4868,  -6.9462, -10.4311,  -1.9602]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.5351, -11.2157,  -9.3007,   6.8936,  -3.1273,  -2.3927,  -8.7012,\n",
      "           -4.2566,   3.3352,   4.4071,  14.8655,  -1.7213,  -4.2678, -10.2427,\n",
      "           -1.1138,  -2.5538, -11.0705,  -1.7741]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.8030, -12.3978,  -7.3073,   1.1870,  -3.4040,   0.0889, -12.6721,\n",
      "           -2.2811,  -1.4625,  -2.1623,  15.4682,  -7.3943,   0.8898,  -8.6162,\n",
      "           -1.3722,  -2.0926, -11.5351,  -0.0264]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.5827,  -9.2454, -10.0834,  -2.8826,  -5.2463,   5.2243, -10.3769,\n",
      "           -2.1276,  -4.5056,  -0.0799,  14.8536,  -0.0487,   0.7236, -11.2186,\n",
      "           -0.8059,  -2.3816, -11.5510,  -5.4069]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.8032,  -6.7131,  -7.1330,  -2.4288,  -5.8022,  -4.1222,  -5.3847,\n",
      "           -5.7269,  -1.8026,  -2.3872,  14.5659,  -5.3882,  -2.6770, -10.8406,\n",
      "            5.3425,  -4.2458, -11.9670,  -5.6416]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.8712,  -3.6933,  -5.1593,   3.7295,  -2.6201,  -2.8120,  -7.3923,\n",
      "           -5.0472,   0.1388,  -0.2779,  11.7351,   2.1377,  -2.8709,  -4.7430,\n",
      "            1.4031,  -3.5006, -11.0704,  -3.9130]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.9935,  -8.0035,  -6.5102,  -1.1773,  -1.9894,  -0.4486, -11.0520,\n",
      "           -5.9072,   2.9918,   2.4015,  14.1308,  -1.0046,  -3.0377,  -8.8758,\n",
      "            0.0878,  -8.7164, -15.2736,  -3.8498]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-13.8880,  -7.3035, -10.2895,   1.6052,  -5.3578,   3.2944,  -7.9444,\n",
      "           -4.9222,  -0.5841,  -3.1422,  13.7150,  -1.4742,  -1.6330,  -6.3031,\n",
      "            2.2628,  -5.8078, -12.9395,  -5.9454]]])\n",
      "Predicted Label Index: 10\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.0487, -0.4180, -0.2819,  1.5542, -1.6166,  0.7667, -7.1334,\n",
      "          -4.8136, -0.0448,  3.1452,  0.9583, 11.9368,  0.2209, -3.0080,\n",
      "          -0.6739, -5.2849, -7.4276, -3.8682]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.3095, -2.7084, -4.1519,  1.0677, -4.1669, -0.4509, -8.8232,\n",
      "          -7.5222,  0.4416,  3.9427,  2.1163, 13.6312, -0.3578, -3.2186,\n",
      "          -2.5410, -7.6131, -9.0691, -6.0510]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.3270, -0.4516, -2.2372, -0.2023, -4.4925, -3.0953, -8.4684,\n",
      "          -5.8893,  0.9622,  1.5260,  1.9931, 12.8478, -1.0591, -0.9230,\n",
      "          -3.3769, -5.9656, -7.2949, -5.9360]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.2551,  1.1727, -0.8159,  0.2865, -4.1462, -1.1422, -7.5548,\n",
      "          -5.7494, -0.2752,  1.1921, -1.9379, 11.8456,  0.7773, -2.9654,\n",
      "          -1.0647, -3.6966, -5.2380, -5.0677]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.7647, -0.8372, -3.5089,  0.5690, -2.3177,  1.6784, -7.5264,\n",
      "          -5.6576, -0.5988,  2.2655, -1.1705, 10.8706,  0.4213, -3.7021,\n",
      "          -0.2785, -5.7834, -7.4601, -5.4009]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.0412, -0.9648, -2.8949,  1.7366, -3.0988, -0.8192, -8.7753,\n",
      "          -6.3533,  0.7618,  1.0034,  0.0538, 11.7642, -0.0376, -2.7134,\n",
      "          -1.2617, -5.7148, -7.5630, -4.1618]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.7047, -0.0573, -3.2678,  1.3069, -3.4121,  0.0489, -8.9845,\n",
      "          -5.7893,  0.1247,  2.0477,  0.1326, 13.8089,  0.0704, -4.2462,\n",
      "          -0.8328, -6.9755, -9.3858, -7.1428]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.0286,  0.1112, -3.9225,  0.5892, -5.2542, -0.2571, -8.3753,\n",
      "          -5.4745, -0.4109,  2.3018, -1.5276, 14.3781,  0.3072, -4.6208,\n",
      "          -1.2517, -5.9893, -8.2692, -7.9972]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.8995,  0.2022, -1.9485,  1.7292, -4.7292, -1.9665, -8.2779,\n",
      "          -6.2406,  0.5601,  2.1661, -0.9958, 12.7609, -0.3492, -2.6376,\n",
      "          -2.0080, -5.0690, -7.3825, -5.7976]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.8547, -0.0195, -2.3645,  2.3834, -5.7175, -2.7352, -9.6610,\n",
      "          -6.4620,  1.9406,  1.2345, -1.1176, 15.6291, -0.3420, -2.7776,\n",
      "          -2.2132, -6.8644, -9.2770, -6.4403]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.3027, -2.1187, -3.9725,  3.1616, -3.3840,  0.3502, -9.7435,\n",
      "          -7.8660,  0.1667,  3.2136,  1.4221, 13.0502, -0.0450, -4.1271,\n",
      "          -1.5356, -6.4053, -8.5887, -4.7702]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.7181, -1.8403, -2.1193,  0.9508, -2.6304,  1.3779, -8.0778,\n",
      "          -6.4825,  0.6038,  3.0378, -0.0699, 11.8371,  0.2858, -2.7588,\n",
      "          -1.6662, -6.3733, -7.6389, -4.4802]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.9103e+00, -1.4318e+00, -3.5548e+00,  2.9093e+00, -4.6765e+00,\n",
      "          -1.3560e+00, -9.0724e+00, -7.7977e+00,  6.9457e-01,  2.9646e+00,\n",
      "           7.6550e-03,  1.3547e+01, -6.9287e-01, -3.8857e+00, -2.3042e+00,\n",
      "          -7.1260e+00, -9.2900e+00, -6.7902e+00]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.8188,  0.5085, -3.1978,  0.7957, -6.0226, -0.2091, -9.2455,\n",
      "          -7.6683,  0.3635,  0.4147, -2.1551, 13.2032,  0.5299, -2.4565,\n",
      "          -2.3632, -6.3556, -8.3150, -6.5993]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.2703,  1.1194, -1.1318,  1.3550, -3.8049,  1.7731, -8.3915,\n",
      "          -6.0804,  0.0561,  3.7159,  1.0161, 13.1407,  0.0659, -3.2748,\n",
      "          -1.8979, -5.0115, -7.0815, -7.0303]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.9830e+00,  4.2271e-01, -1.0947e+00,  1.1628e+00, -3.2761e+00,\n",
      "          -5.1142e-03, -8.1635e+00, -6.4392e+00,  4.8620e-01, -5.6004e-01,\n",
      "          -6.7582e-01,  1.0612e+01,  8.4233e-01, -1.3217e+00, -1.9728e+00,\n",
      "          -5.8479e+00, -7.0876e+00, -2.8706e+00]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.4643,  1.6556,  0.1886,  0.5069, -3.0069, -0.6461, -8.1449,\n",
      "          -7.5206, -0.1521,  3.2751,  0.1240, 12.6755,  0.4484, -3.5594,\n",
      "          -1.0809, -4.3217, -6.5077, -5.2136]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.6860,  1.6246, -2.2850,  1.4211, -3.9004, -0.1797, -8.2697,\n",
      "          -6.1510, -0.6261,  2.4086,  1.5731, 11.9639,  0.4709, -3.2269,\n",
      "          -2.1485, -4.8912, -6.6236, -7.0467]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.6607, -2.4586, -4.1227,  3.1839, -4.0648,  1.4532, -9.4179,\n",
      "          -4.1016,  0.7927, -0.2222, -1.9196, 10.7195, -0.0886, -1.6675,\n",
      "          -2.0451, -5.9109, -6.6230, -5.1719]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.0287,   0.5055,  -2.4967,   1.3100,  -4.3328,  -0.2394,  -7.4348,\n",
      "           -6.0746,   1.0920,   2.5282,   1.2300,  11.6857,  -1.0441,  -2.2129,\n",
      "           -0.9610,  -6.1206,  -9.2197,  -7.8707]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.1019,  -1.7481,  -3.0497,   1.7345,  -4.2252,  -1.4756,  -9.5589,\n",
      "           -7.3226,  -0.4607,   2.9636,   1.1729,  15.7481,   0.7040,  -3.2452,\n",
      "           -1.7890,  -6.6753,  -9.1535,  -6.7334]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.5573, -0.1261, -1.9278,  1.5398, -4.7186,  1.0279, -9.7235,\n",
      "          -6.4976, -1.4532,  2.8501, -0.1229, 12.9241,  0.9725, -3.2278,\n",
      "          -2.3099, -4.5014, -6.4918, -6.5720]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.9862, -1.8627, -2.7260,  1.5959, -3.6246, -0.4202, -9.3980,\n",
      "          -7.8726,  1.9205,  3.4525,  1.3868, 14.1083, -0.6420, -2.7303,\n",
      "          -1.4368, -7.5946, -9.9157, -6.0881]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.9862,  1.7317, -2.3775,  2.6553, -6.1114, -2.0106, -8.3708,\n",
      "          -6.6740,  0.8433,  1.1231, -0.7925, 12.4303, -0.6401, -2.2464,\n",
      "          -2.9632, -5.7979, -8.8687, -7.7284]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.2851e+00,  4.2090e-03, -3.4806e+00,  2.2684e+00, -3.9154e+00,\n",
      "          -3.1819e-01, -8.3315e+00, -6.6964e+00, -1.2845e-01,  1.2847e+00,\n",
      "           8.9724e-02,  1.2131e+01, -4.7559e-02, -2.7130e+00, -9.1495e-01,\n",
      "          -4.1162e+00, -7.3412e+00, -6.2683e+00]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.1514, -0.3274, -2.2284,  0.5399, -5.3850, -1.7961, -7.8225,\n",
      "          -6.4457, -0.3364,  1.9770,  0.7898, 12.2475,  0.3865, -2.6187,\n",
      "          -1.7748, -4.8072, -6.8539, -6.3247]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.1885,  -0.5121,  -4.3652,   1.1786,  -4.6023,  -0.2691,  -8.7700,\n",
      "           -6.7280,   1.1303,   0.0275,   0.4527,  13.4269,  -0.3432,  -1.8803,\n",
      "           -0.8222,  -6.7106,  -9.0815,  -6.8699]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.5616,  -0.2485,  -3.2101,   2.2541,  -5.8807,  -0.7788,  -6.1752,\n",
      "           -6.3542,   1.0510,   3.1568,   0.1226,  12.9763,  -0.0876,  -2.6927,\n",
      "           -1.7798,  -5.9211,  -7.9524,  -7.8063]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.1926, -1.0198, -3.0575,  1.2393, -3.8605, -2.6956, -7.7759,\n",
      "          -7.4493,  1.5292,  0.3955, -1.2184, 10.1855, -1.2190, -2.4763,\n",
      "          -0.0626, -5.3539, -8.0754, -4.1818]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.7149, -0.2540, -3.3236,  1.8232, -4.4399,  1.8911, -8.1143,\n",
      "          -5.7339, -0.6398,  1.9576, -0.0389, 11.6341,  1.1083, -3.3084,\n",
      "          -1.0703, -4.5665, -6.3786, -6.4764]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.8433,  -2.2794,  -2.0922,   1.8804,  -3.2221,   2.4660, -10.7349,\n",
      "           -7.5992,   0.2708,   3.4962,  -1.0804,  15.4391,   1.1130,  -4.6026,\n",
      "           -2.4848,  -8.5790,  -9.4342,  -4.5606]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.9117, -1.0695, -3.6301,  1.9700, -4.3939, -0.2369, -9.8325,\n",
      "          -5.9831, -0.3000,  2.1088,  0.8179, 12.3928, -0.0416, -3.1225,\n",
      "          -2.6939, -5.6992, -7.7267, -6.3751]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.0946, -1.2742, -4.2927,  0.5076, -5.2216, -1.4532, -9.0663,\n",
      "          -6.6619,  0.3141,  2.2567, -0.9312, 15.8097, -0.0485, -3.9527,\n",
      "          -1.3803, -6.1359, -7.9029, -7.0611]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.5474, -0.8946, -1.5995,  0.9209, -3.6752,  0.9749, -9.1795,\n",
      "          -7.3519,  0.3487,  2.5311, -0.9954, 13.7137,  0.9767, -3.2269,\n",
      "          -1.7110, -5.6589, -7.2659, -3.7630]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.2798, -2.2533, -3.6699,  1.4664, -5.5025, -1.3744, -8.3186,\n",
      "          -5.9515,  1.3966,  2.2117, -1.1044, 13.7535, -0.2913, -3.0254,\n",
      "          -1.9307, -7.2015, -9.1925, -6.5430]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.6638,  0.2761, -1.6708, -0.0186, -4.8275, -0.4675, -8.4706,\n",
      "          -7.8968,  0.8149,  3.1218, -0.7661, 14.6488,  0.2734, -2.9063,\n",
      "          -1.5728, -6.1258, -8.6218, -6.9167]]])\n",
      "Predicted Label Index: 11\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.5263, -4.4643, -3.5630, -7.9065, -0.9408, -5.6926, -1.1474,\n",
      "           0.0371, -2.1037, -7.1407, -2.5085, -4.0466,  9.7654, -4.3656,\n",
      "          -8.4684, -4.6333, -2.4671, -1.0290]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.1771, -3.5934, -5.2881, -7.5683, -3.1119, -5.5313, -4.2025,\n",
      "          -1.0400, -4.9511, -8.6491, -3.8746, -0.2626, 12.1652, -4.5993,\n",
      "          -7.3148, -1.9482, -0.7060,  0.3082]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.2584, -4.5572, -6.0803, -8.9687, -3.2497, -6.1990, -1.2141,\n",
      "           0.3020, -5.1891, -7.9777, -1.7305, -3.2776, 13.2781, -6.9372,\n",
      "          -7.6754, -1.5572, -1.6325,  1.3034]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.8969, -3.4932, -6.1489, -5.8749, -3.6963, -7.0101, -3.8478,\n",
      "          -0.0873, -4.3428, -9.0626, -1.9171, -2.5003,  9.8395, -4.7576,\n",
      "          -6.9271,  0.5849, -0.9847,  0.8929]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.4172, -4.4279, -5.8192, -9.9970, -1.3275, -7.2830,  1.1090,\n",
      "           2.8688, -5.6873, -8.5944, -1.7485, -6.4543, 13.5171, -9.8831,\n",
      "          -7.3859, -1.8049, -1.2458,  0.4146]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.3539, -3.0258, -5.5939, -5.1385, -1.9580, -4.2406, -4.9425,\n",
      "           0.3875, -4.0593, -8.4745, -3.3129, -1.4610,  9.4989, -3.8153,\n",
      "          -7.7384, -1.3790, -0.8824, -0.7365]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.9556, -2.7529, -4.3012, -8.7735, -2.7079, -4.9079,  1.0810,\n",
      "           3.7599, -3.9126, -8.3098,  0.5091, -6.5213, 11.2332, -7.8975,\n",
      "          -6.8840, -2.7805, -0.6766, -3.3686]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.5894, -5.0598, -6.1325, -6.7619, -0.9852, -4.8855, -1.1414,\n",
      "           1.1979, -3.4184, -6.5628, -3.2691, -4.9537, 10.8025, -4.6497,\n",
      "          -9.7964, -4.4438,  0.3543, -2.3504]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.3521,  -4.5660,  -3.4505,  -9.0300,  -0.3448,  -6.1616,  -0.2772,\n",
      "           -0.2271,  -4.0826,  -5.6445,  -1.8611,  -5.2022,  11.6157,  -4.4183,\n",
      "          -10.3839,  -4.3265,   2.1927,  -1.1205]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.5023, -3.2165, -3.8117, -5.8687, -4.3477, -5.4613, -4.2658,\n",
      "          -0.8502, -5.7008, -8.9934, -4.3032, -0.4563, 13.0721, -5.6679,\n",
      "          -7.8327, -2.5859, -1.5035, -2.1692]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.5225, -3.9007, -3.7328, -8.5579,  0.0780, -5.1830,  0.4786,\n",
      "           2.0120, -3.8309, -6.9540, -1.5146, -4.2280, 11.3459, -6.1245,\n",
      "          -7.1908, -5.1852, -0.5868, -1.7935]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.7250, -4.2381, -4.9016, -7.8363, -4.5222, -6.3309, -2.0906,\n",
      "           0.9721, -4.0249, -8.9748, -2.3742, -4.6597, 11.7731, -5.6697,\n",
      "          -9.5013, -0.1085, -1.6553, -0.3748]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.3975, -2.7811, -4.3859, -7.5396, -3.0590, -6.0599, -0.2605,\n",
      "          -1.7035, -4.1291, -6.1542, -2.1681, -2.4985, 11.7959, -8.4424,\n",
      "          -4.1094, -1.0274, -1.1024,  1.1367]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.5148, -3.5507, -4.6008, -6.1580, -3.1390, -2.7005, -3.8255,\n",
      "           0.2822, -4.4850, -7.3839, -2.7113, -2.1555, 11.5805, -4.2074,\n",
      "          -9.6821, -1.8536, -0.9075, -0.3612]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.8114, -6.7043, -2.2599, -6.6988, -1.0789, -6.5563, -1.4199,\n",
      "           0.9394, -2.8360, -6.7338, -0.6938, -4.0046,  9.8608, -4.2984,\n",
      "          -8.7245, -4.3123, -0.4315, -1.3476]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.4666, -5.1814, -6.7971, -7.0800, -3.1098, -6.9865, -4.6363,\n",
      "          -0.3886, -4.7630, -8.8234, -1.7344, -3.2578, 11.1531, -3.6453,\n",
      "          -9.0699, -1.1196, -0.0316, -0.1772]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.5279,  -2.3590,  -1.4094, -10.6293,  -3.0534,  -6.4899,  -0.6188,\n",
      "            0.2054,  -5.8489,  -7.3192,  -1.0705,  -5.6883,  12.8886,  -4.1184,\n",
      "          -11.6555,  -2.6185,   1.1653,  -1.9067]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.0003, -4.3243, -2.6584, -8.3594,  0.2126, -6.7384, -3.0560,\n",
      "           1.3157, -6.4723, -8.7728, -2.3792, -4.8215, 10.9314, -5.1875,\n",
      "          -6.7800, -1.8097,  0.6231, -1.3308]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.2279, -4.2692, -3.0032, -9.1810, -2.8095, -6.2588, -0.1107,\n",
      "           0.4506, -4.2121, -6.4855, -2.1584, -4.1391, 11.3088, -6.4710,\n",
      "          -9.7838, -3.9694, -1.8574, -0.6874]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.9387, -3.8959, -4.2581, -9.3709, -4.1287, -9.5364, -2.4285,\n",
      "          -0.3233, -5.6261, -9.9568, -1.7278, -4.9179, 12.7697, -8.5265,\n",
      "          -8.2607,  0.9104,  0.1270,  0.8918]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.8821,  -5.4047,  -7.6553,  -9.1851,  -0.3145,  -7.0245,  -2.1155,\n",
      "           -0.5512,  -3.5106, -11.1349,  -4.5914,  -7.1090,  12.4395,  -6.0269,\n",
      "           -8.9569,  -1.5772,  -0.2101,   0.5182]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.1990,  -5.5328,  -6.2060,  -9.1676,  -3.2054,  -6.1636,  -2.4086,\n",
      "           -1.6683,  -3.7539,  -6.9058,  -3.5202,  -1.9236,  13.8615,  -7.6925,\n",
      "          -12.7401,  -4.0343,   0.0195,   0.0779]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.7253, -4.4558, -4.7678, -7.5864, -4.0353, -6.7967, -2.1147,\n",
      "           0.8574, -4.3354, -7.3444, -1.9779, -4.1309, 11.2901, -5.8543,\n",
      "          -9.1901, -1.2804, -1.8504, -0.5901]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.7520, -5.8931, -5.1443, -7.8215, -3.3845, -7.1597, -3.2117,\n",
      "          -1.6434, -4.2527, -6.6244, -2.4318, -2.4927, 11.2698, -5.1334,\n",
      "          -9.1258, -1.3362, -1.3444,  0.9392]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.6198,  -4.8385,  -6.1749, -10.5222,  -2.6067,  -6.7808,   0.2330,\n",
      "            0.1450,  -5.9308,  -7.6718,  -1.1464,  -6.7418,  14.3604,  -8.7463,\n",
      "          -11.3179,  -1.7807,   1.0569,  -1.6765]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.6144,  -4.3067,  -3.3818,  -9.4497,  -4.0673,  -7.0362,  -1.4440,\n",
      "           -1.0253,  -5.1221,  -7.3511,  -0.0976,  -5.2206,  12.3351,  -5.4911,\n",
      "          -10.2897,  -1.1188,   1.9286,  -0.9643]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.2457,  -3.0097,  -2.5252,  -8.7246,  -3.9838,  -7.0805,  -2.4286,\n",
      "           -0.2420,  -5.2864,  -7.5176,  -3.1709,  -3.8691,  11.4537,  -5.9504,\n",
      "          -10.9849,  -1.6427,  -0.5507,  -0.5345]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.4438, -3.6311, -6.0395, -9.4569, -1.5234, -6.9611,  0.4573,\n",
      "           1.4147, -4.1299, -8.6925, -2.4923, -6.3701, 11.8671, -8.6149,\n",
      "          -7.3390, -1.8282, -0.1579, -2.5362]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.9659, -5.0218, -4.9540, -8.8770, -4.2216, -6.4197, -2.4145,\n",
      "           1.5517, -4.5536, -7.7729,  0.2737, -2.2675, 13.0452, -8.4569,\n",
      "          -7.0298, -1.1123, -1.2601, -1.4207]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.8585, -3.7757, -4.1273, -7.6913, -2.9145, -5.6192, -3.3804,\n",
      "           0.8300, -5.0042, -7.9437, -1.3103, -3.8318, 11.5235, -5.6498,\n",
      "          -9.9338, -1.1741, -0.6916, -1.1489]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.3144,  -2.2380,  -2.7959,  -6.7284,  -3.6879,  -4.7366,  -3.3270,\n",
      "           -0.1626,  -4.5781,  -7.0892,  -3.8450,  -3.4352,  10.1883,  -3.7203,\n",
      "          -10.1312,  -1.3378,   2.4613,  -3.1611]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.4028, -3.7372, -3.8663, -7.8183, -4.6080, -6.2445, -1.1125,\n",
      "           1.3614, -3.9549, -7.3001, -2.6271, -2.2640, 11.1992, -6.9601,\n",
      "          -8.2414, -1.3209, -0.5758, -1.1421]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.7714,  -2.6232,  -4.9250,  -9.2122,  -1.3443,  -5.3399,  -3.8491,\n",
      "           -0.5740,  -5.6621,  -8.9351,  -2.0334,  -2.2743,  13.4571,  -7.1324,\n",
      "          -10.6935,  -2.5739,  -0.0643,  -0.3898]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.9165, -1.1618, -2.5526, -9.4390, -3.5593, -4.4121, -3.9595,\n",
      "          -0.6119, -6.9448, -7.0559, -1.0793, -2.1414, 11.7438, -7.0509,\n",
      "          -6.8218,  0.1274, -1.1225, -0.3533]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.8995,  -1.3850,  -3.4377, -10.2025,  -4.1457,  -7.9136,  -0.1184,\n",
      "           -2.6943,  -4.9354,  -7.3064,  -1.8124,  -2.3489,  12.9451,  -8.3302,\n",
      "           -6.2223,  -0.9105,  -0.8976,   0.3898]]])\n",
      "Predicted Label Index: 12\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.0324,  -7.3198,   2.1543,  -3.8315,  -3.5357,  -1.4238, -10.0603,\n",
      "           -0.8462,  -2.6200,  -6.6474,  -0.9786,  -2.2400,   0.2991,  12.1932,\n",
      "          -11.0222,  -4.0546,  -5.2035,  -0.8687]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.9379,  -9.5892,   4.2073,  -0.6290,  -2.0123,  -1.4174, -10.6063,\n",
      "           -2.0070,  -2.8364,  -4.0186,  -0.0590,  -4.8524,  -3.2396,  15.2361,\n",
      "           -9.8754,  -2.9790,  -0.9464,  -0.4330]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.8026,  -7.1968,   3.9654,  -1.7317,  -0.6552,   1.0520,  -7.8988,\n",
      "           -1.5285,  -4.5101,  -3.0642,  -0.8767,  -5.8112,  -0.8858,  14.6194,\n",
      "          -13.3933,  -5.7874,   1.8488,  -3.5873]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.0289e+01, -6.5726e+00,  5.4910e+00, -2.3932e+00, -1.9075e+00,\n",
      "          -2.8754e-01, -1.1003e+01, -3.6254e+00, -4.9297e+00, -4.8410e+00,\n",
      "          -2.1507e+00, -4.5346e+00, -1.1315e+00,  1.6724e+01, -1.4386e+01,\n",
      "          -6.4083e+00, -1.0324e-03, -4.2738e+00]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.8860, -10.1724,   1.7203,  -1.7302,  -1.9293,  -1.8347,  -7.8150,\n",
      "           -1.9960,  -2.3015,  -4.0094,  -1.2515,  -5.3871,  -1.4631,  14.0561,\n",
      "          -10.6471,  -4.4638,  -1.4639,  -1.4211]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.2012,  -6.6198,   4.5844,   1.1514,  -6.5657,  -1.3028, -11.5177,\n",
      "           -1.3430,  -2.8181,  -5.0855,  -2.0908,  -1.8327,  -3.4254,  14.1747,\n",
      "           -9.1153,  -2.8476,  -3.6629,  -3.2218]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.8490, -6.9272,  1.3556, -1.5124, -3.5246,  0.8381, -9.0481,\n",
      "          -0.3607, -2.8485, -4.9768, -0.8869, -3.9127, -1.8969, 15.1837,\n",
      "          -9.6254, -5.2527, -4.9784, -3.3299]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.5043,  -6.5208,   4.4369,  -1.2015,  -2.1866,  -0.2114, -11.9261,\n",
      "           -1.1651,  -4.0517,  -6.7590,   0.1835,  -4.5147,  -2.1382,  17.2554,\n",
      "          -12.4552,  -4.8840,  -1.6169,  -2.1279]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.8277,  -5.6944,   2.3158,  -0.1173,  -1.3288,   1.6338, -10.0019,\n",
      "            0.0651,  -1.9123,  -6.3979,  -0.4913,  -6.6148,  -3.1498,  17.1034,\n",
      "          -12.0560,  -8.2039,  -2.1541,  -4.2186]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.0769,  -8.7210,   2.1029,  -0.0710,  -3.1551,   0.7128,  -8.4951,\n",
      "            0.5013,  -3.1156,  -5.8742,  -0.6255,  -9.6005,  -2.9043,  17.5929,\n",
      "          -14.6197,  -6.3610,   0.5829,  -4.4954]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.0914,  -8.2071,   2.7707,   1.1102,  -3.3848,  -1.0242,  -8.5347,\n",
      "            1.7305,  -0.6813,  -5.1463,  -0.9338,  -4.1882,  -2.6041,  14.9583,\n",
      "          -12.2002,  -7.1591,  -2.2661,  -3.5208]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.6718, -6.9248,  4.2441, -2.6082, -3.8708, -2.3473, -6.7676,\n",
      "          -1.0379, -2.5988, -5.9233, -1.5433, -6.4345, -3.5765, 12.0171,\n",
      "          -9.1291, -3.0966, -1.3564, -0.2090]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.0785,  -6.2701,   3.3869,   1.1168,  -2.3425,   0.3321,  -9.2070,\n",
      "           -1.7032,  -2.9804,  -2.6393,  -0.7420,  -3.5126,  -1.8109,  16.0974,\n",
      "          -13.6909,  -5.4319,   1.2363,  -3.0647]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.6136,  -7.8846,   3.3359,  -1.4685,  -1.3436,  -0.0385, -10.3714,\n",
      "            0.7845,  -3.2984,  -6.3086,  -0.2405,  -5.5586,  -0.8778,  16.0408,\n",
      "          -14.9443,  -5.6520,  -0.0522,  -1.8576]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.9903, -8.8081,  0.3004, -1.1972, -3.3079,  0.1675, -5.8508,\n",
      "           0.1110, -2.1551, -4.4856, -0.8516, -6.1322, -0.1109, 12.0598,\n",
      "          -9.6020, -5.2522,  0.7296, -2.0769]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.4532e+00, -8.1000e+00,  3.8971e+00,  2.6399e+00, -3.2386e+00,\n",
      "          -1.6022e-02, -1.3676e+01, -1.9600e+00, -4.9570e+00, -5.2583e+00,\n",
      "          -1.7206e+00, -3.4685e+00, -1.7960e+00,  1.8021e+01, -1.4170e+01,\n",
      "          -2.5356e+00,  1.8539e+00, -3.0503e+00]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.2646,  -7.9803,   3.5004,   0.9336,  -2.5296,   0.2072, -10.3424,\n",
      "            1.0422,  -3.5224,  -3.4982,   0.9997,  -5.7606,  -3.6953,  13.4687,\n",
      "           -8.6999,  -2.3974,  -1.6834,  -2.6465]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.1747,  -5.7510,   1.6427,  -0.2395,  -1.8803,   1.4200,  -7.2138,\n",
      "           -0.0948,  -2.7405,  -4.1525,   0.7059,  -3.8155,  -1.1394,  14.0631,\n",
      "          -10.6522,  -5.5197,  -0.4917,  -1.7489]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.6181,  -5.4804,   4.0763,   0.4947,  -2.3850,   2.8463, -10.6559,\n",
      "            0.2086,  -2.6898,  -3.7956,  -0.1150,  -3.2366,  -2.4714,  17.1463,\n",
      "          -13.3173,  -7.0112,  -1.3591,  -4.7371]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.9705,  -5.4268,   3.7054,   1.1961,  -3.2686,   0.7489, -10.9544,\n",
      "           -0.3632,  -3.2643,  -4.4951,  -2.3202,  -2.2839,  -1.4400,  14.9098,\n",
      "          -11.7624,  -6.4710,   0.1356,  -4.1931]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.0781,  -6.9944,   3.6229,  -1.1900,  -2.7779,   2.2511,  -8.7950,\n",
      "           -1.2732,  -2.5573,  -3.5455,  -1.2042,  -2.7239,  -0.6945,  15.9762,\n",
      "          -14.9767,  -7.6040,  -1.0743,  -3.9656]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.6959,  -7.0064,   2.5456,   0.9801,  -2.8972,  -0.4046, -11.1278,\n",
      "           -2.8893,  -3.7113,  -2.7931,   0.4010,  -1.9089,  -1.3032,  15.2772,\n",
      "          -14.4386,  -4.6309,   0.8376,  -3.1075]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.7896, -9.0028,  3.6205, -1.5660, -2.2135, -1.9916, -6.4643,\n",
      "           0.5376, -2.1901, -3.8780, -1.3634, -6.2279, -1.9186, 13.7817,\n",
      "          -9.9938, -3.6650, -1.3172, -1.7120]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.3577, -5.7649,  1.0371,  0.9943, -3.2413, -0.8430, -6.4001,\n",
      "          -1.4519, -2.2006, -2.7596, -0.7242, -3.5122, -2.0410, 13.9374,\n",
      "          -9.4575, -3.6462, -1.3570, -3.8867]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.8242,  -8.2541,   1.6459,  -0.5143,  -3.4840,   1.0257, -11.6504,\n",
      "           -1.9175,  -3.4978,  -5.9518,  -1.0681,  -1.6683,  -0.9864,  18.1548,\n",
      "          -14.8046,  -7.4446,  -3.5981,  -1.4651]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.2793,  -8.3177,   2.9193,   0.8763,  -4.4698,  -1.8149,  -9.8541,\n",
      "           -2.6653,  -2.0864,  -2.1802,  -1.9720,  -0.5393,  -1.3892,  13.4217,\n",
      "          -11.7106,  -3.2605,  -2.1481,  -1.9267]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.8315,  -6.4634,   3.4172,  -1.2337,  -2.4937,  -0.0519,  -8.9901,\n",
      "           -0.0865,  -3.6980,  -4.5148,   1.5946,  -2.3711,  -0.6234,  14.6639,\n",
      "          -13.2928,  -5.2782,  -1.1450,  -1.2180]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.8046,  -5.6215,   2.6735,  -1.5392,  -3.6557,  -0.5384,  -8.2163,\n",
      "           -0.8997,  -4.5104,  -3.8132,   1.7061,  -1.9738,   1.2995,  12.5506,\n",
      "          -12.0605,  -3.6096,  -1.8724,  -2.3343]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.0982,  -6.5149,   2.3966,  -0.1503,  -4.2492,  -0.0512,  -7.2471,\n",
      "           -1.9630,  -4.1799,  -4.2134,   0.1564,  -7.4717,  -1.3802,  12.3454,\n",
      "          -10.0754,  -2.5426,   0.6761,  -3.1018]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.0029,  -6.5214,   4.6683,  -0.7020,  -4.0001,  -0.8352,  -8.5874,\n",
      "            0.4501,  -2.1149,  -4.1427,   0.1367,  -3.6340,  -1.3833,  15.6410,\n",
      "          -12.7954,  -5.9004,  -1.5862,  -3.7789]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.6628e+00, -6.0827e+00,  2.2665e+00, -1.1663e+00, -4.7479e+00,\n",
      "          -1.3839e-03, -8.7407e+00,  6.6129e-01, -1.3416e+00, -4.8653e+00,\n",
      "          -1.5171e+00, -2.9179e+00, -1.4396e+00,  1.4361e+01, -1.2938e+01,\n",
      "          -5.6369e+00, -2.6288e+00, -5.4921e+00]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.5986,  -6.7521,   3.0854,   0.0160,  -4.0974,  -1.2148,  -7.9461,\n",
      "           -0.7579,  -3.1889,  -4.0348,  -1.8726,  -3.6350,  -2.0837,  13.0883,\n",
      "          -11.3119,  -2.2591,  -1.7501,  -3.3571]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.6210,  -7.8071,   3.5504,  -1.7527,  -3.0329,  -1.6166,  -6.3707,\n",
      "           -1.0634,  -2.6342,  -3.6245,   0.2608,  -4.3548,  -1.3296,  13.1251,\n",
      "          -11.4336,  -4.8780,  -0.0383,  -2.9014]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.8180,  -7.6744,   4.0758,  -0.6996,  -2.1487,  -2.1351,  -7.3652,\n",
      "           -1.9842,  -2.9092,  -4.4268,  -0.9600,  -5.4934,  -3.4511,  15.6513,\n",
      "          -11.3446,  -4.4796,   0.3215,  -2.4188]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.2477,  -7.1139,   3.7830,   0.2816,  -2.6823,  -1.4304,  -9.4291,\n",
      "           -1.9586,  -3.9827,  -3.5838,  -0.4020,  -3.5570,  -1.6163,  12.2411,\n",
      "          -10.1421,  -2.9100,   2.0651,  -3.8994]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.7367,  -8.8670,   1.5671,  -1.6967,  -2.3081,  -1.6419,  -7.5148,\n",
      "            0.2932,  -3.3635,  -4.2859,  -0.8435,  -6.8982,  -0.7587,  14.6407,\n",
      "          -14.0837,  -4.1653,   0.1466,  -3.4877]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.8859,  -8.1901,   3.5138,  -0.0583,  -2.2132,  -0.8012, -10.2790,\n",
      "           -1.4355,  -2.2608,  -4.4224,  -0.0694,  -3.2736,  -2.0969,  14.7222,\n",
      "          -12.1031,  -3.3377,  -0.4715,  -0.2823]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.8360,  -7.3887,   3.4742,  -0.9104,  -1.8114,  -0.2211,  -8.8754,\n",
      "           -1.8097,  -2.4257,  -2.4804,  -0.1838,  -1.4779,  -1.2925,  17.1795,\n",
      "          -14.3237,  -7.8138,  -0.8529,  -3.1095]]])\n",
      "Predicted Label Index: 13\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.0494,  -1.3569,  -0.5654,  -1.1748,  -5.5829, -11.6711,  -2.3024,\n",
      "           -6.0116,   0.3411,  -2.2591,  -0.0709,   4.5118,  -2.9862,  -5.8424,\n",
      "           15.7940,   2.1915,  -9.4688,  -1.1449]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.3211,  2.6027,  0.1210, -1.3007,  0.6407, -4.9535, -4.8712,\n",
      "          -5.2527, -0.6842, -3.3086,  2.3134,  2.4415, -1.2892, -5.9235,\n",
      "          12.7713,  0.9662, -7.8168, -2.8217]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.0888, -0.8320, -3.0783,  1.2909, -3.1666, -7.3378, -1.8845,\n",
      "          -4.2765, -0.6055, -6.4926,  0.3375,  1.4071, -2.2224, -6.1540,\n",
      "          12.9839,  0.1337, -8.7217, -0.7096]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.5606,   2.1087,  -2.1978,   1.6061,  -0.1120,  -5.3776,  -5.8595,\n",
      "           -2.6691,   0.0247,  -7.3063,   3.0426,   1.2900,  -2.1568,  -3.8220,\n",
      "           13.8675,   0.3086, -10.4255,  -3.8159]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.4805,   2.2403,  -1.9280,  -2.7944,  -2.3262,  -7.9915,  -1.3869,\n",
      "           -5.3911,   2.3741,  -3.4576,   3.0125,   1.8680,  -4.6463,  -5.9849,\n",
      "           13.3220,  -0.1478, -10.7483,  -5.6006]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.0541,   0.9263,  -1.6574,   0.2105,   0.7214,  -5.5111,  -2.7649,\n",
      "           -4.5358,   1.2206,  -3.0563,   2.1500,   0.1961,  -3.4758,  -6.5086,\n",
      "           13.3692,  -1.2468, -10.1077,  -3.5259]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.1996,   3.6860,   0.4060,  -1.7157,  -0.3665,  -4.8447,  -7.1414,\n",
      "           -5.6604,  -0.2976,  -6.9109,   0.4815,   1.9570,  -1.9439,  -6.0876,\n",
      "           14.6423,  -0.9099, -11.2596,  -2.3520]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.9545,   2.1362,  -4.2107,   0.9951,  -1.6757,  -6.5733,  -0.2952,\n",
      "           -5.1035,   1.3105,  -5.5546,   1.7549,   0.2296,  -3.0259,  -2.6168,\n",
      "           13.6706,   0.8736,  -9.9634,  -2.3421]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.2794,  4.1132, -0.4571, -1.1009,  0.6800, -8.2234, -6.5456,\n",
      "          -7.3009,  0.2706, -7.2913,  1.5634, -0.4054, -4.8948, -5.3129,\n",
      "          15.3735,  1.8439, -9.8176, -4.0010]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.1145,   2.7929,  -1.9509,  -0.0982,  -0.5793,  -7.3577,  -4.9275,\n",
      "           -5.4573,   2.3688,  -6.7465,   1.2274,   1.6649,  -3.8868,  -4.1968,\n",
      "           13.5610,   1.7710,  -9.0480,  -3.1098]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.4866,   2.0276,  -2.0139,   0.2924,  -1.5686,  -6.5986,  -2.2269,\n",
      "           -5.1599,   0.3962,  -4.8242,   1.8603,   3.2360,  -1.8586,  -5.8851,\n",
      "           15.1003,  -0.6193, -10.2526,  -2.9343]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.1913,  1.3636,  0.3322,  1.5004,  2.2035, -5.5975, -7.8993,\n",
      "          -2.4656, -0.3367, -4.8595,  3.8571,  0.2453, -2.9801, -4.3910,\n",
      "          12.8298,  1.5412, -8.6705, -2.2128]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.2360,   4.5629,  -0.2002,  -3.1014,  -1.0696,  -5.8931,  -4.5227,\n",
      "           -8.3343,  -0.3100,  -4.4057,   1.5032,   0.3326,  -2.7431,  -5.8147,\n",
      "           13.3197,  -0.5584,  -9.0489,  -4.8137]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.9649,  0.7934, -1.9429,  2.6140, -1.1543, -1.6782, -2.3674,\n",
      "          -4.6062,  1.2953, -2.2413,  0.5465,  0.9152, -3.0788, -6.0012,\n",
      "          10.9391, -1.7066, -8.0913, -2.7381]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.1336,   2.2034,  -1.7723,  -2.2769,  -2.2754,  -6.5631,  -2.3414,\n",
      "           -5.2922,   1.7984,  -4.1575,   1.3149,   1.0043,  -2.8771,  -6.5006,\n",
      "           10.3985,  -3.1655,  -9.0996,  -5.1040]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.7323,  3.4419, -1.0958, -1.3652, -0.8647, -7.0334, -3.2389,\n",
      "          -7.4446,  0.9477, -3.9424,  1.7665,  2.2806, -2.0633, -3.4892,\n",
      "          13.1016,  2.1007, -8.0871, -4.3742]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.7008,  3.9410,  1.2002, -2.7749, -2.0256, -5.3639, -3.2155,\n",
      "          -6.8407,  1.2510, -4.0987,  0.5649,  0.9319, -2.4619, -4.6220,\n",
      "          13.0287, -0.0810, -8.6049, -2.5954]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.2459,   3.5572,  -0.5464,  -1.4987,  -0.9160,  -7.6437,  -4.1084,\n",
      "           -6.8083,   1.6290,  -5.0201,   1.6680,   2.0782,  -2.9743,  -6.7242,\n",
      "           14.6017,   0.2509,  -9.8451,  -3.0253]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.9796,   3.2294,  -1.2667,  -0.1702,  -1.5542,  -5.5676,  -2.3446,\n",
      "           -3.7518,   0.7528,  -4.3801,   0.5516,   2.9566,  -1.9106,  -4.9898,\n",
      "           12.5276,  -1.1767, -10.0625,  -3.5643]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.2204,  3.3720,  0.5925, -1.0398, -0.7379, -5.2342, -6.8056,\n",
      "          -3.8430, -0.4793, -5.2829,  3.2273, -0.6004, -3.3748, -5.7502,\n",
      "          12.8817,  0.3579, -8.3024, -4.6327]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.9558, -0.5839, -2.3170, -0.4769, -1.8741, -6.6849, -4.2016,\n",
      "          -5.0803,  1.9367, -2.7899, -2.2173, -0.0112, -2.7940, -5.9116,\n",
      "           9.6883, -0.3850, -7.9648, -0.7901]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.6794,   1.8458,  -0.1382,  -1.4635,   3.4630,  -0.4417, -10.5797,\n",
      "           -2.6445,  -3.0329,  -5.0482,  -1.1506,   2.5417,  -4.1269,  -4.5103,\n",
      "           13.4772,   1.8610,  -4.9482,  -3.1504]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.1798, -0.6120, -1.4326, -1.4135, -0.8762, -2.4498, -3.3901,\n",
      "          -5.6371, -0.7255, -4.6774,  0.5894,  1.2992, -2.3620, -2.4491,\n",
      "          11.6320,  1.1312, -6.1963, -2.1856]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.4532, -0.7057, -0.2840,  0.7188,  1.5299, -2.0061, -4.5931,\n",
      "           2.5098,  1.6351, -1.1446,  1.8104,  0.2433, -1.1483, -7.1190,\n",
      "          10.8304,  0.7830, -7.1898, -2.7084]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.4063,   2.9675,  -0.4624,  -3.7618,  -1.9754,  -8.5573,  -3.0192,\n",
      "           -6.8657,   3.5576,  -2.1547,   3.2065,   0.8640,  -4.8332,  -5.7142,\n",
      "           13.0898,  -0.8155, -11.3681,  -5.1342]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.3079, -1.6547, -0.2376, -3.3324, -0.0304, -8.0945, -3.4784,\n",
      "          -3.3000, -0.2316, -4.4092, -1.0557,  0.5022, -3.0239, -1.1310,\n",
      "          11.0158,  0.9007, -7.2322,  1.0445]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.0334, -2.6264, -1.7547, -1.7945, -3.2811, -7.3627, -2.9079,\n",
      "          -3.6367, -0.4866, -1.3518,  0.7146,  1.1503, -2.5374, -8.1578,\n",
      "          10.4050,  0.8841, -8.4790, -2.7896]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.1656,   0.6186,  -2.9264,  -0.8679,  -0.3289,  -8.5611,  -4.6288,\n",
      "           -6.0085,   0.9743,  -6.2275,   1.1857,   1.0963,  -3.3013,  -5.0376,\n",
      "           13.7612,  -1.3084, -10.2486,  -2.9324]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-12.4447,   3.3494,  -1.1854,  -0.1846,   0.3479,  -4.6766,  -5.0565,\n",
      "           -5.2516,   1.5061,  -4.0034,   2.7681,   2.2170,  -3.5255,  -6.8387,\n",
      "           15.6638,   0.0628, -12.3704,  -4.5811]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.8734,   2.0010,  -3.1517,   2.4619,   0.7150,  -3.8052,  -3.4531,\n",
      "           -5.5144,   0.4013,  -6.5341,   2.5569,  -0.6466,  -1.5204,  -4.8915,\n",
      "           13.1695,  -0.1812,  -8.3489,  -1.4533]]])\n",
      "Predicted Label Index: 14\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.0365, -1.0227,  1.3003, -3.6688, -1.8642, -6.8101, -6.9050,\n",
      "           0.4680, -2.9402, -4.3837, -2.9551, -4.4723, -0.4748, -4.7241,\n",
      "          -0.0473,  9.1927, -2.0304, -2.3165]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.6269,   0.5933,   2.6404,  -2.3050,  -5.4229,  -5.9171, -10.2101,\n",
      "           -4.2245,  -5.8596,  -0.6428,  -2.2253,  -1.1138,  -2.0870,  -6.1670,\n",
      "           -0.8000,  13.3420,   0.8244,  -3.9525]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.7384,  -1.0168,  -0.3163,  -3.6282,  -3.9378,  -9.5641,  -7.9703,\n",
      "            1.7903,  -4.8173,  -5.4577,  -2.5966,  -6.8741,  -1.4893, -10.7843,\n",
      "            2.2549,  15.4375,   0.8994,  -6.5767]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.9463,  0.5251,  0.8591, -3.9470, -8.3288, -5.1100, -6.4048,\n",
      "           1.1421, -3.9332, -1.3325, -3.1597, -0.7016,  0.6173, -6.6331,\n",
      "          -0.6052, 13.0053, -1.1119, -6.8257]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.3595, -1.7133,  1.8586, -3.5329, -7.1544, -5.0843, -5.1687,\n",
      "          -1.6804, -2.4686,  0.3924, -3.5939, -0.3017, -0.2914, -4.9592,\n",
      "           0.2329, 11.1364, -0.0867, -4.7885]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.9486,  0.3790, -0.1988, -3.3254, -3.5068, -6.4446, -6.8558,\n",
      "           1.0891, -3.7860, -1.9821, -2.2550, -3.6998, -2.5521, -6.8066,\n",
      "           1.4173, 13.8239, -1.3398, -5.5256]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.9331, -0.5636,  1.1402, -3.4406, -6.1277, -5.1713, -7.4430,\n",
      "           0.2279, -4.5298, -2.2781, -4.8104, -2.4032, -0.0942, -8.4146,\n",
      "          -0.3129, 13.6459,  0.8977, -5.1032]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.4793, -1.3182,  0.0752, -2.9761, -4.3482, -4.1018, -7.3524,\n",
      "           1.6829, -3.6056, -1.6948, -2.7314, -4.6521, -2.6215, -7.4544,\n",
      "           2.4239, 12.9516,  0.2563, -6.6530]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.5166, -0.6859,  0.8951, -2.9468, -5.0241, -5.4679, -9.1236,\n",
      "          -0.8682, -3.9485, -1.8956, -2.6324, -3.9078, -3.3661, -5.8508,\n",
      "           1.2143, 12.4555, -0.5212, -5.2248]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.1953, -0.1889,  0.5210, -2.4197, -4.6875, -6.1552, -8.2931,\n",
      "          -0.6239, -4.7505, -1.8440, -2.5143, -1.9801, -1.4427, -8.1413,\n",
      "           2.4314, 13.6491,  0.0826, -5.0977]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.3219,  -2.5396,   0.8946,  -0.4930,  -3.7592,  -5.7115, -11.6570,\n",
      "           -1.7694,  -7.4315,  -1.1695,  -0.0183,  -0.0303,  -2.7680,  -5.4338,\n",
      "            1.4267,  16.4223,   1.3054,  -5.1092]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.9651, -0.5948,  3.6901, -2.3390, -5.5379, -5.0798, -9.7528,\n",
      "          -0.6761, -4.8262, -2.2379, -2.5355, -2.9226, -1.7024, -3.9391,\n",
      "          -1.0296, 11.6599,  0.2292, -4.5805]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.9978, -0.9367,  4.0324, -2.0682, -3.9071, -5.1636, -8.0215,\n",
      "          -0.7745, -4.3272,  0.1281, -0.3575, -1.9257, -4.0696, -4.2116,\n",
      "           1.0568, 12.7443,  2.5142, -5.1154]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.6494, -0.5353,  2.0664, -1.2134, -4.5891, -6.6231, -8.7986,\n",
      "          -2.4251, -4.5982, -0.9191, -1.7448, -1.7886, -2.6740, -5.0170,\n",
      "           1.9852, 14.0961,  0.5082, -5.9325]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.3735, -0.4451,  1.7907, -2.8836, -4.6117, -6.1830, -7.1708,\n",
      "          -1.0280, -2.3242, -0.6364, -2.6460, -4.0071, -3.0613, -6.5697,\n",
      "           1.3670, 12.8763, -0.3958, -5.9947]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.8249, -0.7581,  1.1904, -2.9671, -4.9451, -4.9948, -7.9818,\n",
      "          -0.4165, -3.4846, -0.7047, -3.3673, -1.4696, -1.3651, -7.3631,\n",
      "           0.6820, 12.9187, -0.6624, -6.0217]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -5.8863,  -1.4300,  -1.8780,  -1.8170,  -1.3070,  -3.5530, -10.3476,\n",
      "            0.6914,  -4.5333,  -5.1714,  -2.6797,  -1.4837,  -1.2614,  -3.5971,\n",
      "            0.9786,  12.4962,  -2.1741,  -4.9327]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.0966, -1.6913, -0.9398, -1.1325, -5.2633, -5.1191, -5.8066,\n",
      "           2.9834, -2.1727, -0.0418, -2.6624, -3.7107, -3.6283, -6.6586,\n",
      "           2.1461, 13.2865, -0.1750, -7.5159]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.2688, -0.9734, -0.1216, -2.2552, -4.5436, -6.0736, -8.9841,\n",
      "           0.9470, -4.1594, -1.9124, -3.0683, -3.5866, -2.3367, -5.4615,\n",
      "          -0.3528, 13.7783,  1.1947, -7.1440]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.7428, -0.5565,  1.1114, -0.3547, -4.9117, -6.8751, -9.2699,\n",
      "           0.6476, -5.7962, -0.9016, -2.0594, -1.0990, -2.6883, -7.1849,\n",
      "           2.1120, 15.8756,  0.1127, -5.6336]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.4682, -2.7027, -1.9499, -1.5549, -5.8965, -6.4672, -8.7830,\n",
      "           2.2544, -3.1130, -2.8188, -3.9236, -4.3441, -4.7554, -4.8781,\n",
      "           0.8496, 15.6262, -0.3634, -8.4560]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.9842, -2.1805,  1.2979, -2.1387, -6.7296, -5.6082, -7.9563,\n",
      "          -0.6451, -2.0482,  0.4707, -4.4198, -2.5048, -4.0105, -4.2953,\n",
      "           0.1396, 12.5854, -2.3564, -7.1093]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.5724, -0.6422,  0.7333, -2.8851, -7.6865, -6.2251, -9.5115,\n",
      "          -2.2435, -6.2746, -0.5908, -3.0199,  0.7826, -1.2227, -6.0818,\n",
      "          -0.1661, 14.2909, -0.6785, -5.6389]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.7981, -3.4791,  1.0977, -2.0052, -4.2025, -6.3046, -6.6542,\n",
      "          -0.2646, -5.5967, -1.1917, -1.7831, -5.1761, -2.2479, -5.5169,\n",
      "          -2.0106, 14.1575,  2.8911, -5.8283]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.5448, -0.1461,  2.7643, -3.2281, -4.3134, -6.4557, -6.4966,\n",
      "           0.8833, -3.7786, -0.9721, -1.5618, -1.8105, -2.6709, -5.5170,\n",
      "           1.1046, 13.1095,  0.1710, -4.0202]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.0114, -2.1273, -0.4069, -0.8778, -3.6113, -4.0332, -8.8545,\n",
      "           1.4310, -4.9516, -3.2513, -2.6881, -2.7842, -0.9390, -2.7151,\n",
      "          -1.6971, 13.6989,  1.7234, -5.5219]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -7.2870,  -0.6121,   2.2666,  -3.7740,  -6.9602,  -4.3159, -10.8258,\n",
      "           -1.9100,  -6.3375,  -2.5150,  -2.9071,  -0.9950,  -1.3645,  -5.2886,\n",
      "           -0.2559,  15.1658,  -0.3814,  -5.4355]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.6620, -1.5292,  0.2884, -2.7304, -5.4096, -5.2418, -5.3835,\n",
      "          -0.1905, -3.7559,  0.0773, -1.5569, -2.9191, -0.7626, -6.5284,\n",
      "          -2.4083, 11.9626,  0.7424, -6.1768]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.6221, -0.7079,  1.6587, -4.2377, -5.2801, -7.3723, -6.2043,\n",
      "          -0.8816, -2.9923,  0.8132, -2.2999, -2.8412, -2.8571, -7.2962,\n",
      "           1.5414, 12.6730, -1.0968, -5.9652]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.9730, -2.0254,  0.8912, -2.2256, -8.2493, -4.4241, -7.8711,\n",
      "          -0.4682, -5.9764, -1.2625, -3.3651, -1.8817, -0.0672, -5.6097,\n",
      "          -0.6220, 13.0344, -0.0532, -4.7146]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.2576, -1.0963,  0.7646, -3.7646, -6.3569, -5.4317, -8.0860,\n",
      "          -0.2134, -5.4856, -0.5143, -3.9736, -2.7322, -1.4102, -9.1467,\n",
      "           0.9152, 15.2483, -0.8756, -7.1245]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.4799, -0.4225,  1.4855, -2.4345, -5.1309, -4.1842, -7.9050,\n",
      "          -0.5164, -5.4433, -0.4206, -2.3262, -1.7010, -1.6101, -6.2775,\n",
      "           1.3360, 12.9960, -0.0311, -5.8950]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.5935, -3.3401,  0.5438, -1.9190, -8.2017, -5.2700, -8.6263,\n",
      "           1.3702, -3.3626, -3.0003, -4.0404, -1.1116,  0.0741, -4.7595,\n",
      "          -1.3027, 11.6956, -1.0589, -4.2261]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.1036, -3.4551, -0.7939, -0.5316, -7.0737, -5.9223, -6.6384,\n",
      "           4.9619, -4.1806, -2.3604, -2.7045, -3.0957, -1.9751, -6.7501,\n",
      "           2.1001, 15.1762, -1.4049, -5.1705]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.3681, -4.0705,  2.1855, -1.7435, -7.6791, -4.5016, -9.4096,\n",
      "           1.8435, -5.3385, -0.2886, -2.3717, -2.2860, -3.1241, -6.4737,\n",
      "          -0.2458, 16.3127, -0.2584, -4.1867]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -6.6038,   0.0497,   2.7613,  -2.3007,  -6.2881,  -5.2315, -10.3361,\n",
      "           -1.9876,  -5.5519,  -1.5941,  -1.4269,  -0.7277,  -1.8996,  -5.2822,\n",
      "            1.2627,  14.2229,  -0.2100,  -6.3623]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.8036, -0.4714, -0.9198, -2.2685, -4.2292, -2.9934, -7.8690,\n",
      "           1.5523, -3.6607, -2.9331, -4.2025, -3.5345, -1.5229, -6.2387,\n",
      "           2.0714, 12.3101, -1.5619, -5.6044]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.8621, -1.3523,  3.2971, -4.8721, -7.4746, -5.0851, -9.0693,\n",
      "          -1.8912, -4.5389, -0.7365, -4.1190, -2.5984, -1.5195, -7.4268,\n",
      "           0.6638, 13.8303, -1.6619, -4.7475]]])\n",
      "Predicted Label Index: 15\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.7981,  -3.2104,   3.1722,  -8.2575,   1.3302,  -5.7512,  -5.8490,\n",
      "           -5.4611,  -3.9277,  -3.9096,  -3.3682,  -7.8239,   2.7998,  -0.0351,\n",
      "          -13.7518,  -2.5397,  12.0100,   2.4989]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.0205,  -1.7753,   3.5830,  -5.6454,  -2.1373,  -5.1942,  -5.7775,\n",
      "           -6.1992,  -4.7961,  -1.3307,  -1.6328,  -6.5398,   0.2129,  -0.7086,\n",
      "          -11.1030,   1.1865,  13.3761,  -2.0713]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.3977,  -1.4377,   1.6483,  -3.6446,  -2.7479,  -5.0321,  -4.8195,\n",
      "           -4.6599,  -4.4353,  -2.1241,  -5.0047,  -7.4294,   0.5716,  -4.0780,\n",
      "          -10.5002,   2.8173,  12.6712,  -0.7760]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.4529,  -2.5097,   5.3691,  -5.2038,  -1.0799,  -4.9795,  -7.6119,\n",
      "           -7.8517,  -4.0650,  -1.0472,  -3.6806,  -9.9177,  -1.6527,  -2.2985,\n",
      "          -11.2876,   1.1744,  15.1519,  -2.0354]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.4063,  -3.3720,   3.4581,  -5.5337,   1.1834,  -4.1699,  -6.6771,\n",
      "           -4.1150,  -4.1947,  -1.3182,  -3.6853, -10.1364,  -0.5216,   1.5112,\n",
      "          -14.5203,  -0.1889,  14.1664,  -3.3167]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.0570,  -1.2663,   1.1583,  -7.7378,  -1.8060,  -7.6056,  -6.6690,\n",
      "           -7.9687,  -5.6200,  -3.2325,  -5.4246,  -9.8680,   2.6683,  -3.9115,\n",
      "          -14.6404,   1.5304,  16.3336,  -1.1101]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.4835,  -0.2907,   0.0342,  -6.2728,   1.2400,  -6.0647,  -7.6553,\n",
      "           -6.2871,  -5.0321,  -3.7715,  -3.2845, -10.5597,  -1.2098,  -1.0362,\n",
      "          -12.8731,  -1.1319,  12.6695,  -1.9709]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.8613,  -1.7591,   1.0235,  -5.8074,  -2.5023,  -4.0473,  -6.6221,\n",
      "           -5.3424,  -4.4569,  -2.5042,  -3.8414, -10.0722,   1.1555,  -1.3209,\n",
      "          -12.1911,   0.4200,  13.5775,  -4.3609]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.4202,  1.0635,  1.9653, -5.4493,  0.3816, -6.5409, -5.5357,\n",
      "          -4.3631, -4.2372, -4.1197, -4.9198, -5.5791, -0.5550, -2.8403,\n",
      "          -9.8979,  0.2921, 12.1378, -0.2641]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.1508,  -2.4747,   0.3320,  -4.3302,  -1.4354,  -4.4887,  -4.1384,\n",
      "           -6.8815,  -2.9395,   0.0439,  -4.8556, -11.1551,  -0.6059,  -3.1079,\n",
      "          -15.1996,  -0.2970,  15.7409,  -4.7831]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.6156,  -2.4126,   0.6857,  -6.2113,   0.6309,  -6.2157,  -2.2337,\n",
      "           -4.3684,  -4.3009,  -1.8261,  -5.1036, -10.3538,   0.7036,  -2.6053,\n",
      "          -13.6546,  -0.9097,  14.9930,  -2.2133]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.9636,   0.9167,   1.6778,  -7.2985,  -0.8002,  -7.8062,  -7.9132,\n",
      "           -8.6990,  -5.5877,  -2.3844,  -4.2637,  -7.1266,   1.2385,  -1.0782,\n",
      "          -12.5296,   1.2942,  12.5803,  -0.2650]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.8103,  -5.1157,   2.4730,  -6.5600,  -0.8628,  -4.6839,  -2.4660,\n",
      "           -3.4124,  -4.0703,  -0.9167,  -3.5716, -10.5283,   2.5244,  -0.5974,\n",
      "          -15.4818,  -1.6340,  12.3738,   0.6257]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.5056,  -0.1989,   2.5440,  -3.3478,  -0.8837,  -3.2238,  -9.4019,\n",
      "           -6.8316,  -5.5071,  -1.4050,  -4.9936,  -7.3227,  -0.0952,  -0.8625,\n",
      "          -13.8877,   0.4045,  13.9065,  -2.5559]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.0386e+01, -1.6138e+00,  2.8540e+00, -5.7302e+00, -4.3555e-01,\n",
      "          -6.7157e+00, -7.5001e+00, -7.7303e+00, -5.0665e+00, -1.5280e+00,\n",
      "          -5.6417e+00, -9.7141e+00, -1.2300e-02, -2.0892e+00, -1.4529e+01,\n",
      "           2.0117e+00,  1.7079e+01,  2.8066e-01]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.5244,  -0.0669,   2.2297,  -7.5971,  -1.1764,  -4.9183,  -6.6916,\n",
      "           -7.9914,  -5.0625,  -1.2332,  -3.2100,  -8.4917,   0.8348,  -1.5393,\n",
      "          -14.8659,  -1.1841,  15.0684,  -2.2610]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.4623,  -1.9295,   1.3058,  -7.1663,  -0.8930,  -4.0646,  -6.8703,\n",
      "           -8.4978,  -5.7326,  -0.8372,  -4.8374,  -9.7063,   2.2129,  -3.1035,\n",
      "          -15.0296,   1.4518,  16.7693,   0.3774]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.9423,  -4.4055,   3.6333,  -6.3819,  -3.4878,  -5.2030,  -5.4986,\n",
      "           -6.3582,  -3.6258,  -2.0564,  -4.1682, -10.3192,   1.1018,  -2.0465,\n",
      "          -12.5762,  -0.6986,  14.0184,  -2.3310]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.3311,  -2.3003,   1.6078,  -5.5325,   0.1659,  -3.9375,  -2.8309,\n",
      "           -4.0002,  -3.8339,  -0.4412,  -3.1278,  -9.5789,   0.7585,  -0.9499,\n",
      "          -13.6168,  -1.3392,  14.0092,  -3.7849]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.9260,  -0.7508,   1.7985,  -5.7631,  -1.0048,  -7.0107,  -5.4560,\n",
      "           -5.9895,  -3.8674,  -2.8973,  -5.0333,  -7.4785,   1.0765,  -2.7135,\n",
      "          -10.9868,   0.7115,  13.9317,  -1.4504]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.5214,  -2.5956,   0.6859,  -3.4396,  -1.3340,  -4.6329,  -6.1853,\n",
      "           -4.6937,  -5.1197,  -2.0488,  -4.0357,  -7.9636,   1.9156,  -3.4147,\n",
      "          -11.4539,   2.1241,  12.4180,   0.0871]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.7609,  -2.3071,   3.0436,  -6.1222,  -0.3319,  -7.1771,  -6.4113,\n",
      "           -5.1213,  -4.3884,  -2.6853,  -2.5306,  -9.1822,   0.6188,  -2.3716,\n",
      "          -12.0189,   1.0967,  13.6516,   0.5918]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.7337, -1.2199,  3.3058, -6.5517, -0.2717, -5.4981, -6.6913,\n",
      "          -6.4808, -4.2499, -2.9889, -3.7214, -7.1179,  2.0202, -4.1831,\n",
      "          -9.9915, -0.8713, 11.8449,  1.3615]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.5793,  -2.2796,   4.4345,  -4.9243,  -1.4279,  -4.8587,  -7.8968,\n",
      "           -8.8148,  -4.5392,  -0.1113,  -4.0190,  -7.4257,   0.9967,  -3.2776,\n",
      "          -12.7895,   2.0928,  14.2857,  -0.9831]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.3524,  -1.4735,   1.6796,  -4.7750,  -1.3467,  -6.0061,  -7.9203,\n",
      "           -7.6954,  -5.0972,  -1.1743,  -6.6164,  -9.2852,  -0.1583,  -2.0322,\n",
      "          -16.7331,   1.2324,  16.9138,  -2.3949]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.9769,  -0.0544,   0.8944,  -3.0534,  -2.5366,  -5.0274,  -4.7794,\n",
      "           -5.2472,  -2.1067,   1.2962,  -4.2103,  -5.2236,  -1.2115,  -5.2865,\n",
      "          -10.1399,   4.0396,  13.5591,  -1.7862]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.9355,  -1.1720,   3.9825,  -8.0319,   0.2888,  -4.7979,  -4.4790,\n",
      "           -5.9132,  -3.9968,  -0.7394,  -4.5220,  -7.5745,   0.6637,  -2.8308,\n",
      "          -12.3348,   0.0573,  13.4308,   1.6217]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.9677,  -2.0832,   4.2742,  -6.1822,  -2.0351,  -5.3416,  -9.7060,\n",
      "           -8.2428,  -5.5685,  -1.5734,  -4.8377,  -8.6733,   0.0468,  -2.9078,\n",
      "          -13.9269,   0.9667,  15.7004,  -3.1714]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.6141,  -0.0862,   1.8223,  -7.4508,   0.8067,  -4.6383,  -5.9044,\n",
      "           -6.8152,  -5.3684,  -4.1545,  -5.4933, -12.4346,   1.3696,  -1.6907,\n",
      "          -14.0733,  -0.9271,  16.2631,   0.0239]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.1477,  -0.7432,   3.1982,  -8.4457,  -1.3004,  -6.3009,  -5.6124,\n",
      "           -8.3471,  -5.0041,  -0.3454,  -3.1047,  -8.9982,   0.0888,  -2.7268,\n",
      "          -13.1932,   1.3812,  14.6752,  -1.5084]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.6092,  -2.9778,   1.9808,  -6.7402,  -3.7314,  -4.7752,  -4.8393,\n",
      "           -6.7941,  -4.7122,  -0.7386,  -5.9849, -11.6842,   3.1455,  -2.0569,\n",
      "          -16.2753,   0.6432,  17.3846,  -3.0944]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.2375,  -1.0009,   1.9055,  -3.5717,  -1.0699,  -5.2545,  -4.9692,\n",
      "           -6.3305,  -3.3925,  -0.0167,  -4.8026,  -6.4252,   0.3577,  -2.7180,\n",
      "          -11.6058,   1.8037,  13.4713,  -3.6421]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.1202,  -2.2184,   0.5037,  -5.8938,  -3.1640,  -6.1523,  -5.2317,\n",
      "           -6.7866,  -3.8611,  -0.7131,  -5.9180,  -8.0879,   1.2940,  -6.4723,\n",
      "          -13.6491,   2.3146,  15.5604,  -1.9307]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.2207,  -2.0347,   2.0108,  -7.7214,  -4.5000,  -7.4949,  -3.4427,\n",
      "           -5.9313,  -2.9835,  -1.9208,  -5.4523, -10.1021,   1.8391,  -6.3416,\n",
      "          -10.8056,   2.1111,  11.3119,  -1.9634]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -9.9344,  -1.1691,   3.6403,  -6.1033,  -2.7010,  -4.7672,  -6.2055,\n",
      "           -7.5310,  -4.9502,  -1.2487,  -3.9436,  -7.1330,   1.5162,  -3.3946,\n",
      "          -10.9748,   1.7883,  13.1096,  -0.8295]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-11.4504,  -4.8759,   2.3495,  -5.4679,  -1.8742,  -7.7491,  -4.5078,\n",
      "           -5.5038,  -4.2218,  -1.2650,  -1.9612, -11.5987,   0.4088,  -0.4031,\n",
      "          -13.8775,  -0.2928,  15.2932,  -3.0118]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.5402,  -0.8308,   1.4658,  -7.2599,  -1.7318,  -6.8707,  -6.0183,\n",
      "           -6.6872,  -4.6382,  -2.0492,  -4.6051,  -9.1836,   0.7530,  -2.3410,\n",
      "          -14.3873,   1.1918,  15.5559,  -3.5044]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.4262,  -2.0882,   2.6409,  -6.5004,  -2.5250,  -8.6693,  -7.0204,\n",
      "           -6.0075,  -5.7347,  -3.5537,  -5.4409, -10.9394,   0.3908,  -4.0057,\n",
      "          -15.5594,   2.1200,  14.5069,   1.8920]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.0173,  -1.8216,   1.9220,  -4.3185,  -1.6858,  -5.4520,  -4.7167,\n",
      "           -2.8033,  -4.0495,  -2.8280,  -3.2417,  -7.8292,   0.2283,  -0.8882,\n",
      "          -11.4455,   0.3336,  13.2430,  -2.2726]]])\n",
      "Predicted Label Index: 16\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.4295, -4.3651, -1.1793, -6.6787, -0.4009, -3.8749, -5.0456,\n",
      "          -0.9648, -1.5192, -7.6750, -2.1716, -3.1722,  1.7782,  0.5669,\n",
      "          -3.8171, -1.2900, -4.6837, 11.8574]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.1652e+00, -2.5869e+00, -4.4376e-03, -6.8325e+00,  2.0805e+00,\n",
      "          -6.3088e+00, -3.2225e+00, -1.9118e+00, -8.6688e-01, -4.5119e+00,\n",
      "          -2.6826e+00, -4.2994e+00,  1.5270e-01, -4.0052e+00, -4.1362e+00,\n",
      "          -1.7166e+00, -9.7221e-01,  1.3244e+01]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.9186, -2.8241, -0.8073, -4.8964,  1.2489, -5.4651, -4.4518,\n",
      "          -1.3035,  0.2561, -3.9339, -3.3823, -3.9526, -0.9032, -2.9188,\n",
      "          -4.1539,  0.0234, -2.2226, 11.6593]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.3599, -2.5759, -1.7478, -6.5099,  1.6805, -5.8829, -4.9923,\n",
      "          -1.7669, -2.0581, -6.7767, -2.2629, -3.9228,  0.3553, -2.3025,\n",
      "          -3.4743, -1.1622, -3.8467, 12.8013]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.3480, -2.0098, -1.0525, -4.7627,  1.6911, -6.8021, -4.2683,\n",
      "          -1.0556, -1.2836, -8.1230, -1.7941, -2.1006, -0.0136, -2.9406,\n",
      "          -0.4254, -0.3265, -2.2428,  9.8298]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.7577, -4.1876, -1.8632, -7.5356,  3.2841, -6.7373, -5.4536,\n",
      "          -1.1970, -1.4004, -5.2555, -3.0586, -6.0205, -0.1389, -2.9197,\n",
      "          -5.9078, -1.2956, -4.0251, 13.3580]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.5563, -4.4748, -2.2168, -6.8969,  0.2120, -6.2327, -3.7837,\n",
      "          -2.2717,  0.5128, -6.8682, -1.0308, -1.5865,  0.3796, -2.5953,\n",
      "          -3.1012, -2.3483, -3.9936, 14.2032]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.9980, -2.7296, -1.6252, -4.9569,  2.0586, -5.7278, -5.4304,\n",
      "          -0.3412, -0.3315, -5.8018, -3.4847, -4.4118, -1.8322, -2.4494,\n",
      "          -4.8357, -0.0887, -3.1495, 13.5159]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.8684, -2.3842, -1.8285, -6.2111,  1.0687, -7.4588, -4.0350,\n",
      "          -1.2608, -0.5268, -6.1167, -3.8693, -4.3506, -0.5164, -2.5048,\n",
      "          -5.6837, -0.3919, -2.6112, 11.8088]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.3000, -3.2684,  0.4483, -5.2549, -0.2044, -5.8083, -3.1633,\n",
      "          -0.8781,  0.3119, -4.8788, -3.0801, -2.9368, -1.3124, -3.2342,\n",
      "          -2.3097, -1.7515, -4.7421, 12.5240]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.7152, -2.3044,  0.3859, -5.7905,  0.1607, -5.5939, -2.6612,\n",
      "          -0.8680, -0.5627, -3.7877, -4.8201, -4.6924, -2.5075, -1.9764,\n",
      "          -3.3678, -1.2042, -1.7311, 12.8272]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.9791e+00, -6.1271e+00, -8.9086e-01, -4.5096e+00, -4.2975e-01,\n",
      "          -3.2198e+00, -3.2271e+00, -4.6311e-04, -7.4257e-01, -3.7985e+00,\n",
      "          -2.1374e+00, -2.7349e+00,  8.2842e-01, -9.3548e-01, -2.1659e+00,\n",
      "          -2.1218e+00, -5.5800e+00,  1.0581e+01]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.9580e+00, -2.9834e+00, -4.8728e-04, -5.2707e+00,  3.2302e-01,\n",
      "          -6.2518e+00, -6.3049e+00, -2.2124e+00, -7.1710e-01, -5.2718e+00,\n",
      "          -3.9306e+00, -4.1257e+00, -1.2790e+00, -8.6071e-01, -5.4093e+00,\n",
      "          -2.8269e-01,  4.4074e-01,  1.3509e+01]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.7142, -4.9223, -1.3790, -7.1473, -0.5663, -6.4312, -3.1748,\n",
      "          -1.2471,  1.1301, -5.5904, -3.3709, -3.7691, -1.5123, -1.5147,\n",
      "          -4.6674, -1.8490, -3.6177, 14.0999]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.1747, -4.9346, -0.1515, -6.4939, -2.4407, -5.4972, -0.0995,\n",
      "           0.1850,  0.6941, -4.4767, -1.8934, -4.0385,  0.8683, -3.2373,\n",
      "          -4.5287, -1.6574, -3.2866, 11.3379]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.4217, -5.3048, -1.5898, -7.1531, -0.3233, -6.7718, -1.5926,\n",
      "          -1.7403,  1.0815, -4.7805, -2.6785, -3.4266,  0.5938, -2.0069,\n",
      "          -4.6236, -2.5363, -3.5078, 12.8766]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.0507, -4.4054,  0.2733, -7.3114, -1.2743, -6.1734, -1.6439,\n",
      "          -1.1280,  1.3368, -5.3720, -3.8554, -3.3980,  0.0553, -1.8578,\n",
      "          -3.6174, -1.7686, -4.1507, 13.3778]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.4338, -3.3149, -1.6208, -7.2295, -0.3041, -5.8149, -1.8590,\n",
      "          -2.4142,  0.2216, -3.7370, -3.2069, -1.8112,  0.4888, -1.9031,\n",
      "          -3.7950, -2.5755, -2.9791, 11.9603]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.6883, -3.5944, -0.3096, -7.1325,  1.6168, -7.4812, -3.4287,\n",
      "          -1.5070, -0.1308, -6.6661, -5.1313, -3.5589, -1.1410, -1.9456,\n",
      "          -2.4094, -1.1782, -2.4112, 14.1348]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.5201, -1.5632, -0.6610, -7.7845,  2.3558, -6.3045, -3.3480,\n",
      "          -1.5710, -1.1129, -4.7296, -3.8808, -5.8059, -0.4388, -2.6590,\n",
      "          -3.5874, -1.3932, -0.2866, 10.3383]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.8334, -5.0439, -0.8194, -6.4290,  1.2363, -6.0694, -1.8222,\n",
      "          -0.8464,  1.5054, -4.9380, -3.0043, -4.2596,  0.6087, -2.3987,\n",
      "          -5.2211, -2.4186, -2.1539, 12.1183]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.7082, -2.6086, -0.6287, -7.1091,  2.7483, -6.0642, -7.7123,\n",
      "          -1.8181, -2.4659, -7.2511, -2.7821, -6.2987, -0.3804, -2.1968,\n",
      "          -4.9312, -1.0689, -2.7612, 14.0122]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.7267, -1.4731, -2.2922, -6.3510, -0.5206, -5.1744, -3.5446,\n",
      "          -1.6236, -0.8358, -5.1526, -6.3204, -3.1108,  0.4025, -1.0075,\n",
      "          -5.5924, -1.3421, -1.1986, 12.8459]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.9044, -2.2569,  0.6243, -8.0793,  4.0341, -6.4216, -9.9233,\n",
      "          -6.6056, -2.3788, -5.9442, -6.3305, -3.6089, -0.6225, -2.3154,\n",
      "          -4.7922, -2.4158, -1.5235, 15.7315]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.0127, -3.4104, -1.7200, -5.4204,  0.7580, -4.5204, -3.2462,\n",
      "          -0.5236,  0.7777, -3.6148, -3.1999, -4.4174, -1.2304, -2.0086,\n",
      "          -4.5463, -0.9517, -2.6173, 13.2236]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.5796, -2.9382, -3.0712, -8.1346,  2.8057, -7.6858, -5.7204,\n",
      "          -1.8126, -1.1300, -6.3891, -5.0732, -5.8451, -1.0101, -2.8383,\n",
      "          -5.2613, -1.7393, -4.3091, 16.3812]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.4073, -2.9888, -0.8645, -7.1009,  2.0342, -7.1089, -5.7238,\n",
      "          -3.3679, -0.2790, -5.6958, -5.6704, -4.1097, -1.9718, -2.7286,\n",
      "          -3.8658, -0.9081, -0.2477, 13.3006]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.3565, -1.9047, -0.3253, -7.6486,  1.3022, -6.6875, -5.9244,\n",
      "          -2.9323, -1.3560, -7.2440, -4.5860, -3.2780, -0.8578, -3.6341,\n",
      "          -1.0042, -1.1816, -3.0812, 14.8693]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.7844, -4.5652, -1.6017, -6.2086,  0.4874, -6.3037, -3.5174,\n",
      "          -1.5410,  1.3176, -5.2280, -4.2757, -3.1108, -1.0527, -2.0383,\n",
      "          -3.9333, -2.5952, -5.0060, 13.1978]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.1150,  0.0233, -1.6618, -8.4900,  2.4462, -6.9180, -6.9259,\n",
      "          -3.6003, -1.0835, -8.0141, -4.6521, -3.2213,  0.0699, -3.7761,\n",
      "          -5.0782, -0.9920, -2.2832, 15.5264]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.3100, -0.2518, -1.5189, -6.9663,  2.7622, -6.8736, -6.8658,\n",
      "          -2.2310, -1.6623, -6.3264, -4.5838, -5.7469, -0.7955, -3.8301,\n",
      "          -5.6904,  0.3738, -0.3745, 13.6722]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.1110, -1.5231, -1.1452, -7.7379,  1.0932, -6.3129, -5.9196,\n",
      "          -3.1166, -0.6324, -5.3863, -4.5292, -4.7147, -0.4484, -2.8963,\n",
      "          -4.9826, -1.6574, -2.2394, 14.9989]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.6128, -3.9749, -2.1602, -4.9901, -0.0948, -6.3820, -4.2375,\n",
      "          -0.8694,  0.1822, -5.4395, -4.4425, -4.0802,  0.3226, -4.0104,\n",
      "          -5.4044, -1.2586, -4.5543, 12.7976]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.1082, -2.6176, -1.5065, -6.2476,  0.8504, -4.2288, -6.7926,\n",
      "          -3.6304,  0.0680, -5.4429, -4.6725, -2.0627, -0.1702, -1.7427,\n",
      "          -2.6425, -2.2608, -5.4092, 11.5495]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.6351, -1.8511, -1.4359, -5.0514,  2.3582, -7.6110, -7.1420,\n",
      "          -1.9256, -1.4965, -7.6492, -3.0319, -3.3290,  0.8847, -4.1174,\n",
      "          -3.6177,  0.2995, -1.0474, 13.3522]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.3056, -3.3729, -1.7445, -6.3935,  0.7896, -6.3857, -3.3637,\n",
      "          -0.1568,  0.0288, -5.2120, -3.9521, -5.1505, -0.8687, -1.8156,\n",
      "          -5.9736, -0.6388, -1.7154, 13.4198]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.9394, -4.9904, -0.0608, -5.9878, -1.4585, -4.0250, -4.1964,\n",
      "          -0.9682,  0.1257, -5.7158, -3.7826, -3.2609, -0.1238, -0.1195,\n",
      "          -4.0702, -1.6317, -5.4607, 12.7833]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.2058, -3.5637, -1.4631, -4.5382,  3.1022, -4.1717, -6.8919,\n",
      "          -1.6410, -0.4981, -7.2593, -1.9487, -1.3760, -0.4743, -0.5805,\n",
      "          -1.3307, -2.0139, -2.5867, 13.6091]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.4221, -2.5772, -0.3359, -3.5428,  1.1352, -4.7768, -3.2049,\n",
      "           0.8253, -0.0317, -3.8308, -1.4783, -4.0014, -1.1001, -2.7041,\n",
      "          -2.2301, -0.2874, -2.1751,  9.4746]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.9777, -2.6477, -2.5584, -6.9513,  1.1783, -5.5148, -3.3404,\n",
      "          -1.7248, -0.6447, -5.0921, -2.2022, -3.6296,  1.1303, -1.8645,\n",
      "          -5.1198, -0.6457, -3.1443, 11.9749]]])\n",
      "Predicted Label Index: 17\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.5795, -2.3330, -1.4308, -5.1036,  3.5787, -4.7604, -7.7450,\n",
      "          -2.1722, -0.7588, -5.3223, -1.5629, -4.3833, -0.1131, -3.7890,\n",
      "          -4.4027, -0.6483, -2.8076, 12.8872]]])\n",
      "Predicted Label Index: 17\n",
      "Test Accuracy: 100.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions for all test samples\n",
    "y_pred = [predict_speaker(model, classifier, file) for file in data]\n",
    "y_true = [speakers[label] for label in labels.numpy()]\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred, labels=speakers)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, xticklabels=speakers, yticklabels=speakers, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "659dcbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -3.4055,   9.5244,   0.7983,  -4.8836,  -3.4049,  -0.1083,  -7.5336,\n",
      "           -4.5838,  -0.3018,  -1.3863,  -0.6668,   0.0702,  -2.9629,  -5.2470,\n",
      "            0.5496,  -1.1606,  -5.5136, -10.4498]]])\n",
      "Predicted Label Index: 1\n",
      "Predicted Speaker: deepak\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b8da628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-10.2829,   5.9308,  -2.8565,   0.3548,  -2.0392,  -0.1621,  -6.9341,\n",
      "           -4.6348,   3.2458,   1.5449,   2.6027,   8.0554,  -2.6147,  -5.0241,\n",
      "           -0.0616,  -6.7205, -10.4584, -12.5231]]])\n",
      "Predicted Label Index: 11\n",
      "Predicted Speaker: rajesh\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test2.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test2.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test2.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e806cebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.3096e+00,  9.3139e+00,  6.4875e-03, -3.8335e+00, -2.6378e+00,\n",
      "           3.0214e+00, -5.2306e+00, -4.3891e+00, -4.3423e-01,  2.3726e-01,\n",
      "          -6.8641e-01, -2.2593e+00, -2.8553e+00, -5.3711e+00, -2.5106e-01,\n",
      "          -2.4848e+00, -4.4658e+00, -1.0404e+01]]])\n",
      "Predicted Label Index: 1\n",
      "Predicted Speaker: deepak\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test3.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test3.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test3.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9e113aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.2918,  2.5267,  1.0131, -2.3594,  3.0109, -0.1817, -6.4075,\n",
      "          -2.4621, -1.3193,  0.3228,  4.4931,  6.4973,  0.4180, -2.4757,\n",
      "           1.9988, -1.4529, -5.1466, -3.5246]]])\n",
      "Predicted Label Index: 11\n",
      "Predicted Speaker: rajesh\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test4.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test4.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test4.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "64468280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.3493, -2.0684, -2.3580,  2.3031, -2.0168, -0.4457, -1.6714,\n",
      "           0.3903,  2.7898,  2.4296, -1.0848, -0.1920, -2.0781, -3.6708,\n",
      "           2.0410, -0.9491, -4.4270, -4.2032]]])\n",
      "Predicted Label Index: 8\n",
      "Predicted Speaker: nihar\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test5.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test5.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test5.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "249eb039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-2.6069, -2.5162, -4.1322, -3.4544,  4.7972, -5.0187, -3.5914,\n",
      "           0.3804,  0.1591, -5.1875, -2.9334, -7.2760, -1.1836, -3.2749,\n",
      "          -5.1866, -1.5730, -2.0376,  4.9015]]])\n",
      "Predicted Label Index: 17\n",
      "Predicted Speaker: vijetha\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test6.wav\", duration=6, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test6.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test6.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "da5348f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-9.5699, -1.5032, -1.7542,  8.8838,  0.8159,  1.4103, -7.5883,\n",
      "          -0.7107,  0.9785,  2.3922,  3.9550,  2.8636, -3.3461, -3.5764,\n",
      "           0.5486, -2.4888, -5.0447, -4.9577]]])\n",
      "Predicted Label Index: 3\n",
      "Predicted Speaker: likith\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test7.wav\", duration=6, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test7.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test7.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66b75549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.1728, 10.0539,  2.6863, -4.3318, -2.2979,  0.6469, -7.5268,\n",
      "          -3.1269, -0.8553, -3.2366, -1.3193, -2.7976, -2.7087, -4.6373,\n",
      "           0.1920, -0.3025, -3.4347, -8.8519]]])\n",
      "Predicted Label Index: 1\n",
      "Predicted Speaker: deepak\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test8.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test8.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test8.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be9a3a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[ -8.7778,  -3.3772,  -0.0308,   5.3794,   1.7522,   5.6738, -12.4194,\n",
      "           -1.1307,  -2.8031,   4.0966,   4.5743,   1.8595,  -2.1301,  -6.1677,\n",
      "            1.0531,  -3.1229,  -4.2588,  -3.8301]]])\n",
      "Predicted Label Index: 5\n",
      "Predicted Speaker: macha\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test9.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test9.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test9.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9a56bec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.9293, -1.3297, -1.8180,  5.8025,  0.1090, -0.3546, -5.8164,\n",
      "           0.7379,  1.0603, -1.0995,  2.5678, -0.5621, -2.5271, -3.2377,\n",
      "           0.7603, -1.2537, -3.8693, -2.5452]]])\n",
      "Predicted Label Index: 3\n",
      "Predicted Speaker: likith\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test10.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test10.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test10.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "085db2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.3493,  1.8515, -1.9337,  2.2466, -3.3708, -1.4038, -6.7577,\n",
      "          -4.0252,  1.4858, -0.2790,  2.1139,  8.0918, -0.0823, -1.4181,\n",
      "          -2.2218, -5.1548, -6.0691, -6.7715]]])\n",
      "Predicted Label Index: 11\n",
      "Predicted Speaker: rajesh\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test11.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test11.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test11.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "45c516f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.6483,  9.4687,  2.2337, -4.4994, -1.2850,  1.0944, -6.3400,\n",
      "          -2.6303, -0.2122, -3.8814, -1.1449, -2.4874, -3.7259, -5.1893,\n",
      "           3.2862, -2.3941, -6.1221, -7.7472]]])\n",
      "Predicted Label Index: 1\n",
      "Predicted Speaker: deepak\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test12.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test12.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test12.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d232698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-8.0260e+00,  4.7756e-03, -1.2779e+00, -3.3243e-01, -8.0299e-01,\n",
      "           1.7538e+00, -8.1058e+00, -3.0739e-02, -2.3676e+00, -2.7932e+00,\n",
      "           1.9094e+00,  4.1355e+00, -5.5067e-01, -1.5868e+00, -2.3248e-01,\n",
      "          -3.5377e+00, -3.3437e+00, -6.6573e+00]]])\n",
      "Predicted Label Index: 11\n",
      "Predicted Speaker: rajesh\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test13.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test13.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test13.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ad9eb068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.9838, -0.2204,  0.6155, -0.1354,  3.9239, -2.9370, -2.9801,\n",
      "           1.3606,  1.7684, -2.0436,  1.6190, -1.4143, -2.6262, -3.7387,\n",
      "           2.1848, -1.1800, -3.7791,  0.0938]]])\n",
      "Predicted Label Index: 4\n",
      "Predicted Speaker: likta\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test14.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test14.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test14.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "16f75c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-4.0077, -3.1431, -0.5932,  1.2365, -0.0877, -4.5913, -4.2608,\n",
      "          -2.3171,  2.6101,  1.0824, -0.5879, -0.5499, -3.1420, -3.9610,\n",
      "           1.3725,  0.5245, -1.3431, -5.3027]]])\n",
      "Predicted Label Index: 8\n",
      "Predicted Speaker: nihar\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test15.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test15.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test15.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "95571f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-1.9927,  1.7455, -0.6816, -1.0542, -0.3119,  0.1917, -4.2923,\n",
      "          -0.2436,  0.8797,  0.8942, -0.5278, -0.5921, -2.4092, -3.1725,\n",
      "          -0.7541, -0.1010, -1.8408, -6.3295]]])\n",
      "Predicted Label Index: 1\n",
      "Predicted Speaker: deepak\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test16.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test16.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test16.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4e16d086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-3.7630, -2.6711, -3.5955,  3.5506, -0.3468,  0.5078, -5.7842,\n",
      "          -1.6454,  0.7675,  2.5646,  3.3086,  2.3180, -2.4352, -3.8305,\n",
      "          -1.5197, -3.1605, -4.9354, -5.7126]]])\n",
      "Predicted Label Index: 3\n",
      "Predicted Speaker: likith\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test17.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test17.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test17.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "71368905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-5.7269, -1.7568, -3.0669,  6.3813, -2.4554,  0.3620, -6.9833,\n",
      "          -3.0954,  5.1714,  2.4846, -0.7573,  2.2688, -2.9850, -4.6465,\n",
      "          -1.3765, -4.3008, -6.1133, -5.3080]]])\n",
      "Predicted Label Index: 3\n",
      "Predicted Speaker: likith\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test18.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test18.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test18.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "79635270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.8823,  4.0382, -1.1711, -3.9061, -0.9738, -0.7684, -9.9120,\n",
      "          -5.4907, -2.1373, -1.2138,  4.9578,  4.6058, -2.1259, -5.2050,\n",
      "           1.5695, -4.8409, -8.6063, -9.0479]]])\n",
      "Predicted Label Index: 10\n",
      "Predicted Speaker: pavan\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test19.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test19.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test19.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c2d38b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.6960,  2.7121, -4.1413, -0.5047, -3.1593, -1.0860, -4.4064,\n",
      "          -7.7801,  0.0527, -2.0727, -0.6405,  4.6656, -1.9181, -5.2286,\n",
      "           4.1356, -3.1777, -7.0679, -5.0980]]])\n",
      "Predicted Label Index: 11\n",
      "Predicted Speaker: rajesh\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test20.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test20.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test20.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ce1a4083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-7.6372,  6.4830,  2.8437, -3.7534,  0.4513,  0.1999, -7.6825,\n",
      "          -2.4858,  0.5438, -0.7386,  1.0944, -1.0438, -3.8760, -5.6316,\n",
      "           2.3551, -0.8269, -4.8510, -8.0707]]])\n",
      "Predicted Label Index: 1\n",
      "Predicted Speaker: deepak\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test21.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test21.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test21.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ec6176c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved.\n",
      "Embedding Shape: torch.Size([1, 192])\n",
      "Reshaped Embedding Shape: torch.Size([1, 1, 192])\n",
      "Model Output Shape: torch.Size([1, 1, 18])\n",
      "Model Raw Output: tensor([[[-6.1822, -2.0056, -3.2309,  6.0710, -1.1573, -2.8875, -2.3353,\n",
      "          -1.8862,  3.4634,  1.3296,  1.1955, -0.9401, -2.8592, -1.2746,\n",
      "           0.5693,  0.3170, -1.4674, -4.5372]]])\n",
      "Predicted Label Index: 3\n",
      "Predicted Speaker: likith\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def record_audio(filename=\"test22.wav\", duration=4, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"int16\")\n",
    "    sd.wait()\n",
    "    wav.write(filename, sr, audio)\n",
    "    print(\"Recording saved.\")\n",
    "\n",
    "# Record and Predict\n",
    "record_audio(\"test22.wav\", duration=4)\n",
    "predicted_speaker = predict_speaker(model, classifier, \"test22.wav\")\n",
    "print(f\"Predicted Speaker: {predicted_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b2a4fbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\System32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # Check current directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206574a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
